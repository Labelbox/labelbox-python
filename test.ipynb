{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "from labelbox.schema.conflict_resolution_strategy import ConflictResolutionStrategy\n",
        "\n",
        "client = lb.Client(\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbG9vcmRpaGUwMDkyMDcza2Nvcm5jajdnIiwib3JnYW5pemF0aW9uSWQiOiJjbG9vcmRpZ3cwMDkxMDcza2M2cG9oeWFiIiwiYXBpS2V5SWQiOiJjbHc2NzFqOGowNHZsMDd6ZTczemEwdjJuIiwic2VjcmV0IjoiZjExOWVhZDk3MGVkM2ZhMGYyZjkzNGU2ZTFhOWMxMDYiLCJpYXQiOjE3MTU2NzkxMDYsImV4cCI6MjM0NjgzMTEwNn0.3lSmBkOVmbjIltAN1umf3H_pJ_HsptIhxs6v7kv1-Dc\")\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import uuid\n",
        "# Creates an empty project\n",
        "project = client.create_project(name=\"my-test-project\",\n",
        "                                description=\"a description\",\n",
        "                                media_type=lb.MediaType.Image)\n",
        "\n",
        "\n",
        "dataset = client.create_dataset(name=\"project-demo-dataset\")\n",
        "global_keys = []\n",
        "uploads = []\n",
        "# Generate data rows\n",
        "for i in range(1,9):\n",
        "    gb_key = \"TEST-ID-%id\" % uuid.uuid1()\n",
        "    uploads.append({\n",
        "        'row_data':  f\"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_000{i}.jpeg\",\n",
        "        \"global_key\": gb_key,\n",
        "    })\n",
        "    global_keys.append(gb_key)\n",
        "\n",
        "task = dataset.create_data_rows(uploads)\n",
        "task.wait_till_done()\n",
        "print(\"ERRORS: \" , task.errors)\n",
        "print(\"RESULT URL: \", task.result_url)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "project.create_batch(\n",
        "  \"project-demo\", # each batch in a project must have a unique name\n",
        "  global_keys=global_keys,  # paginated collection of data row objects, list of data row ids or global keys\n",
        "  priority=1 # priority between 1(highest) - 5(lowest)\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Create normalized json with a radio classification\n",
        "ontology_builder = lb.OntologyBuilder(classifications=[  # List of Classification objects\n",
        "        lb.Classification(class_type=lb.Classification.Type.RADIO,\n",
        "                          name=\"radio_question\",\n",
        "                          options=[\n",
        "                              lb.Option(value=\"first_radio_answer\"),\n",
        "                              lb.Option(value=\"second_radio_answer\")\n",
        "                          ]),\n",
        "])\n",
        "# Creating an ontology\n",
        "ontology = client.create_ontology(\"test-ontology\",\n",
        "                                  ontology_builder.asdict())\n",
        "\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Create labels\n",
        "labels = []\n",
        "for global_key in global_keys:\n",
        "    labels.append(lb_types.Label(data={\"global_key\":global_key},\n",
        "                   annotations=[\n",
        "                        # Create radio classification annotation for labels\n",
        "                        lb_types.ClassificationAnnotation(\n",
        "                         name=\"radio_question\",\n",
        "                         value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n",
        "                         name=\"second_radio_answer\")))\n",
        "                   ]))\n",
        "\n",
        "# Upload labels for the data rows in project\n",
        "upload_job = lb.LabelImport.create_from_objects(\n",
        "     client = client,\n",
        "     project_id = project.uid,\n",
        "     name=\"label_import_job\"+str(uuid.uuid4()),\n",
        "     labels=labels)\n",
        "\n",
        "upload_job.wait_until_done()\n",
        "\n",
        "print(f\"Errors: {upload_job.errors}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Create an empty destination project\n",
        "destination_project = client.create_project(name=\"destination-test-project\",\n",
        "                                description=\"a description\",\n",
        "                                media_type=lb.MediaType.Image)\n",
        "\n",
        "# Create ontology and attach to destination project\n",
        "destination_ontology_builder = lb.OntologyBuilder(classifications=[  # List of Classification objects\n",
        "        lb.Classification(class_type=lb.Classification.Type.RADIO,\n",
        "                          name=\"destination_radio_question\",\n",
        "                          options=[\n",
        "                              lb.Option(value=\"destination_first_radio_answer\"),\n",
        "                              lb.Option(value=\"destination_second_radio_answer\")\n",
        "                          ]),\n",
        "])\n",
        "\n",
        "destination_ontology = client.create_ontology(\"dest-test-ontology\",\n",
        "                                  ontology_builder.asdict())\n",
        "\n",
        "destination_project.setup_editor(destination_ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Get ontology dictionary to obtain featureSchemaIds\n",
        "source_ontology_normalized = ontology.normalized\n",
        "destination_ontology_normalized = destination_ontology.normalized\n",
        "\n",
        "ANNOTATION_ONTOLOGY_MAPPING = {\n",
        "    source_ontology_normalized[\"classifications\"][0][\"featureSchemaId\"]:destination_ontology_normalized[\"classifications\"][0][\"featureSchemaId\"], # Classification featureSchemaID\n",
        "    source_ontology_normalized[\"classifications\"][0][\"options\"][0][\"featureSchemaId\"]:destination_ontology_normalized[\"classifications\"][0][\"options\"][0][\"featureSchemaId\"], # Different Classification Answer featureSchemaIDs\n",
        "    source_ontology_normalized[\"classifications\"][0][\"options\"][1][\"featureSchemaId\"]:destination_ontology_normalized[\"classifications\"][0][\"options\"][1][\"featureSchemaId\"]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "send_to_annotate_params = {\n",
        "    \"source_project_id\": project.uid,\n",
        "    \"annotations_ontology_mapping\": ANNOTATION_ONTOLOGY_MAPPING,\n",
        "    \"exclude_data_rows_in_project\": False,\n",
        "    \"override_existing_annotations_rule\": ConflictResolutionStrategy.OverrideWithPredictions,\n",
        "    \"batch_priority\": 5,\n",
        "}\n",
        "\n",
        "# Get task id to workflow you want to send data rows. If sent to initial labeling queue, labels will be pre-labels. \n",
        "queue_id = [queue.uid for queue in destination_project.task_queues() if queue.queue_type == \"MANUAL_REVIEW_QUEUE\" ][0]\n",
        "\n",
        "task = client.send_to_annotate_from_catalog(\n",
        "    destination_project_id=destination_project.uid,\n",
        "    task_queue_id=queue_id, # ID of workflow task, set ID to None if you want to send data rows with labels to the Done queue.\n",
        "    batch_name=\"Prediction Import Demo Batch\",\n",
        "    data_rows=lb.GlobalKeys(\n",
        "        global_keys # Provide a list of global keys from source project\n",
        "    ),\n",
        "    params=send_to_annotate_params\n",
        "    )\n",
        "\n",
        "task.wait_till_done()\n",
        "\n",
        "print(f\"Errors: {task.errors}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}