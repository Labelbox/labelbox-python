{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/prediction_upload/video_predictions.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/blob/master/examples/prediction_upload/video_predictions.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Video Prediction Import \n",
        "* This notebook walks you through the process of uploading model predictions to a Model Run. This notebook provides an example for each supported prediction type for video assets.\n",
        "\n",
        "A Model Run is a container for the predictions, annotations and metrics of a specific experiment in your ML model development cycle.\n",
        "\n",
        "**Supported annotations that can be uploaded through the SDK**\n",
        "- Bounding box\n",
        "- Point\n",
        "- Polyline\n",
        "- Classification - radio\n",
        "- Classification - checklist\n",
        "- Classification - free text\n",
        "- Nested classifications \n",
        "\n",
        "**NOT** supported:\n",
        "- Polygons \n",
        "- Segmentation masks\n",
        "\n",
        "Please note that this list of unsupported annotations only refers to limitations for importing predictions into a model. For example, when using the Labelbox editor, segmentation masks can be created and edited on video assets but cannot be imported into a model run.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q \"labelbox[data]\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "import uuid"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Replace with your API Key \n",
        "Guides on [Create an API key](https://docs.labelbox.com/docs/create-an-api-key)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "API_KEY=\"\"\n",
        "client = lb.Client(API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Supported Predictions\n",
        "- Confidence scores are currently not supported for segment or frame annotations, which are required for bounding box, point, and line for video assets. For this tutorial, only the radio and checklist annotations will have confidence scores."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "####### Bounding box (frame specific) ###########\n",
        "\n",
        "# Confidence scores are not supported for frame specific bounding box annotations and VideoObjectAnnotation\n",
        "\n",
        "# bbox dimensions \n",
        "bbox_dm = {\n",
        "  \"top\":617,\n",
        "  \"left\":1371,\n",
        "  \"height\":419,\n",
        "  \"width\":505\n",
        "}\n",
        "\n",
        "# Python Annotation\n",
        "bbox_prediction = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=13,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm[\"left\"], y=bbox_dm[\"top\"]), # x = left, y = top \n",
        "          end=lb_types.Point(x=bbox_dm[\"left\"] + bbox_dm[\"width\"], y=bbox_dm[\"top\"] + bbox_dm[\"height\"]), # x= left + width , y = top + height\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=15,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm[\"left\"], y=bbox_dm[\"top\"]),\n",
        "          end=lb_types.Point(x=bbox_dm[\"left\"] + bbox_dm[\"width\"], y=bbox_dm[\"top\"] + bbox_dm[\"height\"]),\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=19,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm[\"left\"], y=bbox_dm[\"top\"]), \n",
        "          end=lb_types.Point(x=bbox_dm[\"left\"] + bbox_dm[\"width\"], y=bbox_dm[\"top\"] + bbox_dm[\"height\"]),\n",
        "      )\n",
        "  )\n",
        "]\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "bbox_prediction_ndjson = {\n",
        "    \"name\" : \"bbox_video\",\n",
        "    \"segments\" : [{\n",
        "        \"keyframes\" : [\n",
        "            {\n",
        "              \"frame\": 13,\n",
        "              \"bbox\" : bbox_dm \n",
        "           },\n",
        "           {\n",
        "              \"frame\": 15,\n",
        "              \"bbox\" : bbox_dm \n",
        "           },\n",
        "           {\n",
        "              \"frame\": 19,\n",
        "              \"bbox\" : bbox_dm \n",
        "           }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Point ########\n",
        "# Confidence score is not supported for VideoObjectAnnotation\n",
        "# Python Annotation\n",
        "point_prediction = [\n",
        "    lb_types.VideoObjectAnnotation(\n",
        "        name = \"point_video\",\n",
        "        keyframe=True,\n",
        "        frame=17,\n",
        "        value = lb_types.Point(x=660.134, y=407.926),\n",
        "        )\n",
        "]\n",
        "\n",
        "# NDJSON\n",
        "point_prediction_ndjson = {\n",
        "    \"name\": \"point_video\", \n",
        "    \"confidence\": 0.5,\n",
        "    \"segments\": [{\n",
        "        \"keyframes\": [{\n",
        "            \"frame\": 17,\n",
        "            \"point\" : {\n",
        "                \"x\": 660.134 ,\n",
        "                \"y\": 407.926\n",
        "            }\n",
        "        }]\n",
        "    }] \n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Polyline (frame specific) ########\n",
        "# confidence scores are not supported in polyline annotations\n",
        "\n",
        "# Python Annotation\n",
        "polyline_prediction = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=5,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=12,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=20,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=24,\n",
        "    segment_index=1,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=45,\n",
        "    segment_index=1,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  )\n",
        "  \n",
        "]\n",
        "\n",
        "# NDJSON\n",
        "polyline_prediction_ndjson = {\n",
        "  \"name\": \"line_video_frame\", \n",
        "  \"segments\": [\n",
        "      {\n",
        "        \"keyframes\": [\n",
        "          {\n",
        "            \"frame\": 5,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 100\n",
        "            },{\n",
        "              \"x\": 100,\n",
        "              \"y\": 190\n",
        "            },{\n",
        "              \"x\": 190,\n",
        "              \"y\": 220\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 12,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 280\n",
        "            },{\n",
        "              \"x\": 300,\n",
        "              \"y\": 380\n",
        "            },{\n",
        "              \"x\": 400,\n",
        "              \"y\": 460\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 20,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 180\n",
        "            },{\n",
        "              \"x\": 100,\n",
        "              \"y\": 200\n",
        "            },{\n",
        "              \"x\": 200,\n",
        "              \"y\": 260\n",
        "            }]\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"keyframes\": [\n",
        "          {\n",
        "            \"frame\": 24,\n",
        "            \"line\": [{\n",
        "              \"x\": 300,\n",
        "              \"y\": 310\n",
        "            },{\n",
        "              \"x\": 330,\n",
        "              \"y\": 430\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 45,\n",
        "            \"line\": [{\n",
        "              \"x\": 600,\n",
        "              \"y\": 810\n",
        "            },{\n",
        "              \"x\": 900,\n",
        "              \"y\": 930\n",
        "            }]\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Frame base classifications ########\n",
        "\n",
        "# Python Annotation\n",
        "radio_prediction = [\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"radio_class\", \n",
        "        frame=9,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Radio(answer = lb_types.ClassificationAnswer(\n",
        "          name = \"first_radio_answer\",\n",
        "          confidence=0.5 \n",
        "          ))\n",
        "    ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"radio_class\", \n",
        "        frame=15,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Radio(answer = lb_types.ClassificationAnswer(\n",
        "          name = \"first_radio_answer\",\n",
        "          confidence=0.5 \n",
        "          ))\n",
        "    )\n",
        "]\n",
        "\n",
        "checklist_prediction= [\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\",\n",
        "        frame=29,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"first_checklist_answer\",\n",
        "                    confidence=0.5 \n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=35,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"first_checklist_answer\",\n",
        "                    confidence=0.5 \n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=39, \n",
        "        segment_index=1,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"second_checklist_answer\",\n",
        "                    confidence=0.5 \n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=45, \n",
        "        segment_index=1,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                \n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"second_checklist_answer\",\n",
        "                    confidence=0.5 \n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        )\n",
        "]\n",
        "\n",
        "\n",
        "## NDJSON\n",
        "frame_radio_classification_prediction_ndjson = {\n",
        "    \"name\": \"radio_class\", \n",
        "    \"answer\": { \"name\": \"first_radio_answer\", \"frames\": [{\"start\": 9, \"end\": 15}]}\n",
        "}\n",
        "\n",
        "## frame specific\n",
        "frame_checklist_classification_prediction_ndjson = {\n",
        "    \"name\": \"checklist_class\", \n",
        "    \"answer\": [\n",
        "        { \"name\": \"first_checklist_answer\" , \"frames\": [{\"start\": 29, \"end\": 35 }]},\n",
        "        { \"name\": \"second_checklist_answer\", \"frames\": [{\"start\": 39, \"end\": 45 }]} \n",
        "  ]      \n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "####### Global Classifications ######### \n",
        "\n",
        "# Python Annotation\n",
        "## For global classifications use ClassificationAnnotation\n",
        "global_radio_prediction = [lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_class_global\",\n",
        "    value=lb_types.Radio(answer = lb_types.ClassificationAnswer(\n",
        "      name = \"first_radio_answer\",\n",
        "      confidence=0.5 \n",
        "      ))\n",
        ")]\n",
        "\n",
        "global_checklist_prediction=[lb_types.ClassificationAnnotation(\n",
        "  name=\"checklist_class_global\", \n",
        "  value=lb_types.Checklist(\n",
        "      answer = [\n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"first_checklist_answer\",\n",
        "            confidence=0.5 \n",
        "        ), \n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"second_checklist_answer\",\n",
        "            confidence=0.5 \n",
        "        )\n",
        "      ]\n",
        "    )\n",
        " )]\n",
        "\n",
        "# NDJSON\n",
        "global_radio_classification_ndjson = {\n",
        "    \"name\": \"radio_class_global\", \n",
        "    \"answer\": { \"name\": \"first_radio_answer\", \"confidence\": 0.5}\n",
        "}\n",
        "\n",
        "\n",
        "global_checklist_classification_ndjson = {\n",
        "    \"name\": \"checklist_class_global\", \n",
        "    \"answer\": [\n",
        "        { \"name\": \"first_checklist_answer\" , \"confidence\": 0.5},\n",
        "        { \"name\": \"second_checklist_answer\", \"confidence\": 0.5} \n",
        "  ]      \n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Nested Global Classification ########### \n",
        "\n",
        "# Python Annotation\n",
        "nested_radio_prediction =[lb_types.ClassificationAnnotation(\n",
        "  name=\"nested_radio_question\",\n",
        "  value=lb_types.Radio(\n",
        "    answer=lb_types.ClassificationAnswer(\n",
        "      name=\"first_radio_answer\",\n",
        "      confidence=0.5 ,\n",
        "      classifications=[\n",
        "        lb_types.ClassificationAnnotation(\n",
        "          name=\"sub_radio_question\",\n",
        "          value=lb_types.Radio(\n",
        "            answer=lb_types.ClassificationAnswer(\n",
        "              name=\"first_sub_radio_answer\",\n",
        "              confidence=0.5 \n",
        "            )\n",
        "          )\n",
        "        )\n",
        "      ]\n",
        "    )\n",
        "  )\n",
        ")]\n",
        "\n",
        "# NDJSON\n",
        "nested_radio_prediction_ndjson = {\n",
        "  \"name\": \"nested_radio_question\",\n",
        "  \"answer\": {\"name\": \"first_radio_answer\", \"confidence\": 0.5},\n",
        "  \"classifications\" : [\n",
        "    {\"name\": \"sub_radio_question\", \"answer\": {\"name\": \"first_sub_radio_answer\", \"confidence\": 0.5}}\n",
        "   ]\n",
        "}\n",
        "\n",
        "# Python Annotation\n",
        "nested_checklist_prediction = [lb_types.ClassificationAnnotation(\n",
        "  name=\"nested_checklist_question\",\n",
        "  value=lb_types.Checklist(\n",
        "    answer=[lb_types.ClassificationAnswer(\n",
        "      name=\"first_checklist_answer\",\n",
        "      confidence=0.5 ,\n",
        "      classifications=[\n",
        "        lb_types.ClassificationAnnotation(\n",
        "          name=\"sub_checklist_question\",\n",
        "          value=lb_types.Checklist(\n",
        "            answer=[lb_types.ClassificationAnswer(\n",
        "            name=\"first_sub_checklist_answer\",\n",
        "            confidence=0.5 \n",
        "          )]\n",
        "        ))\n",
        "      ]\n",
        "    )]\n",
        "  )\n",
        ")]\n",
        "\n",
        "# NDJSON\n",
        "nested_checklist_prediction_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\",\n",
        "      \"confidence\": 0.5,\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\",\n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\", \"confidence\": 0.5}\n",
        "        }\n",
        "      ]\n",
        "  }]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Classifications under frame base tools ##########\n",
        "# Confidence scores are not supported for frame specific bounding box annotations with sub-classifications\n",
        "\n",
        "# bounding box dimensions\n",
        "bbox_dm2 = {\n",
        "  \"top\": 146.0,\n",
        "  \"left\": 98.0,\n",
        "  \"height\": 382.0,\n",
        "  \"width\": 341.0\n",
        "}\n",
        "\n",
        "# Python Annotation \n",
        "frame_bbox_with_checklist_subclass_prediction = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_class\",  \n",
        "    keyframe=True,\n",
        "    frame=10,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm2[\"left\"], y=bbox_dm2[\"top\"]), # x = left, y = top \n",
        "          end=lb_types.Point(x=bbox_dm2[\"left\"] + bbox_dm2[\"width\"], y=bbox_dm2[\"top\"] + bbox_dm2[\"height\"]), # x= left + width , y = top + height\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_class\",  \n",
        "    keyframe=True,\n",
        "    frame=11,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm2[\"left\"], y=bbox_dm2[\"top\"]), \n",
        "          end=lb_types.Point(x=bbox_dm2[\"left\"] + bbox_dm2[\"width\"], y=bbox_dm2[\"top\"] + bbox_dm2[\"height\"]),\n",
        "      ),\n",
        "    classifications=[\n",
        "                lb_types.ClassificationAnnotation(\n",
        "                    name='checklist_class',\n",
        "                    value=lb_types.Checklist(answer=[lb_types.ClassificationAnswer(\n",
        "                        name=\"first_checklist_answer\",\n",
        "                        confidence=0.5 \n",
        "                    )])\n",
        "                )\n",
        "            ]\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_class\",  \n",
        "    keyframe=True,\n",
        "    frame=13,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm2[\"left\"], y=bbox_dm2[\"top\"]), \n",
        "          end=lb_types.Point(x=bbox_dm2[\"left\"] + bbox_dm2[\"width\"], y=bbox_dm2[\"top\"] + bbox_dm2[\"height\"]),\n",
        "      ),\n",
        "    classifications=[\n",
        "              lb_types.ClassificationAnnotation(\n",
        "                  name='checklist_class',\n",
        "                  value=lb_types.Checklist(answer=[lb_types.ClassificationAnswer(\n",
        "                      name=\"second_checklist_answer\",\n",
        "                      confidence=0.5 \n",
        "                  )])\n",
        "              )\n",
        "          ]\n",
        "  )\n",
        "]\n",
        "\n",
        "frame_bbox_with_checklist_subclass_prediction_ndjson = {\n",
        "    \"name\": \"bbox_class\",\n",
        "    \"segments\": [{\n",
        "        \"keyframes\": [\n",
        "            {\n",
        "            \"frame\": 10,\n",
        "            \"bbox\": bbox_dm2\n",
        "          },\n",
        "          {  \n",
        "          \"frame\": 11,\n",
        "            \"bbox\": bbox_dm2,\n",
        "            \"classifications\": [\n",
        "              {\n",
        "                \"name\": \"bbox_radio\",\n",
        "                \"answer\": [{\"name\": \"first_checklist_answer\", \"confidence\": 0.5}]\n",
        "              }\n",
        "            ]\n",
        "          },\n",
        "          {  \n",
        "          \"frame\": 13,\n",
        "            \"bbox\": bbox_dm2,\n",
        "            \"classifications\": [\n",
        "              {\n",
        "                \"name\": \"bbox_radio\",\n",
        "                \"answer\": [{\"name\": \"second_checklist_answer\", \"confidence\": 0.5}]\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######### Free text classification ###########\n",
        "text_prediction = [lb_types.ClassificationAnnotation(\n",
        "  name=\"free_text\",  # must match your ontology feature's name\n",
        "  value=lb_types.Text(answer=\"sample text\")\n",
        ")]\n",
        "\n",
        "text_prediction_ndjson = {\n",
        "  'name': 'free_text',\n",
        "  'answer': 'sample text',\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Import data rows into Catalog"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# send a sample image as batch to the project\n",
        "global_key = \"sample-video-2.mp4\"\n",
        "test_img_url = {\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/video-sample-data/sample-video-2.mp4\",\n",
        "    \"global_key\": global_key\n",
        "}\n",
        "dataset = client.create_dataset(\n",
        "    name=\"Video prediction demo\",\n",
        "    iam_integration=None # Removing this argument will default to the organziation's default iam integration\n",
        ")\n",
        "task = dataset.create_data_rows([test_img_url])\n",
        "task.wait_till_done()\n",
        "print(\"Errors: \",task.errors)\n",
        "print(\"Failed data rows: \",task.failed_data_rows)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There are errors present. Please look at `task.errors` for more details\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors:  Duplicate global keys found: sample-video-2.mp4\n",
            "Failed data rows:  [{'message': 'Duplicate global keys found: sample-video-2.mp4', 'failedDataRows': [{'globalKey': 'sample-video-2.mp4', 'rowData': 'https://storage.googleapis.com/labelbox-datasets/video-sample-data/sample-video-2.mp4', 'attachmentInputs': []}]}]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Create/select an Ontology for your model predictions\n",
        "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the name/instructions fields in your annotations to ensure the correct feature schemas are matched.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "ontology_builder = lb.OntologyBuilder(\n",
        "    tools=[\n",
        "        lb.Tool(tool=lb.Tool.Type.BBOX, name=\"bbox_video\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.POINT, name=\"point_video\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.LINE, name=\"line_video_frame\"),\n",
        "        lb.Tool(\n",
        "          tool=lb.Tool.Type.BBOX, name=\"bbox_class\",\n",
        "          classifications=[\n",
        "            lb.Classification(\n",
        "            class_type=lb.Classification.Type.CHECKLIST,\n",
        "            name=\"checklist_class\",\n",
        "            scope = lb.Classification.Scope.INDEX, ## defined scope for frame classifications\n",
        "            options=[ \n",
        "                lb.Option(value=\"first_checklist_answer\"),\n",
        "                lb.Option(value=\"second_checklist_answer\")\n",
        "            ]\n",
        "            )\n",
        "          ]\n",
        "        )\n",
        "    ],\n",
        "    classifications=[ \n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.CHECKLIST,\n",
        "            name=\"checklist_class\",\n",
        "            scope = lb.Classification.Scope.INDEX, ## defined scope for frame classifications\n",
        "            options=[ \n",
        "                lb.Option(value=\"first_checklist_answer\"),\n",
        "                lb.Option(value=\"second_checklist_answer\")\n",
        "            ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.RADIO,\n",
        "            name=\"radio_class\",\n",
        "            scope = lb.Classification.Scope.INDEX,\n",
        "            options=[ \n",
        "                lb.Option(value=\"first_radio_answer\"),\n",
        "                lb.Option(value=\"second_radio_answer\")\n",
        "            ]\n",
        "        ),\n",
        "         lb.Classification(\n",
        "              class_type=lb.Classification.Type.RADIO,\n",
        "              name=\"nested_radio_question\",\n",
        "              options=[\n",
        "                  lb.Option(\"first_radio_answer\",\n",
        "                        options=[\n",
        "                            lb.Classification(\n",
        "                                class_type=lb.Classification.Type.RADIO,\n",
        "                                name=\"sub_radio_question\",\n",
        "                                options=[lb.Option(\"first_sub_radio_answer\")]\n",
        "                            )\n",
        "                        ]\n",
        "                  )\n",
        "              ] \n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.CHECKLIST,\n",
        "          name=\"nested_checklist_question\",\n",
        "          options=[\n",
        "              lb.Option(\"first_checklist_answer\",\n",
        "                options=[\n",
        "                  lb.Classification(\n",
        "                      class_type=lb.Classification.Type.CHECKLIST,\n",
        "                      name=\"sub_checklist_question\",\n",
        "                      options=[lb.Option(\"first_sub_checklist_answer\")]\n",
        "                  )\n",
        "              ]\n",
        "            )\n",
        "          ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.RADIO, \n",
        "          name=\"radio_class_global\",\n",
        "          options=[ \n",
        "                lb.Option(value=\"first_radio_answer\"),\n",
        "                lb.Option(value=\"second_radio_answer\")\n",
        "            ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.CHECKLIST,\n",
        "          name=\"checklist_class_global\",\n",
        "          options=[\n",
        "                lb.Option(value=\"first_checklist_answer\"),\n",
        "                lb.Option(value=\"second_checklist_answer\")\n",
        "          ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.TEXT,\n",
        "          name=\"free_text\"\n",
        "        )\n",
        "    ]  \n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Ontology Video Annotations\", \n",
        "                                  ontology_builder.asdict(), \n",
        "                                  # media_type=lb.MediaType.Video\n",
        "                                  )"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Create a Model and Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# create Model\n",
        "model = client.create_model(name=\"video_model_run_\" + str(uuid.uuid4()), \n",
        "                            ontology_id=ontology.uid)\n",
        "# create Model Run\n",
        "model_run = model.create_model_run(\"iteration 1\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Send data rows to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "model_run.upsert_data_rows(global_keys=[global_key])"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 5. Create the predictions payload\n",
        "\n",
        "Create the annotations payload using the snippets of [code here](https://docs.labelbox.com/reference/import-video-annotations).\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### Python Annotation Types"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "label_predictions = []\n",
        "annotations_list = [\n",
        "    point_prediction,\n",
        "    bbox_prediction,\n",
        "    polyline_prediction, \n",
        "    checklist_prediction, \n",
        "    radio_prediction,\n",
        "    nested_radio_prediction,\n",
        "    nested_checklist_prediction,\n",
        "    frame_bbox_with_checklist_subclass_prediction,\n",
        "    global_radio_prediction,\n",
        "    global_checklist_prediction,\n",
        "    text_prediction\n",
        "      ]\n",
        "\n",
        "flatten_list_annotations = [ann for ann_sublist in annotations_list for ann in ann_sublist] \n",
        "\n",
        "label_predictions.append(\n",
        "    lb_types.Label(\n",
        "        data=lb_types.VideoData(global_key=global_key),\n",
        "        annotations = flatten_list_annotations\n",
        "    )\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### NDJSON annotations"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Label object by identifying the applicable data row in Labelbox and providing a list of annotations\n",
        "label_prediction_ndjson = []\n",
        "\n",
        "for annotation in [\n",
        "    point_prediction_ndjson,\n",
        "    bbox_prediction_ndjson,\n",
        "    polyline_prediction_ndjson, \n",
        "    frame_checklist_classification_prediction_ndjson, \n",
        "    frame_radio_classification_prediction_ndjson,\n",
        "    nested_radio_prediction_ndjson,\n",
        "    nested_checklist_prediction_ndjson,\n",
        "    frame_bbox_with_checklist_subclass_prediction_ndjson,\n",
        "    global_radio_classification_ndjson,\n",
        "    global_checklist_classification_ndjson,\n",
        "    text_prediction_ndjson\n",
        "]:      \n",
        "  annotation.update({\n",
        "      \"dataRow\": {\n",
        "          \"globalKey\": global_key\n",
        "      }\n",
        "  })\n",
        "  label_prediction_ndjson.append(annotation)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 6. Upload the predictions payload to the Model Run "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload the prediction label to the Model Run\n",
        "upload_job_prediction = model_run.add_predictions(\n",
        "    name=\"prediction_upload_job\"+str(uuid.uuid4()),\n",
        "    predictions=label_predictions)\n",
        "\n",
        "# Errors will appear for annotation uploads that failed.\n",
        "print(\"Errors:\", upload_job_prediction.errors)\n",
        "print(\"Status of uploads: \", upload_job_prediction.statuses)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n",
            "Status of uploads:  [{'uuid': 'f3c3293c-5827-4da9-952d-adb3fad63552', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'be0e6cd8-30b8-457e-ae31-d30664902599', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '7cc0f028-44ed-4f1e-bf54-24ac3421803c', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '9ab4bc56-5d28-4d96-8771-c71a68df408f', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '5926e8ae-b65c-42bf-a73c-db47906b6e58', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '9811f8cd-6153-4120-ab92-e0ecb0c94938', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'ae19473f-0c96-4db5-8451-f22666aacd2a', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '0ae42618-f5ea-4bba-a7c1-be50957229f8', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '563fb75d-b4de-40fd-9998-7c506a336659', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'abea4c77-3285-41bc-a807-5e0cbff8cc45', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'cb095e77-f6af-48dd-88e1-507e9cc8597f', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 7: Send annotations to the Model Run \n",
        "To send annotations to a Model Run, we must first import them into a project, create a label payload and then send them to the Model Run."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "##### 7.1. Create a labelbox project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Labelbox project\n",
        "project = client.create_project(name=\"video_prediction_demo\",\n",
        "                                    auto_audit_percentage=1,\n",
        "                                    auto_audit_number_of_labels=1,\n",
        "                                    media_type=lb.MediaType.Video)\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Default createProject behavior will soon be adjusted to prefer batch projects. Pass in `queue_mode` parameter explicitly to opt-out for the time being.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.2. Create a batch to send to the project "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "project.create_batch(\n",
        "  \"batch_video_prediction_demo\", # Each batch in a project must have a unique name\n",
        "  global_keys=[global_key], # A list of data rows, data row ids or global keys\n",
        "  priority=5 # priority between 1(Highest) - 5(lowest)\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Batch ID: 37ff67f0-f65d-11ed-8f97-c906b0175f82>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.3 Create the annotations payload"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Python Annotation\n",
        "point_annotation = [\n",
        "    lb_types.VideoObjectAnnotation(\n",
        "        name = \"point_video\",\n",
        "        keyframe=True,\n",
        "        frame=17,\n",
        "        value = lb_types.Point(x=660.134, y=407.926),\n",
        "        )\n",
        "]\n",
        "\n",
        "\n",
        "######## Polyline ########\n",
        "\n",
        "# Python Annotation\n",
        "polyline_annotation = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=5,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=12,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=20,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=24,\n",
        "    segment_index=1,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=45,\n",
        "    segment_index=1,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  )\n",
        "  \n",
        "]\n",
        "\n",
        "radio_annotation = [\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"radio_class\", \n",
        "        frame=9,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"first_radio_answer\"))\n",
        "    ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"radio_class\", \n",
        "        frame=15,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"first_radio_answer\"))\n",
        "    )\n",
        "]\n",
        "\n",
        "checklist_annotation= [\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\",\n",
        "        frame=29,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"first_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=35,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"first_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=39, \n",
        "        segment_index=1,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"second_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=45, \n",
        "        segment_index=1,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                \n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"second_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        )\n",
        "]\n",
        "\n",
        "global_radio_annotation = [lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_class_global\",\n",
        "    value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"first_radio_answer\"))\n",
        ")]\n",
        "\n",
        "global_checklist_annotation=[lb_types.ClassificationAnnotation(\n",
        "  name=\"checklist_class_global\", \n",
        "  value=lb_types.Checklist(\n",
        "      answer = [\n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"first_checklist_answer\"\n",
        "        ), \n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"second_checklist_answer\"\n",
        "        )\n",
        "      ]\n",
        "    )\n",
        " )]\n",
        "\n",
        "nested_radio_annotation =[lb_types.ClassificationAnnotation(\n",
        "  name=\"nested_radio_question\",\n",
        "  value=lb_types.Radio(\n",
        "    answer=lb_types.ClassificationAnswer(\n",
        "      name=\"first_radio_answer\",\n",
        "      classifications=[\n",
        "        lb_types.ClassificationAnnotation(\n",
        "          name=\"sub_radio_question\",\n",
        "          value=lb_types.Radio(\n",
        "            answer=lb_types.ClassificationAnswer(\n",
        "              name=\"first_sub_radio_answer\"\n",
        "            )\n",
        "          )\n",
        "        )\n",
        "      ]\n",
        "    )\n",
        "  )\n",
        ")]\n",
        "\n",
        "nested_checklist_annotation = [lb_types.ClassificationAnnotation(\n",
        "  name=\"nested_checklist_question\",\n",
        "  value=lb_types.Checklist(\n",
        "    answer=[lb_types.ClassificationAnswer(\n",
        "      name=\"first_checklist_answer\",\n",
        "      classifications=[\n",
        "        lb_types.ClassificationAnnotation(\n",
        "          name=\"sub_checklist_question\",\n",
        "          value=lb_types.Checklist(\n",
        "            answer=[lb_types.ClassificationAnswer(\n",
        "            name=\"first_sub_checklist_answer\"\n",
        "          )]\n",
        "        ))\n",
        "      ]\n",
        "    )]\n",
        "  )\n",
        ")]\n",
        "\n",
        "bbox_dm2 = {\n",
        "  \"top\": 146.0,\n",
        "  \"left\": 98.0,\n",
        "  \"height\": 382.0,\n",
        "  \"width\": 341.0\n",
        "}\n",
        "frame_bbox_with_checklist_subclass = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_class\",  \n",
        "    keyframe=True,\n",
        "    frame=10,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm2[\"left\"], y=bbox_dm2[\"top\"]), # x = left, y = top \n",
        "          end=lb_types.Point(x=bbox_dm2[\"left\"] + bbox_dm2[\"width\"], y=bbox_dm2[\"top\"] + bbox_dm2[\"height\"]), # x= left + width , y = top + height\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_class\",  \n",
        "    keyframe=True,\n",
        "    frame=11,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm2[\"left\"], y=bbox_dm2[\"top\"]), # x = left, y = top \n",
        "          end=lb_types.Point(x=bbox_dm2[\"left\"] + bbox_dm2[\"width\"], y=bbox_dm2[\"top\"] + bbox_dm2[\"height\"]), # x= left + width , y = top + height\n",
        "      ),\n",
        "    classifications=[\n",
        "                lb_types.ClassificationAnnotation(\n",
        "                    name=\"checklist_class\",\n",
        "                    value=lb_types.Checklist(answer=[lb_types.ClassificationAnswer(\n",
        "                        name=\"first_checklist_answer\",\n",
        "                        confidence=0.5 \n",
        "                    )])\n",
        "                )\n",
        "            ]\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_class\",  \n",
        "    keyframe=True,\n",
        "    frame=13,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm2[\"left\"], y=bbox_dm2[\"top\"]), # x = left, y = top \n",
        "          end=lb_types.Point(x=bbox_dm2[\"left\"] + bbox_dm2[\"width\"], y=bbox_dm2[\"top\"] + bbox_dm2[\"height\"]), # x= left + width , y = top + height\n",
        "      ),\n",
        "    classifications=[\n",
        "              lb_types.ClassificationAnnotation(\n",
        "                  name=\"checklist_class\",\n",
        "                  value=lb_types.Checklist(answer=[lb_types.ClassificationAnswer(\n",
        "                      name=\"second_checklist_answer\",\n",
        "                      confidence=0.5 \n",
        "                  )])\n",
        "              )\n",
        "          ]\n",
        "  )\n",
        "]\n",
        "\n",
        "\n",
        "bbox_dm = {\n",
        "  \"top\":617,\n",
        "  \"left\":1371,\n",
        "  \"height\":419,\n",
        "  \"width\":505\n",
        "}\n",
        "bbox_annotation = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=13,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm[\"left\"], y=bbox_dm[\"top\"]), # x = left, y = top \n",
        "          end=lb_types.Point(x=bbox_dm[\"left\"] + bbox_dm[\"width\"], y=bbox_dm[\"top\"] + bbox_dm[\"height\"]), # x= left + width , y = top + height\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=15,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm[\"left\"], y=bbox_dm[\"top\"]),\n",
        "          end=lb_types.Point(x=bbox_dm[\"left\"] + bbox_dm[\"width\"], y=bbox_dm[\"top\"] + bbox_dm[\"height\"]),\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=19,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=bbox_dm[\"left\"], y=bbox_dm[\"top\"]), \n",
        "          end=lb_types.Point(x=bbox_dm[\"left\"] + bbox_dm[\"width\"], y=bbox_dm[\"top\"] + bbox_dm[\"height\"]),\n",
        "      )\n",
        "  )\n",
        "]\n",
        "\n",
        "\n",
        "text_annotation = [lb_types.ClassificationAnnotation(\n",
        "  name=\"free_text\",  # must match your ontology feature's name\n",
        "  value=lb_types.Text(answer=\"sample text\")\n",
        ")]\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.4. Create the label object"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Label object by identifying the applicable data row in Labelbox and providing a list of annotations\n",
        "\n",
        "labels = []\n",
        "annotations_list = [\n",
        "          checklist_annotation, \n",
        "          radio_annotation,\n",
        "          bbox_annotation, \n",
        "          frame_bbox_with_checklist_subclass,\n",
        "          point_annotation, \n",
        "          polyline_annotation,\n",
        "          global_checklist_annotation,\n",
        "          global_radio_annotation,\n",
        "          nested_checklist_annotation,\n",
        "          nested_radio_annotation,\n",
        "          text_annotation\n",
        "      ]\n",
        "\n",
        "flatten_list_annotations = [ann for ann_sublist in annotations_list for ann in ann_sublist] \n",
        "\n",
        "labels.append(\n",
        "    lb_types.Label(\n",
        "        data=lb_types.VideoData(global_key=global_key),\n",
        "        annotations = flatten_list_annotations\n",
        "    )\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.5. Upload annotations to the project using Label Import"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_job_annotation = lb.LabelImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid,\n",
        "    name=\"video_annotations_import_\" + str(uuid.uuid4()),\n",
        "    labels=labels)\n",
        "\n",
        "upload_job_annotation.wait_until_done()\n",
        "# Errors will appear for annotation uploads that failed.\n",
        "print(\"Errors:\", upload_job_annotation.errors)\n",
        "print(\"Status of uploads: \", upload_job_annotation.statuses)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n",
            "Status of uploads:  [{'uuid': '18f75f9a-ae38-4839-9d1b-5d5ba79167d2', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'ea2e1890-09d5-45ad-a37d-895e89b7a7b8', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '92e329c5-4dea-4370-b7be-3ef8e65e9e5a', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '11c93223-b8bb-4ef6-9647-9bb28d605e51', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '807ae575-083c-4fcb-a876-312758df3238', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '5b6a07f6-e57f-49a4-a770-1d4dcbf95b41', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '8a49c009-367b-479b-a04e-59a4cc9459db', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'd8fde3b0-4224-4eff-ada9-724e9bfda18e', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '301e5050-81a5-4755-ad6a-ff7a77f4ef75', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '082f10ec-60d3-49ed-8475-1a7302dc703d', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '8b715636-fc08-4731-ba98-1fd8e64216e6', 'dataRow': {'id': 'clhpc7h2y11oa07cjfk2dg67d', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.6. Send the annotations to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# get the labels id from the project\n",
        "model_run.upsert_labels(project_id=project.uid)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Optional deletions for cleanup \n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# project.delete()\n",
        "# dataset.delete()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}