{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/prediction_upload/html_predictions.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/blob/master/examples/prediction_upload/html_predictions.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# HTML Prediction Import\n",
        "\n",
        "This notebook walks you through the process of uploading model predictions to a Model Run. This notebook provides an example for each supported prediction type for HTML assets.\n",
        "\n",
        "**Supported predictions**\n",
        "- Radio Classification \n",
        "- Checklist Classification\n",
        "- free-text Classification\n",
        "\n",
        "**Not supported:**\n",
        "- Bounding Box\n",
        "- Polygon\n",
        "- Point\n",
        "- Polyline\n",
        "- Masks\n",
        "- NER\n",
        "\n",
        "A Model Run is a container for the predictions, annotations and metrics of a specific experiment in your ML model development cycle."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q 'labelbox[data]'"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/187.7 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m \u001b[32m184.3/187.7 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m187.7/187.7 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pygeotile (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "import uuid\n",
        "import numpy as np"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Replace with your API Key \n",
        "Guides on [Create an API key](https://docs.labelbox.com/docs/create-an-api-key)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "API_KEY = None\n",
        "client = lb.Client(API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Supported Predictions"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "########### Radio Classification ###########\n",
        "radio_prediction = lb_types.ClassificationAnnotation(\n",
        "  name=\"radio_question\", \n",
        "  value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"second_radio_answer\", confidence=0.5))\n",
        ")\n",
        "\n",
        "\n",
        "radio_prediction_ndjson = {\n",
        "  'name': 'radio_question',\n",
        "  'answer': {'name': 'first_radio_answer'}\n",
        "}\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### Nested Classifications ######\n",
        "\n",
        "# Python annotation\n",
        "radio_prediction_nested = lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_question_sub\", \n",
        "    value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"first_radio_answer\", confidence=0.5)),\n",
        "    classifications=[\n",
        "    \tlb_types.ClassificationAnnotation(\n",
        "        \tname=\"sub_radio_question\",\n",
        "      \t\tvalue=lb_types.Radio(answer=lb_types.ClassificationAnswer(name=\"first_sub_radio_answer\", confidence=0.5))\n",
        "      )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "nested_radio_prediction_ndjson = {\n",
        "  'name': 'radio_question_sub',\n",
        "  'answer': {\n",
        "      'name': 'first_radio_answer',\n",
        "      \"confidence\": 0.5,\n",
        "      'classifications': [{\n",
        "          'name':'sub_radio_question',\n",
        "          'answer': { 'name' : 'first_sub_radio_answer', 'confidence': 0.5 }\n",
        "        }]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Nested classification for checklits is only supported with NDJSON tools\n",
        "nested_checklist_prediction_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\", \n",
        "      \"confidence\": 0.5,\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\", \n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\", \"confidence\": 0.5 }\n",
        "        }          \n",
        "      ]         \n",
        "  }]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Checklist ##########\n",
        "\n",
        "# Python annotation\n",
        "checklist_prediction = lb_types.ClassificationAnnotation(\n",
        "    name=\"checklist_question\",\n",
        "    value=lb_types.Checklist(\n",
        "        answer = [\n",
        "            lb_types.ClassificationAnswer(\n",
        "                name = \"first_checklist_answer\",\n",
        "                confidence=0.5\n",
        "            ),\n",
        "            lb_types.ClassificationAnswer(\n",
        "                name = \"second_checklist_answer\", \n",
        "                confidence=0.5\n",
        "            ),\n",
        "            lb_types.ClassificationAnswer(\n",
        "                name = \"third_checklist_answer\", \n",
        "                confidence=0.5\n",
        "            )\n",
        "    ])\n",
        "  )\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "checklist_prediction_ndjson = {\n",
        "  'name': 'checklist_question',\n",
        "  'confidence': 0.5,\n",
        "  'answer': [\n",
        "    {'name': 'first_checklist_answer', 'confidence': 0.5}\n",
        "  ]\n",
        "}\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Classification Free-Form text  ##########\n",
        "## Text classifications do not support confidence values\n",
        "# Python annotation\n",
        "text_prediction = lb_types.ClassificationAnnotation(\n",
        "    name = \"free_text\", \n",
        "    value = lb_types.Text(answer=\"sample text\")\n",
        ")\n",
        "\n",
        "#  NDJSON\n",
        "text_prediction_ndjson = {\n",
        "  'name': 'free_text',\n",
        "  'answer': 'sample text'\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Import data rows into Catalog"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# send a sample image as batch to the project\n",
        "test_img_url = {\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/html_sample_data/sample_html_2.html\",\n",
        "    \"global_key\": str(uuid.uuid4())\n",
        "}\n",
        "dataset = client.create_dataset(name=\"html demo dataset\")\n",
        "data_row = dataset.create_data_row(test_img_url)\n",
        "print(data_row)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<DataRow {\n",
            "    \"created_at\": \"2023-02-10 14:57:25+00:00\",\n",
            "    \"external_id\": null,\n",
            "    \"global_key\": \"1fdad0fa-98f3-4b86-a58d-775bb28b9f86\",\n",
            "    \"media_attributes\": {},\n",
            "    \"metadata\": [],\n",
            "    \"metadata_fields\": [],\n",
            "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/html_sample_data/sample_html_2.html\",\n",
            "    \"uid\": \"cldynkblw1iz107yc6czg20cn\",\n",
            "    \"updated_at\": \"2023-02-10 14:57:25+00:00\"\n",
            "}>\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Create/select an Ontology for your model predictions\n",
        "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the name/instructions fields in your annotations to ensure the correct feature schemas are matched.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup the ontology and link the tools created above.\n",
        "\n",
        "ontology_builder = lb.OntologyBuilder(\n",
        "  classifications=[ # List of Classification objects\n",
        "    lb.Classification( \n",
        "      class_type=lb.Classification.Type.RADIO, \n",
        "      name=\"radio_question\", \n",
        "      options=[lb.Option(value=\"first_radio_answer\")]\n",
        "    ),\n",
        "    lb.Classification( \n",
        "      class_type=lb.Classification.Type.RADIO, \n",
        "      name=\"radio_question_sub\", \n",
        "      options=[\n",
        "        lb.Option(value=\"first_radio_answer\",\n",
        "          options=[\n",
        "              lb.Classification(\n",
        "                class_type=lb.Classification.Type.RADIO,\n",
        "                name=\"sub_radio_question\",\n",
        "                options=[\n",
        "                  lb.Option(value=\"first_sub_radio_answer\")\n",
        "                ]\n",
        "            ),\n",
        "          ]\n",
        "        )\n",
        "      ],\n",
        "    ),\n",
        "    lb.Classification( \n",
        "      class_type=lb.Classification.Type.CHECKLIST, \n",
        "      name=\"checklist_question\", \n",
        "      options=[\n",
        "        lb.Option(value=\"first_checklist_answer\"),\n",
        "        lb.Option(value=\"second_checklist_answer\"), \n",
        "        lb.Option(value=\"third_checklist_answer\")            \n",
        "      ]\n",
        "    ), \n",
        "     lb.Classification( \n",
        "      class_type=lb.Classification.Type.TEXT,\n",
        "      name=\"free_text\"\n",
        "    ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.CHECKLIST, \n",
        "      name=\"nested_checklist_question\",\n",
        "      options=[\n",
        "          lb.Option(\"first_checklist_answer\",\n",
        "            options=[\n",
        "              lb.Classification(\n",
        "                  class_type=lb.Classification.Type.CHECKLIST, \n",
        "                  name=\"sub_checklist_question\", \n",
        "                  options=[lb.Option(\"first_sub_checklist_answer\")]\n",
        "              )\n",
        "          ]\n",
        "        )\n",
        "      ]\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Ontology HTML Predictions\", ontology_builder.asdict(), media_type=lb.MediaType.Html)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Create a Model and Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# create Model\n",
        "model = client.create_model(name=\"HTML_model_run_\" + str(uuid.uuid4()), \n",
        "                            ontology_id=ontology.uid)\n",
        "# create Model Run\n",
        "model_run = model.create_model_run(\"iteration 1\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Send data rows to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "model_run.upsert_data_rows([data_row.uid])"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 5. Create the predictions payload\n",
        "\n",
        "Create the annotations payload using the snippets of code in the **Supported Predictions** section.\n",
        "\n",
        "Labelbox support two formats for the annotations payload: NDJSON and Python Annotation types. Both are described below to compose your annotations into Labels attached to the data rows.\n",
        "\n",
        "The resulting label_ndjson should have exactly the same content for annotations that are supported by both (with exception of the uuid strings that are generated)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Label for predictions\n",
        "label_prediction = lb_types.Label(\n",
        "    data=lb_types.ImageData(uid=data_row.uid),\n",
        "    annotations = [\n",
        "      radio_prediction, \n",
        "      radio_prediction_nested,\n",
        "      checklist_prediction,\n",
        "      text_prediction\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create a label list \n",
        "label_list_prediction = [label_prediction]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "If using NDJSON: "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "\n",
        "ndjson_prediction_method2 = []\n",
        "for annot in [\n",
        "    radio_prediction_ndjson, \n",
        "    nested_radio_prediction_ndjson,\n",
        "    checklist_prediction_ndjson,\n",
        "    text_prediction_ndjson,\n",
        "    nested_checklist_prediction_ndjson\n",
        "]:\n",
        "  annot.update({\n",
        "      'uuid': str(uuid.uuid4()),\n",
        "      'dataRow': {'id': data_row.uid},\n",
        "  })\n",
        "  ndjson_prediction_method2.append(annot)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 6. Upload the predictions payload to the Model Run "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload the prediction label to the Model Run\n",
        "upload_job_prediction = model_run.add_predictions(\n",
        "    name=\"prediction_upload_job\"+str(uuid.uuid4()),\n",
        "    predictions=ndjson_prediction_method2)\n",
        "\n",
        "# Errors will appear for annotation uploads that failed.\n",
        "print(\"Errors:\", upload_job_prediction.errors)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 7: Send annotations to the Model Run \n",
        "To send annotations to a Model Run, we must first import them into a project, create a label payload and then send them to the Model Run."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "##### 7.1. Create a labelbox project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Labelbox project\n",
        "project = client.create_project(name=\"HTML prediction import demo\",                                    \n",
        "                                    queue_mode=lb.QueueMode.Batch,\n",
        "                                    # Quality Settings setup \n",
        "                                    auto_audit_percentage=1,\n",
        "                                    auto_audit_number_of_labels=1,\n",
        "                                    media_type=lb.MediaType.Html)\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.2. Create a batch to send to the project "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "project.create_batch(\n",
        "  \"batch_prediction_html\", # Each batch in a project must have a unique name\n",
        "  dataset.export_data_rows(), # A list of data rows or data row ids\n",
        "  5 # priority between 1(Highest) - 5(lowest)\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Batch ID: 48918730-a953-11ed-a337-239007885060>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.3 Create the annotations payload"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "######  Annotations ###### \n",
        "\n",
        "\n",
        "radio_annotation_ndjson = {\n",
        "  'name': 'radio_question',\n",
        "  'answer': {'name': 'first_radio_answer'}\n",
        "}\n",
        "\n",
        "\n",
        "nested_radio_annotation_ndjson = {\n",
        "  'name': 'radio_question_sub',\n",
        "  'answer': {\n",
        "      'name': 'first_radio_answer',\n",
        "      'classifications': [{\n",
        "          'name':'sub_radio_question',\n",
        "          'answer': { 'name' : 'first_sub_radio_answer'}\n",
        "        }]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "nested_checklist_annotation_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\", \n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\", \n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\" }\n",
        "        }          \n",
        "      ]         \n",
        "  }]\n",
        "}\n",
        "\n",
        "checklist_annotation_ndjson = {\n",
        "  'name': 'checklist_question',\n",
        "  'answer': [\n",
        "    {'name': 'first_checklist_answer', }\n",
        "  ]\n",
        "}\n",
        "\n",
        "\n",
        "text_annotation_ndjson = {\n",
        "  'name': 'free_text',\n",
        "  'answer': 'sample text'\n",
        "}\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.4. Create the label object"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "ndjson_annotation = []\n",
        "for annot in [\n",
        "    radio_annotation_ndjson,\n",
        "    nested_radio_annotation_ndjson,\n",
        "    nested_checklist_annotation_ndjson ,\n",
        "    checklist_annotation_ndjson,\n",
        "    text_annotation_ndjson\n",
        "  ]:\n",
        "  annot.update({\n",
        "      'uuid': str(uuid.uuid4()),\n",
        "      'dataRow': {'id': data_row.uid},\n",
        "  })\n",
        "  ndjson_annotation.append(annot)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.5. Upload annotations to the project using Label Import"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_job_annotation = lb.LabelImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid,\n",
        "    name=\"html_annotation_import\" + str(uuid.uuid4()),\n",
        "    labels=ndjson_annotation)\n",
        "\n",
        "upload_job_annotation.wait_until_done()\n",
        "# Errors will appear for annotation uploads that failed.\n",
        "print(\"Errors:\", upload_job_annotation.errors)\n"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.6 Send the annotations to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# get the labels id from the project\n",
        "label_ids = [x['ID'] for x in project.export_labels(download=True)]\n",
        "model_run.upsert_labels(label_ids)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Optional deletions for cleanup \n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# project.delete()\n",
        "# dataset.delete()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}