{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "db768cda",
      "metadata": {
        "id": "db768cda"
      },
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb5611d0",
      "metadata": {
        "id": "cb5611d0"
      },
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/annotation_types/basics.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/annotation_types/basics.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "incoming-linux",
      "metadata": {
        "id": "incoming-linux"
      },
      "source": [
        "## Annotation Types\n",
        "This is a common format for representing human and machine generated annotations. A standard interface allows us to build one set of tools that is compatible with all of our data. For example, if model predictions and labels are all represented by a common format we can write all of our etl, visualization code, training code to work with a single interface. Annotation types can also provide a seamless transition between local modeling and using labelbox. Some of the helper functions include:\n",
        "* Build annotations locally with local file paths, numpy arrays, or urls and create data rows with a single line of code\n",
        "* Easily upload model predictions for MAL or MEA by converting annotation objects to the import format\n",
        "* Configure project ontologies from a set of model inferences\n",
        "* Easily access video data without having to worry about downloading each frame's annotations.\n",
        "* Helper functions for drawing annotations, converting them into shapely objects, and much more."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "guilty-accreditation",
      "metadata": {
        "id": "guilty-accreditation"
      },
      "source": [
        "------- \n",
        "## Installation\n",
        "* Installing annotation types requires a slightly different pattern\n",
        "    - `pip install \"labelbox[data]\"`\n",
        "* `pip install labelbox` is still valid but it won't add the required dependencies. If you only want the client functionality of the SDK then don't add the [data] extras. However, you will likely get import errors if attempting to use the annotation types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "literary-qualification",
      "metadata": {
        "id": "literary-qualification"
      },
      "outputs": [],
      "source": [
        "# !pip install \"labelbox[data]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "latter-marina",
      "metadata": {
        "id": "latter-marina"
      },
      "source": [
        "## Imports\n",
        "* All annotation types can be imported from `labelbox.data.annotation_types`\n",
        "* Helper functions that are compatible with annotation types can be found under `labelbox.data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "productive-power",
      "metadata": {
        "id": "productive-power"
      },
      "outputs": [],
      "source": [
        "from labelbox.data.annotation_types import (\n",
        "    Label, ImageData, MaskData, LabelList, TextData, VideoData,\n",
        "    ObjectAnnotation, ClassificationAnnotation, Polygon, Rectangle, Line, Mask,\n",
        "    Point, Checklist, Radio, Text, TextEntity, ClassificationAnswer)\n",
        "from labelbox.schema.media_type import MediaType\n",
        "from labelbox import (LabelingFrontend, Client, OntologyBuilder, Tool,\n",
        "                      Classification, Option)\n",
        "from shapely.ops import transform\n",
        "from shapely.affinity import affine_transform\n",
        "import requests\n",
        "import IPython\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3150348b",
      "metadata": {
        "id": "3150348b"
      },
      "source": [
        "# API Key and Client\n",
        "Provide a valid api key below in order to properly connect to the Labelbox Client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selective-harrison",
      "metadata": {
        "id": "selective-harrison"
      },
      "outputs": [],
      "source": [
        "# Add your api key\n",
        "API_KEY = None\n",
        "client = Client(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "democratic-jerusalem",
      "metadata": {
        "id": "democratic-jerusalem"
      },
      "source": [
        "## Basic Introduction\n",
        "* Construct annotations, labels, and label collections to create a common representation for all data\n",
        "    * A `LabelCollection` is essentially a list or generator for working with a collection of Labels\n",
        "    * A `Label` is a type of data and its associated annotations. E.g. an image and image annotations\n",
        "    * An annotation is either an `ObjectAnnotation` or a `ClassificationAnnotation`. These annotations contain a name and a `Geometry`, `Classification`, or some `Text` data. They also support a classifications field for subclasses.\n",
        "* In addition to create common interfaces for reducing the amount of etl work, each of these types have a set of helper functions that make ML workflows much easier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "settled-atmosphere",
      "metadata": {
        "id": "settled-atmosphere"
      },
      "source": [
        "### Constructing Annotation Objects\n",
        "* Annotation objects can be created in one of three ways:\n",
        "1. Manually construct them - usually used for model inferences\n",
        "    - Covered in this notebook\n",
        "2. Export labels to an annotation generator\n",
        "    - `project.label_generator()`\n",
        "3. Use a converter to load from another format\n",
        "    - Covered in the converters.ipynb notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "terminal-implementation",
      "metadata": {
        "id": "terminal-implementation"
      },
      "source": [
        "### Basic LabelCollection\n",
        "* A Label collection is either a `labelList` or `LabelGenerator` containing `Labels`\n",
        "    * More on this in label_containers.ipynb\n",
        "* Each label contains:\n",
        "    1. Data\n",
        "    2. Annotations associated with that data\n",
        "* The individual data and annotations will be explained below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "valuable-objective",
      "metadata": {
        "id": "valuable-objective"
      },
      "outputs": [],
      "source": [
        "labels = [\n",
        "    Label(\n",
        "        data=ImageData(url=\"http://my-img.jpg\"),\n",
        "        annotations=[ObjectAnnotation(value=Point(x=10, y=10), name=\"target\")])\n",
        "]\n",
        "labels = LabelList(labels)  # or LabelList(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "circular-router",
      "metadata": {
        "id": "circular-router"
      },
      "source": [
        "* All models are pydantic models so we can easily convert all of our objects to dictionaries and view the schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "judicial-galaxy",
      "metadata": {
        "id": "judicial-galaxy"
      },
      "outputs": [],
      "source": [
        "labels[0].schema()\n",
        "labels[0].dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "neither-involvement",
      "metadata": {
        "id": "neither-involvement"
      },
      "source": [
        "# Data \n",
        "* There are three classes to represent data\n",
        "    * TextData\n",
        "    * VideoData\n",
        "    * ImageData\n",
        "* The data objects can be constructed from various representations\n",
        "    - remote (url, uri)\n",
        "    - disk ( file path)\n",
        "    - compressed (image bytes)\n",
        "    - memory ( numpy array )\n",
        "* Then the access pattern is consistent regardless of the format used to construct the object\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "associate-cutting",
      "metadata": {
        "id": "associate-cutting"
      },
      "source": [
        "### ImageData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "excellent-oakland",
      "metadata": {
        "id": "excellent-oakland"
      },
      "outputs": [],
      "source": [
        "# Data can be instantiated with any of the following\n",
        "image = ImageData(im_bytes=b'bytes')\n",
        "image = ImageData(arr=np.zeros((10, 10, 3)).astype(np.uint8))\n",
        "image = ImageData(file_path='/tmp/img.jpg')\n",
        "image_url = \"https://picsum.photos/id/1003/200/300\"\n",
        "image = ImageData(url=image_url)\n",
        "# All of these can access the numpy representation the same way:\n",
        "np_data = image.value\n",
        "\n",
        "im = Image.fromarray(np_data)\n",
        "im.resize((im.size[0] // 2, im.size[1] // 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "appropriate-harvey",
      "metadata": {
        "id": "appropriate-harvey"
      },
      "source": [
        "### TextData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "smart-pearl",
      "metadata": {
        "id": "smart-pearl"
      },
      "outputs": [],
      "source": [
        "# Text has the same access pattern as imagery.\n",
        "text = TextData(file_path=\"/tmp/some local file.txt\")\n",
        "text = TextData(text=\" some text content...\")\n",
        "text = TextData(url=\"https://filesamples.com/samples/document/txt/sample3.txt\")\n",
        "\n",
        "print(text.value[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "growing-seattle",
      "metadata": {
        "id": "growing-seattle"
      },
      "source": [
        "### VideoData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "looking-pharmacy",
      "metadata": {
        "id": "looking-pharmacy"
      },
      "outputs": [],
      "source": [
        "video_url = \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4\"\n",
        "\n",
        "video = VideoData(file_path=\"some video path.mp4\")\n",
        "video = VideoData(frames={1: np.zeros((32, 32, 3), dtype=np.uint8)})\n",
        "video = VideoData(url=video_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "closed-newcastle",
      "metadata": {
        "id": "closed-newcastle"
      },
      "outputs": [],
      "source": [
        "for idx, frame in video.value:\n",
        "    # Show every 50th frame\n",
        "    if idx % 50 == 0:\n",
        "        video_im = Image.fromarray(frame)\n",
        "        w, h = video_im.size\n",
        "        IPython.display.display(video_im.resize((w // 16, h // 16)))\n",
        "    if idx > 250:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "limiting-blackberry",
      "metadata": {
        "id": "limiting-blackberry"
      },
      "source": [
        "### Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "opposed-blackberry",
      "metadata": {
        "id": "opposed-blackberry"
      },
      "source": [
        "#### Adding data row information\n",
        "* This is not required ( and can be added at a later time but you can add data row information to your data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rising-grammar",
      "metadata": {
        "id": "rising-grammar"
      },
      "outputs": [],
      "source": [
        "td = TextData(text=\"some text\",\n",
        "              uid=\"ckrey6o07000008l50uk2gcr3\",\n",
        "              external_id=\"my_text_data_row\")\n",
        "rd = ImageData(url=image_url,\n",
        "               uid=\"ckrey7te2000108l5hl8564dr\",\n",
        "               external_id=\"my_raster_data_row\")\n",
        "vd = VideoData(url=video_url,\n",
        "               uid=\"ckrey7xef000208l57hwfgi3v\",\n",
        "               external_id=\"my_video_data_row\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dense-venice",
      "metadata": {
        "id": "dense-venice"
      },
      "source": [
        "#### Non-public urls\n",
        "* If the urls in your data is not publicly accessible you can override the fetching logic\n",
        "* For `TextData` and `ImageData` overwrite the following function and make sure it has the same signature. `data.fetch_remote(self) -> bytes`.\n",
        "* For `VideoData`, the signature is `VideoData.fetch_remote(self, local_path)`. This function needs to download the video file locally to that local_path to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exceptional-diary",
      "metadata": {
        "id": "exceptional-diary"
      },
      "outputs": [],
      "source": [
        "image.set_fetch_fn(lambda self: requests.get(self.url, headers={...}).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "contemporary-jacket",
      "metadata": {
        "id": "contemporary-jacket"
      },
      "source": [
        "# Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "protective-minute",
      "metadata": {
        "id": "protective-minute"
      },
      "source": [
        "* There are 4 types of annotations\n",
        "    1. `ObjectAnnotation`\n",
        "        - Objects with location information\n",
        "        - Annotations that are found in the object field of the labelbox export\n",
        "        - Classes: `Point`, `Polygon`, `Mask`, `Line`, `Rectangle`, `TextEntity`\n",
        "    2. `ClassificationAnnotation`\n",
        "        - Classifications that can apply to data or another annotation\n",
        "        - Classes: `Checklist`, `Radio`, `Text`, `Dropdown`\n",
        "    3. `VideoObjectAnnotation`\n",
        "        - Same as object annotation but there are extra fields for video information\n",
        "    4. `VideoClassificationAnnotation`\n",
        "        - Same as classification annotation but there are extra fields for video information    \n",
        "-------- \n",
        "* Create an annotation by providing the following:\n",
        "1. Value\n",
        "    - Must be either a `Geometry`, `TextEntity`, or `Classification`\n",
        "    - This is the same as a top level tool in labelbox\n",
        "2. Name or feature_schema_id\n",
        "    - This is the id that corresponds to a particular class or just simply the class name\n",
        "    - If uploading to labelbox this must match a field in an ontology.\n",
        "3. (Optional) Classifications \n",
        "    - List of `ClassificationAnnotations`. This self referencing field enables infinite nesting of classifications.\n",
        "    - Be careful with how you use the tool. Labelbox does not support nesting classifications\n",
        "    - E.g. you can have tool.classifications but not tool.classifications[0].classifications\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "humanitarian-inspection",
      "metadata": {
        "id": "humanitarian-inspection"
      },
      "source": [
        "### ObjectAnnotation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dynamic-fruit",
      "metadata": {
        "id": "dynamic-fruit"
      },
      "source": [
        "##### Point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hollow-bulletin",
      "metadata": {
        "id": "hollow-bulletin"
      },
      "outputs": [],
      "source": [
        "point_annotation = ObjectAnnotation(value=Point(x=5, y=3),\n",
        "                                    name=\"point class name\")\n",
        "\n",
        "point_annotation = ObjectAnnotation(\n",
        "    value=Point(x=5, y=3), feature_schema_id=\"ckrgcgl89000108jtggc9e687\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "endless-karen",
      "metadata": {
        "id": "endless-karen"
      },
      "source": [
        "##### Polygon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loose-buffer",
      "metadata": {
        "id": "loose-buffer"
      },
      "outputs": [],
      "source": [
        "# Given some polygon:\n",
        "xy_poly = [\n",
        "    [60, 161],\n",
        "    [67, 177],\n",
        "    [76, 180],\n",
        "    [77, 222],\n",
        "    [82, 246],\n",
        "    [78, 291],\n",
        "    [72, 300],\n",
        "    [87, 300],\n",
        "    [94, 244],\n",
        "    [103, 243],\n",
        "    [100, 269],\n",
        "    [90, 290],\n",
        "    [95, 296],\n",
        "    [104, 292],\n",
        "    [108, 272],\n",
        "    [111, 300],\n",
        "    [121, 300],\n",
        "    [117, 244],\n",
        "    [128, 236],\n",
        "    [133, 298],\n",
        "    [142, 297],\n",
        "    [137, 250],\n",
        "    [146, 208],\n",
        "    [138, 185],\n",
        "    [120, 180],\n",
        "    [105, 189],\n",
        "    [112, 162],\n",
        "    [93, 156],\n",
        "    [72, 160],\n",
        "]\n",
        "\n",
        "polygon_annotation = ObjectAnnotation(\n",
        "    value=Polygon(points=[Point(x=x, y=y) for x, y in xy_poly]),\n",
        "    name=\"polygon class name\")\n",
        "\n",
        "polygon_annotation = ObjectAnnotation(\n",
        "    value=Polygon(points=[Point(x=x, y=y) for x, y in xy_poly]),\n",
        "    feature_schema_id=\"ckrgcel71000008jtd9mn0szu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "improved-sharing",
      "metadata": {
        "id": "improved-sharing"
      },
      "source": [
        "##### Line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statistical-steering",
      "metadata": {
        "id": "statistical-steering"
      },
      "outputs": [],
      "source": [
        "xy_line = [[0, 0], [10, 5], [15, 5]]\n",
        "\n",
        "line_annotation = ObjectAnnotation(\n",
        "    value=Line(points=[Point(x=x, y=y) for x, y in xy_line]),\n",
        "    name=\"line class name\")\n",
        "\n",
        "line_annotation = ObjectAnnotation(\n",
        "    value=Line(points=[Point(x=x, y=y) for x, y in xy_line]),\n",
        "    feature_schema_id=\"ckrgcel71000008jtd9mn0szu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "consistent-april",
      "metadata": {
        "id": "consistent-april"
      },
      "source": [
        "##### Rectangle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "closing-determination",
      "metadata": {
        "id": "closing-determination"
      },
      "outputs": [],
      "source": [
        "start = Point(x=0, y=0)\n",
        "end = Point(x=5, y=10)\n",
        "\n",
        "rectangle_annotation = ObjectAnnotation(value=Rectangle(start=start, end=end),\n",
        "                                        name=\"rectangle class name\")\n",
        "\n",
        "rectangle_annotation = ObjectAnnotation(\n",
        "    value=Rectangle(start=start, end=end),\n",
        "    feature_schema_id=\"ckrgcel71000008jtd9mn0szu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prostate-earthquake",
      "metadata": {
        "id": "prostate-earthquake"
      },
      "source": [
        "##### Mask\n",
        "* The mask can be any ImageData object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "asian-gates",
      "metadata": {
        "id": "asian-gates"
      },
      "outputs": [],
      "source": [
        "mask_annotation = ObjectAnnotation(value=Mask(\n",
        "    mask=MaskData(arr=np.zeros((32, 32, 3), dtype=np.uint8)),\n",
        "    color=(255, 255, 255)),\n",
        "                                   name=\"mask class name\")\n",
        "\n",
        "mask_annotation = ObjectAnnotation(\n",
        "    value=Mask(mask=MaskData(arr=np.zeros((32, 32, 3), dtype=np.uint8)),\n",
        "               color=(255, 255, 255)),\n",
        "    feature_schema_id=\"ckrgcel71000008jtd9mn0szu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "agreed-short",
      "metadata": {
        "id": "agreed-short"
      },
      "source": [
        "* Multiple mask objects can reference the same mask to save memory and reduce the number of files that need to be uploaded (i.e. one seg mask for multiple classes).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "approved-klein",
      "metadata": {
        "id": "approved-klein"
      },
      "outputs": [],
      "source": [
        "raster_data = MaskData(arr=np.zeros((32, 32, 3), dtype=np.uint8))\n",
        "mask_annotation = ObjectAnnotation(value=Mask(mask=raster_data,\n",
        "                                              color=[255, 255, 255]),\n",
        "                                   name=\"eyes\")\n",
        "\n",
        "mask_annotation = ObjectAnnotation(value=Mask(mask=raster_data,\n",
        "                                              color=[0, 255, 255]),\n",
        "                                   name=\"nose\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rocky-seeker",
      "metadata": {
        "id": "rocky-seeker"
      },
      "source": [
        "* The Mask class support either RGB masks only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "japanese-extraction",
      "metadata": {
        "id": "japanese-extraction"
      },
      "outputs": [],
      "source": [
        "raster_data = MaskData(arr=np.zeros((32, 32, 3), dtype=np.uint8))\n",
        "mask_annotation = ObjectAnnotation(value=Mask(mask=raster_data,\n",
        "                                              color=(128, 255, 255)),\n",
        "                                   name=\"eye\")\n",
        "\n",
        "mask_annotation = ObjectAnnotation(value=Mask(mask=raster_data,\n",
        "                                              color=(255, 255, 255)),\n",
        "                                   name=\"nose\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "metric-coast",
      "metadata": {
        "id": "metric-coast"
      },
      "source": [
        "##### Text Entity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "representative-malpractice",
      "metadata": {
        "id": "representative-malpractice"
      },
      "outputs": [],
      "source": [
        "entity_annotation = ObjectAnnotation(value=TextEntity(start=10, end=12),\n",
        "                                     name=\"person\")\n",
        "\n",
        "entity_annotation = ObjectAnnotation(\n",
        "    value=TextEntity(start=10, end=12),\n",
        "    feature_schema_id=\"ckrgddyli000108mk0c0t9qya\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "close-collaboration",
      "metadata": {
        "id": "close-collaboration"
      },
      "source": [
        "##### Geometry Utilities\n",
        "* All of the previous objects except TextEntity inherit from the Geometry base class\n",
        "* They have the following properties and functions\n",
        "    1. draw(height width, kwargs)\n",
        "    2. shape - property\n",
        "    3. geometry - property"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "liquid-marsh",
      "metadata": {
        "id": "liquid-marsh"
      },
      "outputs": [],
      "source": [
        "polygon_annotation.value.shapely"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unnecessary-yeast",
      "metadata": {
        "id": "unnecessary-yeast"
      },
      "source": [
        "* Flip because shapely origin is different from image coords\n",
        "```\n",
        "      Shapely Coordinates           Image Coordinates\n",
        "           ------                        -------    \n",
        "                               0 → → Greater X → →\n",
        "    ↑                          ↓\n",
        "Greater Y                    ↓\n",
        "    ↑                       Greater Y\n",
        "    ↑                          ↓\n",
        "    0 → → Greater X → →\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fixed-priority",
      "metadata": {
        "id": "fixed-priority"
      },
      "outputs": [],
      "source": [
        "def flip_y_axis(poly, height):\n",
        "    return affine_transform(poly, [1, 0, 0, -1, 0, height])\n",
        "\n",
        "\n",
        "flip_y_axis(polygon_annotation.value.shapely, im.size[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "important-novel",
      "metadata": {
        "id": "important-novel"
      },
      "source": [
        "##### Shape to Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "split-planner",
      "metadata": {
        "id": "split-planner"
      },
      "outputs": [],
      "source": [
        "color = (255, 255, 255)\n",
        "np_mask = polygon_annotation.value.draw(height=im.size[1],\n",
        "                                        width=im.size[0],\n",
        "                                        color=color)\n",
        "Image.fromarray(np.hstack([np_mask, np_data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "static-narrow",
      "metadata": {
        "id": "static-narrow"
      },
      "source": [
        "##### Mask to Shape\n",
        "* Adds extra vertices to be as accurate as possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "young-herald",
      "metadata": {
        "id": "young-herald"
      },
      "outputs": [],
      "source": [
        "mask_annotation = Mask(mask=MaskData(arr=np_mask), color=color)\n",
        "\n",
        "flip_y_axis(mask_annotation.shapely, im.size[1])\n",
        "# Simplify with mask_annotation.shapely.simplify(<float> simplification error tolerance)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "awful-shareware",
      "metadata": {
        "id": "awful-shareware"
      },
      "source": [
        "#### Masks with multiple annotations\n",
        "* Since masks can contain multiple classes you can split them up by calling raster on an individual annotation.\n",
        "* E.g. eyes and nose for our deer image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colored-vermont",
      "metadata": {
        "id": "colored-vermont"
      },
      "outputs": [],
      "source": [
        "# Build a combined mask from polygons\n",
        "eye_color, nose_color = (255, 255, 255), (255, 0, 0)\n",
        "h, w = np_data.shape[:2]\n",
        "eyes = [\n",
        "    Polygon(points=[\n",
        "        Point(x=x, y=y) for x, y in [[82, 180], [83, 184], [88, 184], [86, 180]]\n",
        "    ]),\n",
        "    Polygon(points=[\n",
        "        Point(x=x, y=y)\n",
        "        for x, y in [[97, 182], [99, 184], [102, 183], [101, 180], [98, 180]]\n",
        "    ]),\n",
        "]\n",
        "eye_masks = np.max([eye.draw(height=h, width=w) for eye in eyes], axis=0)\n",
        "nose = Polygon(points=[\n",
        "    Point(x=x, y=y) for x, y in [[95, 192], [93, 197], [96, 198], [100, 197],\n",
        "                                 [100, 194], [100, 192], [96, 192]]\n",
        "])\n",
        "nose_mask = nose.draw(height=h, width=w, color=nose_color)\n",
        "# Picks the brighter color if there is overlap.\n",
        "# If you don't want overlap then just simply create separate masks\n",
        "np_seg_mask = np.max([nose_mask, eye_masks], axis=0)\n",
        "Image.fromarray(np.hstack([np_seg_mask, np_data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accredited-state",
      "metadata": {
        "id": "accredited-state"
      },
      "source": [
        "* Create two mask annotations from this one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "broadband-doubt",
      "metadata": {
        "id": "broadband-doubt"
      },
      "outputs": [],
      "source": [
        "mask_data = MaskData(arr=np_seg_mask)\n",
        "eye_mask = Mask(mask=mask_data, color=eye_color)\n",
        "nose_mask = Mask(mask=mask_data, color=nose_color)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "swiss-storm",
      "metadata": {
        "id": "swiss-storm"
      },
      "source": [
        "* Calling `mask.draw()` will return a mask with pixels equal to the specified color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "progressive-feeding",
      "metadata": {
        "id": "progressive-feeding"
      },
      "outputs": [],
      "source": [
        "eye_raster = eye_mask.draw()\n",
        "nose_raster = nose_mask.draw()\n",
        "Image.fromarray(np.hstack([eye_raster, nose_raster, np_data]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "institutional-montana",
      "metadata": {
        "id": "institutional-montana"
      },
      "source": [
        "### Classification Annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "split-stomach",
      "metadata": {
        "id": "split-stomach"
      },
      "source": [
        "#### Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "celtic-approval",
      "metadata": {
        "id": "celtic-approval"
      },
      "outputs": [],
      "source": [
        "text_annotation = ClassificationAnnotation(\n",
        "    name=\"my text class\", value=Text(answer=\"some text answer\"))\n",
        "\n",
        "text_annotation = ClassificationAnnotation(\n",
        "    feature_schema_id=\"my text class\", value=Text(answer=\"some text answer\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "silent-japan",
      "metadata": {
        "id": "silent-japan"
      },
      "source": [
        "#### Radio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "orange-liberty",
      "metadata": {
        "id": "orange-liberty"
      },
      "outputs": [],
      "source": [
        "radio_annotation = ClassificationAnnotation(\n",
        "    name=\"is dog\", value=Radio(answer=ClassificationAnswer(name=\"dog\")))\n",
        "\n",
        "radio_annotation = ClassificationAnnotation(\n",
        "    feature_schema_id=\"ckresqdg7000001jnb70v4zcc\",\n",
        "    value=Radio(answer=ClassificationAnswer(\n",
        "        feature_schema_id=\"ckrdy06ia000007ky94h04qlj\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "editorial-manual",
      "metadata": {
        "id": "editorial-manual"
      },
      "source": [
        "##### Checklist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "closing-federal",
      "metadata": {
        "id": "closing-federal"
      },
      "outputs": [],
      "source": [
        "checklist_annotation = ClassificationAnnotation(\n",
        "    feature_schema_id=\"ckrestd5g000101jnhudjf29a\",\n",
        "    value=Checklist(answer=[\n",
        "        ClassificationAnswer(feature_schema_id=\"ckrdy06ia000007ky94h04qlj\")\n",
        "    ]))\n",
        "\n",
        "checklist_annotation = ClassificationAnnotation(\n",
        "    name=\"weather\",\n",
        "    value=Checklist(answer=[ClassificationAnswer(name=\"cloudy\")]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "younger-sauce",
      "metadata": {
        "id": "younger-sauce"
      },
      "source": [
        "### Subclassifications\n",
        "* Objects can have nested classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "partial-mission",
      "metadata": {
        "id": "partial-mission"
      },
      "outputs": [],
      "source": [
        "subclass_annotation = ObjectAnnotation(\n",
        "    value=Polygon(points=[Point(x=x, y=y) for x, y in xy_poly]),\n",
        "    name=\"deer\",\n",
        "    classifications=[checklist_annotation, radio_annotation])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mathematical-brass",
      "metadata": {
        "id": "mathematical-brass"
      },
      "source": [
        "# Labels\n",
        "* Labels connect a list of annotations to data such as images, text, and video.\n",
        "* Labels have a convenient set of functions for dealing with that collection of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "legislative-blink",
      "metadata": {
        "id": "legislative-blink"
      },
      "outputs": [],
      "source": [
        "label = Label(data=ImageData(url=image_url),\n",
        "              annotations=[\n",
        "                  ObjectAnnotation(value=Polygon(\n",
        "                      points=[Point(x=x, y=y) for x, y in xy_poly]),\n",
        "                                   name=\"deer\"),\n",
        "                  ObjectAnnotation(name=\"deer_eyes\",\n",
        "                                   value=Mask(mask=MaskData(arr=np_mask),\n",
        "                                              color=color))\n",
        "              ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "headed-preservation",
      "metadata": {
        "id": "headed-preservation"
      },
      "source": [
        "### Interacting with labelbox:\n",
        "* For this label to be compatible with labelbox we need the following:\n",
        "    - all named features must have feature_schema_ids\n",
        "    - all data must have urls\n",
        "        - masks\n",
        "        - images\n",
        "        - videos\n",
        "        - text\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "honey-behavior",
      "metadata": {
        "id": "honey-behavior"
      },
      "source": [
        "### Uploading Urls\n",
        "* It doesn't matter how urls are set\n",
        "* Manually setting urls or use helper functions are both valid for working with labelbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sized-trash",
      "metadata": {
        "id": "sized-trash"
      },
      "outputs": [],
      "source": [
        "# Manually set just by adding a value:\n",
        "image = ImageData(arr=np_data)\n",
        "image.url = \"http://myurl\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "express-indiana",
      "metadata": {
        "id": "express-indiana"
      },
      "source": [
        "* Use functions to upload urls:\n",
        "    - Upload image urls : `Label.add_url_to_data(signer)`\n",
        "    - Upload segmentation masks : `label.add_url_to_masks(signer)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gross-blond",
      "metadata": {
        "id": "gross-blond"
      },
      "source": [
        "----- \n",
        "* Define the signer\n",
        "    - Creating urls requires a function that maps bytes to a str (url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "incomplete-annotation",
      "metadata": {
        "id": "incomplete-annotation"
      },
      "outputs": [],
      "source": [
        "def signing_function(obj_bytes: bytes) -> str:\n",
        "    # Do not use this signer. You will not be able to resign these images at a later date\n",
        "    url = client.upload_data(content=obj_bytes, sign=True)\n",
        "    return url"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "genuine-milan",
      "metadata": {
        "id": "genuine-milan"
      },
      "source": [
        "* Create a complex label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "actual-noise",
      "metadata": {
        "id": "actual-noise"
      },
      "outputs": [],
      "source": [
        "label = Label(\n",
        "    data=ImageData(arr=np_data),\n",
        "    annotations=[\n",
        "        ObjectAnnotation(\n",
        "            name=\"deer_nose\",\n",
        "            value=nose_mask,\n",
        "            classifications=[\n",
        "                ClassificationAnnotation(\n",
        "                    name=\"description\",\n",
        "                    value=Radio(answer=ClassificationAnswer(name=\"wet\")))\n",
        "            ]),\n",
        "        ObjectAnnotation(name=\"deer_eyes\", value=eye_mask),\n",
        "        ObjectAnnotation(\n",
        "            value=Polygon(points=[Point(x=x, y=y) for x, y in xy_poly]),\n",
        "            name=\"deer\"),\n",
        "        ClassificationAnnotation(name=\"image_description\",\n",
        "                                 value=Checklist(answer=[\n",
        "                                     ClassificationAnswer(name=\"bright\"),\n",
        "                                     ClassificationAnswer(name=\"not_blurry\"),\n",
        "                                 ])),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "precise-murray",
      "metadata": {
        "id": "precise-murray"
      },
      "source": [
        "* Check that the image does not have a url\n",
        "* Add the url\n",
        "* Check that the url was added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "retired-canadian",
      "metadata": {
        "id": "retired-canadian"
      },
      "outputs": [],
      "source": [
        "print(\"Before\", label.data.url)\n",
        "label.add_url_to_data(signing_function)\n",
        "print(\"After\", label.data.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "right-outdoors",
      "metadata": {
        "id": "right-outdoors"
      },
      "source": [
        "* Masks also need urls for annotation imports\n",
        "* Note that the url is the same when uploaded.\n",
        "    - The url is only uploaded once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tested-premises",
      "metadata": {
        "id": "tested-premises"
      },
      "outputs": [],
      "source": [
        "# We also have a mask that needs a url:\n",
        "mask_annotations = [\n",
        "    annot for annot in label.annotations if isinstance(annot.value, Mask)\n",
        "]\n",
        "for annot in mask_annotations:\n",
        "    print(f\"{annot.name} before\", annot.value.mask.url)\n",
        "\n",
        "label.add_url_to_masks(signing_function)\n",
        "\n",
        "for annot in mask_annotations:\n",
        "    print(f\"{annot.name} after\", annot.value.mask.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "neutral-disabled",
      "metadata": {
        "id": "neutral-disabled"
      },
      "source": [
        "### Creating Data Rows\n",
        "* `Labels` objects are great for working with locally but we might want to upload to labelbox\n",
        "* This is required for MAL, MEA, and to add additional labels to the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "explicit-interval",
      "metadata": {
        "id": "explicit-interval"
      },
      "outputs": [],
      "source": [
        "dataset = client.create_dataset(name=\"label_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "equivalent-plain",
      "metadata": {
        "id": "equivalent-plain"
      },
      "outputs": [],
      "source": [
        "# Note that the signing function is only used if a url is not already provided\n",
        "print(label.data.uid)\n",
        "label.create_data_row(dataset, signing_function)\n",
        "print(label.data.uid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "literary-steam",
      "metadata": {
        "id": "literary-steam"
      },
      "source": [
        "### Assigning Schema Ids:\n",
        "* All tools, classifications, and options either have names or feature_schema_ids.\n",
        "* Locally it is convenient to provide a name so that we don't need a labelbox project to use these interfaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bearing-logan",
      "metadata": {
        "id": "bearing-logan"
      },
      "outputs": [],
      "source": [
        "# When uploading for MAL or MEA we need an ontology.\n",
        "# So let's create one\n",
        "\n",
        "# These names have to match our object names exactly!!\n",
        "ontology_builder = OntologyBuilder(tools=[\n",
        "    Tool(tool=Tool.Type.POLYGON, name=\"deer\"),\n",
        "    Tool(tool=Tool.Type.SEGMENTATION,\n",
        "         name=\"deer_nose\",\n",
        "         classifications=[\n",
        "             Classification(class_type=Classification.Type.RADIO,\n",
        "                            instructions=\"description\",\n",
        "                            options=[Option(value=\"wet\")])\n",
        "         ]),\n",
        "    Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_eyes\")\n",
        "],\n",
        "                                   classifications=[\n",
        "                                       Classification(\n",
        "                                           Classification.Type.CHECKLIST,\n",
        "                                           instructions=\"image_description\",\n",
        "                                           options=[\n",
        "                                               Option(value=\"bright\"),\n",
        "                                               Option(value=\"not_blurry\"),\n",
        "                                               Option(value=\"dark\")\n",
        "                                           ])\n",
        "                                   ])\n",
        "\n",
        "editor = next(\n",
        "    client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
        "project = client.create_project(name=\"test_annotation_types\", media_type=MediaType.Image)\n",
        "project.setup(editor, ontology_builder.asdict())\n",
        "project.datasets.connect(dataset)\n",
        "\n",
        "ontology = OntologyBuilder.from_project(project)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "special-prerequisite",
      "metadata": {
        "id": "special-prerequisite"
      },
      "source": [
        "### Next Steps\n",
        "* Annotation types should be thought of as low level interfaces\n",
        "* We are working on a set of tools to make working with annotation types less verbose. Please provide any feedback!\n",
        "* Checkout other notebooks to see how to use higher level tools that are compatible with these interfaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "expired-bryan",
      "metadata": {
        "id": "expired-bryan"
      },
      "outputs": [],
      "source": [
        "# Cleanup\n",
        "dataset.delete()\n",
        "project.delete()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
