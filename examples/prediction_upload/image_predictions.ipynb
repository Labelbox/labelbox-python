{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6a048e8-b5fe-418b-aec4-829b5b6802e5"
   },
   "source": [
    "<td>\n",
    "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51cf1362-1cde-4749-aac7-5fb94473baa7"
   },
   "source": [
    "\n",
    "<td>\n",
    "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/prediction_upload/image_predictions.ipynb\" target=\"_blank\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<a href=\"https://github.com/Labelbox/labelbox-python/blob/develop/examples/prediction_upload/image_predictions.ipynb\" target=\"_blank\"><img\n",
    "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Prediction Import\n",
    "\n",
    "* This notebook walks you through the process of uploading model predictions to a Model Run. This notebook provides an example for each supported prediction type for image assets. \n",
    "\n",
    "A Model Run is a container for the predictions, annotations and metrics of a specific experiment in your ML model development cycle.\n",
    "\n",
    "**Supported annotations that can be uploaded through the SDK**\n",
    "\n",
    "- Bounding box \n",
    "- Polygon\n",
    "- Point\n",
    "- Polyline \n",
    "- Classification free-text\n",
    "- Classification - radio\n",
    "- Classification - checklist\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "9znxMjDYGi0Y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Notes:\n",
    "    * If you are importing more than 1,000 mask predictions at a time, consider submitting separate jobs, as they can take longer than other prediction types to import.\n",
    "    * After the execution of this notebook a complete Model Run with predictions will be created in your organization. "
   ],
   "metadata": {
    "id": "8uOiTLI413Kj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "id": "UtJHIuE8HDRI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q 'labelbox[data]'"
   ],
   "metadata": {
    "id": "cm8xMaLbGb7v"
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import labelbox as lb\n",
    "import labelbox.data.annotation_types as lb_types\n",
    "import labelbox.data.serialization as lb_serializers\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "# from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "# from labelbox import Client, MALPredictionImport, LabelImport\n",
    "# from labelbox.data.serialization import NDJsonConverter\n",
    "# from labelbox.schema.media_type import MediaType\n",
    "# from labelbox.data.annotation_types import (\n",
    "#     Label, ImageData, ObjectAnnotation, MaskData,\n",
    "#     Rectangle, Point, Line, Mask, Polygon,\n",
    "#     Radio, Checklist, Text,\n",
    "#     ClassificationAnnotation, ClassificationAnswer\n",
    "# )\n",
    "# import uuid\n",
    "# import numpy as np\n",
    "# from labelbox.schema.queue_mode import QueueMode"
   ],
   "metadata": {
    "id": "NIq-6M9kHKSs"
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replace with your API Key \n",
    "Guides on [Create an API key](https://docs.labelbox.com/docs/create-an-api-key)"
   ],
   "metadata": {
    "id": "pZ2rBqY8HQoe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3R1NGZ0N28zeHZxMHk2dDd6NGtoa3R5Iiwib3JnYW5pemF0aW9uSWQiOiJja3R1NGZ0N2UzeHZwMHk2dGd2MjRkOW13IiwiYXBpS2V5SWQiOiJjbGR0MHdvdnQyOG8wMDcxaDN4N2oyNGNvIiwic2VjcmV0IjoiYmM0NWI5YjRkYmUxYTQyYWU5MWQyMzIyZGQzOGNlYWIiLCJpYXQiOjE2NzU3MDA2NjAsImV4cCI6MjMwNjg1MjY2MH0.XI5JRU-lA21yjkZFPqTIgKmpZpgdR0XB3e-bcsr_q2s\"\n",
    "client = lb.Client(API_KEY)"
   ],
   "metadata": {
    "id": "z7ZLKLYLHP__"
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supported Predictions"
   ],
   "metadata": {
    "id": "OePiibbed0nG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########### Radio Classification ###########\n",
    "\n",
    "# Python annotation\n",
    "radio_prediction = lb_types.ClassificationAnnotation(\n",
    "    name=\"radio_question\", \n",
    "    value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"second_radio_answer\", confidence=0.5))\n",
    ")\n",
    "\n",
    "# NDJSON\n",
    "radio_prediction_ndjson = {\n",
    "  'name': 'radio_question',\n",
    "  'answer': {'name': 'second_radio_answer', 'confidence': 0.5}\n",
    "} "
   ],
   "metadata": {
    "id": "v5wL6oojz9Ge"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Nested Classifications are only supported with NDJSON tools ##########\n",
    "\n",
    "nested_radio_prediction_ndjson = {\n",
    "  \"name\": \"nested_radio_question\",\n",
    "  \"confidence\": 0.5 ,\n",
    "  \"answer\": { \"name\": \"first_radio_answer\", \"confidence\": 0.5 },\n",
    "      \"classifications\" : [\n",
    "      {\n",
    "        \"name\": \"sub_radio_question\", \n",
    "        \"answer\": {\"name\": \"first_sub_radio_answer\", \"confidence\": 0.5 }\n",
    "      }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "nested_checklist_prediction_ndjson = {\n",
    "  \"name\": \"nested_checklist_question\",\n",
    "  \"confidence\": 0.5 ,\n",
    "  \"answer\": [{\n",
    "      \"name\": \"first_checklist_answer\", \n",
    "      \"confidence\": 0.5,\n",
    "      \"classifications\" : [\n",
    "        {\n",
    "          \"name\": \"sub_checklist_question\", \n",
    "          \"answer\": {\"name\": \"first_sub_checklist_answer\", \"confidence\": 0.5 }\n",
    "        }          \n",
    "      ]         \n",
    "  }]\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "id": "I75K-wx7_sDs"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "############ Checklist ############\n",
    "\n",
    "# Python Annotations\n",
    "checklist_prediction = lb_types.ClassificationAnnotation(\n",
    "  name=\"checklist_question\", # must match your ontology feature's name\n",
    "  value=lb_types.Checklist(\n",
    "      answer = [\n",
    "        lb_types.ClassificationAnswer(\n",
    "            name = \"first_checklist_answer\", \n",
    "            confidence=0.5\n",
    "        ), \n",
    "        lb_types.ClassificationAnswer(\n",
    "            name = \"second_checklist_answer\", \n",
    "            confidence=0.5\n",
    "        )\n",
    "      ]\n",
    "    )\n",
    " )\n",
    "\n",
    "# NDJSON\n",
    "checklist_prediction_ndjson = {\n",
    "  'name': 'checklist_question',\n",
    "  'answer': [\n",
    "    {'name': 'first_checklist_answer' , 'confidence': 0.5},\n",
    "    {'name': 'second_checklist_answer', 'confidence': 0.5}\n",
    "  ]\n",
    "}"
   ],
   "metadata": {
    "id": "b2UjSoYez9I1"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "####### Bounding box #######\n",
    "\n",
    "\n",
    "# Python Annotation \n",
    "bbox_prediction = lb_types.ObjectAnnotation(\n",
    "  name = \"bounding_box\",  # must match your ontology feature's name\n",
    "  confidence=0.5, \n",
    "  value=lb_types.Rectangle(\n",
    "        start=lb_types.Point(x=977, y=1690), # Top left\n",
    "        end=lb_types.Point(x=330, y=225), # Bottom right\n",
    "    ),\n",
    "  \n",
    ")\n",
    "\n",
    "#NDJSON \n",
    "bbox_prediction_ndjson = {\n",
    "  'name': 'bounding_box', \n",
    "  'confidence': 0.5,\n",
    "  'bbox': {\n",
    "          \"top\": 977,\n",
    "          \"left\": 1690,\n",
    "          \"height\": 330,\n",
    "          \"width\": 225\n",
    "      }\n",
    "}\n"
   ],
   "metadata": {
    "id": "xCU4JRP0z9Nh"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "####### Bounding box with nested classification #######\n",
    "bbox_with_radio_subclass_prediction = lb_types.ObjectAnnotation(\n",
    "    name=\"bbox_with_radio_subclass\",\n",
    "    confidence=0.5, # must match your ontology feature's name\n",
    "    value=lb_types.Rectangle(\n",
    "        start=lb_types.Point(x=933, y=541), # Top left\n",
    "        end=lb_types.Point(x=191, y=330), # Bottom right\n",
    "    ),\n",
    "    classifications=[\n",
    "    \tlb_types.ClassificationAnnotation(\n",
    "        \tname=\"sub_radio_question\",\n",
    "      \t\tvalue=lb_types.Radio(answer=lb_types.ClassificationAnswer(name=\"first_sub_radio_answer\", confidence=0.5))\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "## NDJSON\n",
    "bbox_with_radio_subclass_prediction_ndjson = {\n",
    "    \"name\": \"bbox_with_radio_subclass\", \n",
    "    \"confidence\": 0.5,\n",
    "    \"classifications\": [{\n",
    "        \"name\": \"sub_radio_question\",\n",
    "        \"confidence\": 0.5,\n",
    "        \"answer\": \n",
    "            { \"name\":\"first_sub_radio_answer\", \"confidence\": 0.5}\n",
    "         \n",
    "    }],\n",
    "    \"bbox\": {\n",
    "          \"top\": 933,\n",
    "          \"left\": 541,\n",
    "          \"height\": 191,\n",
    "          \"width\": 330\n",
    "        }\n",
    "}"
   ],
   "metadata": {
    "id": "gAIzsxEjLmhv"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Polygon ##########\n",
    "# Python Anotation \n",
    "polygon_prediction = lb_types.ObjectAnnotation(\n",
    "  name = \"polygon\",  # must match your ontology feature's name \n",
    "  confidence = 0.5, \n",
    "  value=lb_types.Polygon( # Coordinates for the verticies of your polygon\n",
    "        points=[lb_types.Point(x=1489.581,y=183.934), lb_types.Point(x=2278.306,y=256.885), lb_types.Point(x=2428.197,y=200.437), lb_types.Point(x=2560.0,y=335.419),\n",
    "                lb_types.Point(x=2557.386,y=503.165), lb_types.Point(x=2320.596,y=503.103), lb_types.Point(x=2156.083, y=628.943), lb_types.Point(x=2161.111,y=785.519),\n",
    "                lb_types.Point(x=2002.115, y=894.647), lb_types.Point(x=1838.456,y=877.874), lb_types.Point(x=1436.53,y=874.636), lb_types.Point(x=1411.403,y=758.579),\n",
    "                lb_types.Point(x=1353.853,y=751.74), lb_types.Point(x=1345.264, y=453.461), lb_types.Point(x=1426.011,y=421.129)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# NDJSON\n",
    "\n",
    "polygon_prediction_ndjson = {\n",
    "  'name': 'polygon',\n",
    "  'confidence': 0.5,\n",
    "  'polygon': [\n",
    "    {'x': 1489.581, 'y': 183.934},\n",
    "    {'x': 2278.306, 'y': 256.885},\n",
    "    {'x': 2428.197, 'y': 200.437},\n",
    "    {'x': 2560.0, 'y': 335.419},\n",
    "    {'x': 2557.386, 'y': 503.165},\n",
    "    {'x': 2320.596, 'y': 503.103},\n",
    "    {'x': 2156.083, 'y': 628.943},\n",
    "    {'x': 2161.111, 'y': 785.519},\n",
    "    {'x': 2002.115, 'y': 894.647},\n",
    "    {'x': 1838.456, 'y': 877.874},\n",
    "    {'x': 1436.53, 'y': 874.636},\n",
    "    {'x': 1411.403, 'y': 758.579},\n",
    "    {'x': 1353.853, 'y': 751.74},\n",
    "    {'x': 1345.264, 'y': 453.461},\n",
    "    {'x': 1426.011, 'y': 421.129},\n",
    "    {'x': 1489.581, 'y': 183.934}\n",
    "  ]\n",
    "}"
   ],
   "metadata": {
    "id": "jRwfE4MFz9Ph"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "####### Free text #######\n",
    "# Confidence is not supported for text prediction\n",
    "# Python annotation\n",
    "text_annotation = lb_types.ClassificationAnnotation(\n",
    "  name=\"free_text\",  # must match your ontology feature's name\n",
    "  value=lb_types.Text(answer=\"sample text\")\n",
    ")\n",
    "\n",
    "# NDJSON\n",
    "text_annotation_ndjson = {\n",
    "  'name': 'free_text',\n",
    "  'answer': 'sample text',\n",
    "}"
   ],
   "metadata": {
    "id": "PBB37YpWTiVR"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "######### Segmentation mask #########\n",
    "\n",
    "# Python \n",
    "# Identifying what values in the numpy array correspond to the mask annotation\n",
    "color = (0, 0, 0)\n",
    "\n",
    "# convert a polygon to mask\n",
    "im_height, im_width = 100,100 #need to provide the height and width of image.\n",
    "mask_data = lb_types.MaskData(arr=\n",
    "                     polygon_prediction.value.draw(height=im_height,width=im_width,color=color))\n",
    "\n",
    "# convert a 2D array to 3D array\n",
    "arr_2d = np.zeros((100,100), dtype='uint8')\n",
    "mask_data = lb_types.MaskData.from_2D_arr(arr_2d)\n",
    "\n",
    "# a 3D array where 3rd axis is RGB values.\n",
    "mask_data = lb_types.MaskData(arr= np.zeros([400,450,3],dtype='uint8'))\n",
    "\n",
    "mask_prediction = lb_types.ObjectAnnotation(\n",
    "  name = \"mask\", # must match your ontology feature's name\n",
    "  confidence=0.5,\n",
    "  value=lb_types.Mask(mask=mask_data, color=color),\n",
    ")\n",
    "\n",
    "\n",
    "# NDJSON\n",
    "mask_prediction_ndjson = {\n",
    "  'name': 'mask',\n",
    "  'confidence': 0.5,\n",
    "  'classifications': [],\n",
    "  'mask': {'instanceURI': 'https://storage.labelbox.com/cjhfn5y6s0pk507024nz1ocys%2F1d60856c-59b7-3060-2754-83f7e93e0d01-1?Expires=1666901963361&KeyName=labelbox-assets-key-3&Signature=t-2s2DB4YjFuWEFak0wxYqfBfZA',\n",
    "  'colorRGB': (0, 0, 0)}\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "id": "39vz-tYsz9Ry"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "######## Point ########\n",
    "\n",
    "# Python Annotation\n",
    "point_prediction = lb_types.ObjectAnnotation(\n",
    "  name = \"point\",  # must match your ontology feature's name\n",
    "  confidence=0.5,\n",
    "  value = lb_types.Point(x=1166.606, y=1441.768),\n",
    ")\n",
    "\n",
    "\n",
    "# NDJSON\n",
    "point_prediction_ndjson = {\n",
    "  'name': 'point',\n",
    "  'confidence': 0.5,\n",
    "  'classifications': [],\n",
    "  'point': {'x': 1166.606, 'y': 1441.768}\n",
    "}"
   ],
   "metadata": {
    "id": "UelSiWN2z9Tg"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "###### Polyline ######\n",
    "\n",
    "\n",
    "# Python Annotation \n",
    "\n",
    "polyline_prediction = lb_types.ObjectAnnotation(\n",
    "  name = \"polyline\", # must match your ontology feature's name\n",
    "  confidence=0.5, ## Not supported for python annotation tools\n",
    "  value=lb_types.Line( # Coordinates for the keypoints in your polyline\n",
    "        points=[lb_types.Point(x=2534.353, y=249.471), lb_types.Point(x=2429.492, y=182.092), lb_types.Point(x=2294.322, y=221.962), lb_types.Point(x=2224.491, y=180.463), lb_types.Point(x=2136.123, y=204.716),\n",
    "                lb_types.Point(x=1712.247, y=173.949), lb_types.Point(x=1703.838, y=84.438), lb_types.Point(x=1579.772, y=82.61), lb_types.Point(x=1583.442, y=167.552),\n",
    "                lb_types.Point(x=1478.869, y=164.903), lb_types.Point(x=1418.941, y=318.149), lb_types.Point(x=1243.128, y=400.815), lb_types.Point(x=1022.067, y=319.007),\n",
    "                lb_types.Point(x=892.367, y=379.216), lb_types.Point(x=670.273, y=364.408), lb_types.Point(x=613.114, y=288.16), lb_types.Point(x=377.559, y=238.251),\n",
    "                lb_types.Point(x=368.087, y=185.064), lb_types.Point(x=246.557, y=167.286), lb_types.Point(x=236.648, y=285.61), lb_types.Point(x=90.929, y=326.412)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# NDJSON\n",
    "polyline_prediction_ndjson = {\n",
    "  'name': 'polyline',\n",
    "  'confidence':0.5,\n",
    "  'classifications': [],\n",
    "  'line': [\n",
    "    {'x': 2534.353, 'y': 249.471},\n",
    "    {'x': 2429.492, 'y': 182.092},\n",
    "    {'x': 2294.322, 'y': 221.962},\n",
    "    {'x': 2224.491, 'y': 180.463},\n",
    "    {'x': 2136.123, 'y': 204.716},\n",
    "    {'x': 1712.247, 'y': 173.949},\n",
    "    {'x': 1703.838, 'y': 84.438},\n",
    "    {'x': 1579.772, 'y': 82.61},\n",
    "    {'x': 1583.442, 'y': 167.552},\n",
    "    {'x': 1478.869, 'y': 164.903},\n",
    "    {'x': 1418.941, 'y': 318.149},\n",
    "    {'x': 1243.128, 'y': 400.815},\n",
    "    {'x': 1022.067, 'y': 319.007},\n",
    "    {'x': 892.367, 'y': 379.216},\n",
    "    {'x': 670.273, 'y': 364.408},\n",
    "    {'x': 613.114, 'y': 288.16},\n",
    "    {'x': 377.559, 'y': 238.251},\n",
    "    {'x': 368.087, 'y': 185.064},\n",
    "    {'x': 246.557, 'y': 167.286},\n",
    "    {'x': 236.648, 'y': 285.61},\n",
    "    {'x': 90.929, 'y': 326.412}\n",
    "  ]\n",
    "}\n"
   ],
   "metadata": {
    "id": "mrjb8qY3z9VY"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Import data rows into Catalog"
   ],
   "metadata": {
    "id": "U-o15yu9IPDo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# send a sample image as batch to the project\n",
    "test_img_url = {\n",
    "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/2560px-Kitano_Street_Kobe01s5s4110.jpeg\",\n",
    "    \"global_key\": str(uuid.uuid4())\n",
    "}\n",
    "dataset = client.create_dataset(name=\"image_prediction_demo\")\n",
    "data_row = dataset.create_data_row(test_img_url)\n",
    "print(data_row)"
   ],
   "metadata": {
    "id": "HjH9gTV8IBG9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "800b120e-c41e-4f6f-a509-8d089f3e20bc"
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DataRow {\n",
      "    \"created_at\": \"2023-02-06 19:48:47+00:00\",\n",
      "    \"external_id\": null,\n",
      "    \"global_key\": \"6abbb998-54a7-4c2d-afba-0c2837de0a22\",\n",
      "    \"media_attributes\": {},\n",
      "    \"metadata\": [],\n",
      "    \"metadata_fields\": [],\n",
      "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/2560px-Kitano_Street_Kobe01s5s4110.jpeg\",\n",
      "    \"uid\": \"cldt87lp10pnc07yjdwua8p97\",\n",
      "    \"updated_at\": \"2023-02-06 19:48:47+00:00\"\n",
      "}>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Create/select an Ontology for your model predictions\n",
    "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the name/instructions fields in your annotations to ensure the correct feature schemas are matched.\n"
   ],
   "metadata": {
    "id": "oy0umzuNIceP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ontology_builder = lb.OntologyBuilder(\n",
    "  classifications=[ # List of Classification objects\n",
    "    lb.Classification( # Radio classification given the name \"text\" with two options: \"first_radio_answer\" and \"second_radio_answer\"\n",
    "      class_type=lb.Classification.Type.RADIO,\n",
    "      instructions=\"radio_question\", \n",
    "      options=[\n",
    "        lb.Option(value=\"first_radio_answer\"),\n",
    "        lb.Option(value=\"second_radio_answer\")\n",
    "      ]\n",
    "    ),\n",
    "    lb.Classification( # Checklist classification given the name \"text\" with two options: \"first_checklist_answer\" and \"second_checklist_answer\"\n",
    "      class_type=lb.Classification.Type.CHECKLIST,\n",
    "      instructions=\"checklist_question\", \n",
    "      options=[\n",
    "        lb.Option(value=\"first_checklist_answer\"),\n",
    "        lb.Option(value=\"second_checklist_answer\")\n",
    "      ]\n",
    "    ), \n",
    "    lb.Classification( # Text classification given the name \"text\"\n",
    "      class_type=lb.Classification.Type.TEXT,\n",
    "      instructions=\"free_text\"\n",
    "    ),\n",
    "    lb.Classification(\n",
    "        class_type=lb.Classification.Type.RADIO,\n",
    "        instructions=\"nested_radio_question\",\n",
    "        options=[\n",
    "            lb.Option(\"first_radio_answer\",\n",
    "                options=[\n",
    "                    lb.Classification(\n",
    "                        class_type=lb.Classification.Type.RADIO,\n",
    "                        instructions=\"sub_radio_question\",\n",
    "                        options=[lb.Option(\"first_sub_radio_answer\")]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "          ] \n",
    "        ),\n",
    "    lb.Classification(\n",
    "      class_type=lb.Classification.Type.CHECKLIST,\n",
    "      instructions=\"nested_checklist_question\",\n",
    "      options=[\n",
    "          lb.Option(\"first_checklist_answer\",\n",
    "            options=[\n",
    "              lb.Classification(\n",
    "                  class_type=lb.Classification.Type.CHECKLIST,\n",
    "                  instructions=\"sub_checklist_question\", \n",
    "                  options=[lb.Option(\"first_sub_checklist_answer\")]\n",
    "              )\n",
    "          ]\n",
    "        )\n",
    "      ]\n",
    "    ),      \n",
    "  ],\n",
    "  tools=[ # List of Tool objects\n",
    "    lb.Tool( # Bounding Box tool given the name \"box\"\n",
    "      tool=lb.Tool.Type.BBOX,\n",
    "      name=\"bounding_box\"), \n",
    "    lb.Tool( # Bounding Box tool given the name \"box\"\n",
    "      tool=lb.Tool.Type.BBOX,\n",
    "      name=\"bbox_with_radio_subclass\",\n",
    "      classifications=[\n",
    "            lb.Classification(\n",
    "                class_type=lb.Classification.Type.RADIO,\n",
    "                instructions=\"sub_radio_question\",\n",
    "                options=[\n",
    "                  lb.Option(value=\"first_sub_radio_answer\")\n",
    "                ]\n",
    "              ),\n",
    "        ]\n",
    "      ), \n",
    "    lb.Tool( # Polygon tool given the name \"polygon\"\n",
    "      tool=lb.Tool.Type.POLYGON,\n",
    "      name=\"polygon\"),\n",
    "    lb.Tool( # Segmentation mask tool given the name \"mask\"\n",
    "      tool=lb.Tool.Type.SEGMENTATION,\n",
    "      name=\"mask\"),\n",
    " \t  lb.Tool( # Point tool given the name \"point\"\n",
    "      tool=lb.Tool.Type.POINT,\n",
    "      name=\"point\"), \n",
    "    lb.Tool( # Polyline tool given the name \"line\"\n",
    "      tool=lb.Tool.Type.LINE,\n",
    "      name=\"polyline\")]\n",
    ")\n",
    "\n",
    "ontology = client.create_ontology(\"Image Prediction Import Demo\", ontology_builder.asdict(), media_type=lb.MediaType.Image)"
   ],
   "metadata": {
    "id": "Kt4XWWqgIiWk"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Create a Model and Model Run"
   ],
   "metadata": {
    "id": "ZjN8jxHvIvHP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# create Model\n",
    "model = client.create_model(name=\"image_model_run_\" + str(uuid.uuid4()),\n",
    "                            ontology_id=ontology.uid)\n",
    "# create Model Run\n",
    "model_run = model.create_model_run(\"iteration 1\")"
   ],
   "metadata": {
    "id": "8n-AvzdiOR6d"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Send data rows to the Model Run"
   ],
   "metadata": {
    "id": "NX6L0axRJN5J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_run.upsert_data_rows([data_row.uid])"
   ],
   "metadata": {
    "id": "6sngCgIwJSae",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4eb2e619-1139-49c5-a9e7-d29838336c05"
   },
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5. Create the predictions payload\n",
    "\n",
    "Create the prediction payload using the snippets of code in ***Supported Predictions*** section. \n",
    "\n",
    "The resulting label_ndjson should have exactly the same content for predictions that are supported by both (with exception of the uuid strings that are generated)"
   ],
   "metadata": {
    "id": "6FZyvnrqSGuc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a Label for predictions\n",
    "label_prediction = lb_types.Label(\n",
    "    data=lb_types.ImageData(uid=data_row.uid),\n",
    "    annotations = [\n",
    "      radio_prediction,\n",
    "      checklist_prediction, \n",
    "      bbox_prediction, \n",
    "      bbox_with_radio_subclass_prediction, \n",
    "      polygon_prediction, \n",
    "      mask_prediction, \n",
    "      point_prediction,\n",
    "      text_annotation\n",
    "      ]\n",
    ")\n",
    "\n",
    "# Create a label list \n",
    "label_list_prediction = [label_prediction]\n",
    "\n",
    "# Convert the prediction label from a Labelbox class object to the underlying NDJSON format required for upload - uploads can be directly built in this syntax as well\n",
    "ndjson_prediction = list(lb_serializers.NDJsonConverter.serialize(label_list_prediction))"
   ],
   "metadata": {
    "id": "zv2OLTXKSGWv"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "If using NDJSON:"
   ],
   "metadata": {
    "id": "HaIjOzZggv56"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ndjson_prediction_method2 = []\n",
    "\n",
    "for annot in [\n",
    "    radio_prediction_ndjson,\n",
    "    checklist_prediction_ndjson, \n",
    "    bbox_prediction_ndjson, \n",
    "    bbox_with_radio_subclass_prediction_ndjson, \n",
    "    polygon_prediction_ndjson, \n",
    "    mask_prediction_ndjson, \n",
    "    point_prediction_ndjson,\n",
    "    polyline_prediction_ndjson,\n",
    "    text_annotation_ndjson, \n",
    "    nested_radio_prediction_ndjson,\n",
    "    nested_checklist_prediction_ndjson\n",
    "]:\n",
    "  annot.update({\n",
    "      'uuid': str(uuid.uuid4()),\n",
    "      'dataRow': {'id': data_row.uid},\n",
    "  })\n",
    "  ndjson_prediction_method2.append(annot)"
   ],
   "metadata": {
    "id": "F-Y7sSyAV3tn"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6. Upload the predictions payload to the Model Run "
   ],
   "metadata": {
    "id": "viFHCnBeTD1Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Upload the prediction label to the Model Run\n",
    "upload_job_prediction = model_run.add_predictions(\n",
    "    name=\"prediction_upload_job\"+str(uuid.uuid4()),\n",
    "    predictions=ndjson_prediction_method2)\n",
    "\n",
    "# Errors will appear for prediction uploads that failed.\n",
    "print(\"Errors:\",  upload_job_prediction.errors)"
   ],
   "metadata": {
    "id": "0VN3ZRzyb4cl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c6ab8349-c327-49df-e3f6-00e06370c7e3"
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: []\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 7: Send annotations to a model run\n",
    "To visualize both annotations and predictions in the model run we will create a project with ground truth annotations. \n",
    "To send annotations to a Model Run, we must first import them into a project, create a label payload and then send them to the Model Run."
   ],
   "metadata": {
    "id": "T-ZHWWI3JgmX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 7.1. Create a labelbox project"
   ],
   "metadata": {
    "id": "CYRiqHr2O_aL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a Labelbox project\n",
    "project = client.create_project(name=\"image_prediction_demo\",\n",
    "                                    # Quality Settings setup \n",
    "                                    auto_audit_percentage=1,\n",
    "                                    auto_audit_number_of_labels=1,\n",
    "                                    media_type=lb.MediaType.Image)\n",
    "project.setup_editor(ontology)"
   ],
   "metadata": {
    "id": "jEtoDiDrPFvI"
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default createProject behavior will soon be adjusted to prefer batch projects. Pass in `queue_mode` parameter explicitly to opt-out for the time being.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 7.2. Create a batch to send to the project "
   ],
   "metadata": {
    "id": "7FEyC-nBPPuD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "project.create_batch(\n",
    "  \"batch_predictions_demo\", # Each batch in a project must have a unique name\n",
    "  dataset.export_data_rows(), # A list of data rows or data row ids\n",
    "  5 # priority between 1(Highest) - 5(lowest)\n",
    ")"
   ],
   "metadata": {
    "id": "WRr5tdVEPXXy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "262e1be8-3e43-42dd-ac99-e47378f9a705"
   },
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Batch ID: ba07c3b0-a657-11ed-a4f2-7f189fdbf63d>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 7.3 Create the annotations payload"
   ],
   "metadata": {
    "id": "FTGAI730UlZ3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########### Annotations ###########\n",
    "radio_annotation_ndjson = {\n",
    "  'name': 'radio_question',\n",
    "  'answer': {'name': 'second_radio_answer'}\n",
    "} \n",
    "\n",
    "nested_radio_annotation_ndjson = {\n",
    "  \"name\": \"nested_radio_question\",\n",
    "  \"answer\": {\"name\": \"first_radio_answer\"},\n",
    "  \"classifications\" : [\n",
    "   {'name': 'sub_radio_question', 'answer': {'name': 'first_sub_radio_answer'}}\n",
    "   ]\n",
    "}\n",
    "\n",
    "checklist_annotation_ndjson = {\n",
    "  'name': 'checklist_question',\n",
    "  'answer': [\n",
    "    {'name': 'first_checklist_answer'},\n",
    "    {'name': 'second_checklist_answer'}\n",
    "  ]\n",
    "}\n",
    "\n",
    "bbox_annotation_ndjson = {\n",
    "  'name': 'bounding_box',\n",
    "  'bbox': {\n",
    "          \"top\": 977,\n",
    "          \"left\": 1690,\n",
    "          \"height\": 330,\n",
    "          \"width\": 225\n",
    "      }\n",
    "}\n",
    "\n",
    "bbox_with_radio_subclass_ndjson = {\n",
    "    \"name\": \"bbox_with_radio_subclass\", \n",
    "    \"classifications\": [{\n",
    "        \"name\": \"sub_radio_question\",\n",
    "        \"answer\": \n",
    "            { \"name\":\"first_sub_radio_answer\" }\n",
    "         \n",
    "    }],\n",
    "    \"bbox\": {\n",
    "          \"top\": 933,\n",
    "          \"left\": 541,\n",
    "          \"height\": 191,\n",
    "          \"width\": 330\n",
    "        }\n",
    "}\n",
    "\n",
    "polygon_annotation_ndjson = {\n",
    "  'name': 'polygon',\n",
    "  'polygon': [\n",
    "    {'x': 1489.581, 'y': 183.934},\n",
    "    {'x': 2278.306, 'y': 256.885},\n",
    "    {'x': 2428.197, 'y': 200.437},\n",
    "    {'x': 2560.0, 'y': 335.419},\n",
    "    {'x': 2557.386, 'y': 503.165},\n",
    "    {'x': 2320.596, 'y': 503.103},\n",
    "    {'x': 2156.083, 'y': 628.943},\n",
    "    {'x': 2161.111, 'y': 785.519},\n",
    "    {'x': 2002.115, 'y': 894.647},\n",
    "    {'x': 1838.456, 'y': 877.874},\n",
    "    {'x': 1436.53, 'y': 874.636},\n",
    "    {'x': 1411.403, 'y': 758.579},\n",
    "    {'x': 1353.853, 'y': 751.74},\n",
    "    {'x': 1345.264, 'y': 453.461},\n",
    "    {'x': 1426.011, 'y': 421.129},\n",
    "    {'x': 1489.581, 'y': 183.934}\n",
    "  ]\n",
    "}\n",
    "\n",
    "mask_annotation_ndjson = {\n",
    "  'name': 'mask',\n",
    "  'classifications': [],\n",
    "  'mask': {'instanceURI': 'https://storage.labelbox.com/cjhfn5y6s0pk507024nz1ocys%2F1d60856c-59b7-3060-2754-83f7e93e0d01-1?Expires=1666901963361&KeyName=labelbox-assets-key-3&Signature=t-2s2DB4YjFuWEFak0wxYqfBfZA',\n",
    "  'colorRGB': (0, 0, 0)}\n",
    "}\n",
    "\n",
    "\n",
    "point_annotation_ndjson = {\n",
    "  'name': 'point',\n",
    "  'classifications': [],\n",
    "  'point': {'x': 1166.606, 'y': 1441.768}\n",
    "}\n",
    "\n",
    "point_annotation_ndjson = {\n",
    "  'name': 'point',\n",
    "  'classifications': [],\n",
    "  'point': {'x': 1166.606, 'y': 1441.768}\n",
    "}\n",
    "\n",
    "polyline_annotation_ndjson = {\n",
    "  'name': 'polyline',\n",
    "  'classifications': [],\n",
    "  'line': [\n",
    "    {'x': 2534.353, 'y': 249.471},\n",
    "    {'x': 2429.492, 'y': 182.092},\n",
    "    {'x': 2294.322, 'y': 221.962},\n",
    "    {'x': 2224.491, 'y': 180.463},\n",
    "    {'x': 2136.123, 'y': 204.716},\n",
    "    {'x': 1712.247, 'y': 173.949},\n",
    "    {'x': 1703.838, 'y': 84.438},\n",
    "    {'x': 1579.772, 'y': 82.61},\n",
    "    {'x': 1583.442, 'y': 167.552},\n",
    "    {'x': 1478.869, 'y': 164.903},\n",
    "    {'x': 1418.941, 'y': 318.149},\n",
    "    {'x': 1243.128, 'y': 400.815},\n",
    "    {'x': 1022.067, 'y': 319.007},\n",
    "    {'x': 892.367, 'y': 379.216},\n",
    "    {'x': 670.273, 'y': 364.408},\n",
    "    {'x': 613.114, 'y': 288.16},\n",
    "    {'x': 377.559, 'y': 238.251},\n",
    "    {'x': 368.087, 'y': 185.064},\n",
    "    {'x': 246.557, 'y': 167.286},\n",
    "    {'x': 236.648, 'y': 285.61},\n",
    "    {'x': 90.929, 'y': 326.412}\n",
    "  ]\n",
    "}\n",
    "\n",
    "nested_checklist_annotation_ndjson = {\n",
    "  \"name\": \"nested_checklist_question\",\n",
    "  \"answer\": [{\n",
    "      \"name\": \"first_checklist_answer\", \n",
    "      \"classifications\" : [\n",
    "        {\n",
    "          \"name\": \"sub_checklist_question\", \n",
    "          \"answer\": {\"name\": \"first_sub_checklist_answer\"}\n",
    "        }          \n",
    "      ]         \n",
    "  }]\n",
    "}\n",
    "\n",
    "text_annotation_ndjson = {\n",
    "  'name': 'free_text',\n",
    "  'answer': 'sample text',\n",
    "}\n"
   ],
   "metadata": {
    "id": "A8_HVvu9Uvfl"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 7.4. Create the label object"
   ],
   "metadata": {
    "id": "8QwmguFvPltl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a Label object by identifying the applicable data row in Labelbox and providing a list of annotations\n",
    "ndjson_annotation = []\n",
    "for annot in [\n",
    "    radio_annotation_ndjson, \n",
    "    checklist_annotation_ndjson, \n",
    "    bbox_annotation_ndjson, \n",
    "    bbox_with_radio_subclass_ndjson, \n",
    "    polygon_annotation_ndjson, \n",
    "    mask_annotation_ndjson, \n",
    "    point_annotation_ndjson, \n",
    "    polyline_annotation_ndjson,\n",
    "    nested_radio_annotation_ndjson,\n",
    "    nested_checklist_annotation_ndjson,\n",
    "    text_annotation_ndjson\n",
    "]:\n",
    "  annot.update({\n",
    "      'uuid': str(uuid.uuid4()),\n",
    "      'dataRow': {'id': data_row.uid},\n",
    "  })\n",
    "  ndjson_annotation.append(annot) \n",
    "\n"
   ],
   "metadata": {
    "id": "9gD_alThQA3G"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 7.5. Upload annotations to the project using Label Import"
   ],
   "metadata": {
    "id": "nGVNQlvPQ-kF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "upload_job_annotation = lb.LabelImport.create_from_objects(\n",
    "    client = client,\n",
    "    project_id = project.uid,\n",
    "    name=\"annotation_import_\" + str(uuid.uuid4()),\n",
    "    labels=ndjson_annotation)\n",
    "\n",
    "upload_job_annotation.wait_until_done()\n",
    "# Errors will appear for annotation uploads that failed.\n",
    "print(\"Errors:\", upload_job_annotation.errors)\n"
   ],
   "metadata": {
    "id": "HYh9AzrlRYX-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eba0209a-bcde-4816-b386-d69f97899678"
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: []\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 7.6 Send the annotations to the Model Run"
   ],
   "metadata": {
    "id": "Y3rgM-5cRrxM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# get the labels id from the project\n",
    "label_ids = [x['ID'] for x in project.export_labels(download=True)]\n",
    "model_run.upsert_labels(label_ids)"
   ],
   "metadata": {
    "id": "i2BrS8CcSBzo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b2d68ab6-6d1f-4ce2-d633-8048e8209af3"
   },
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optional deletions for cleanup \n"
   ],
   "metadata": {
    "id": "DMtOfWWDWFbJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# project.delete()\n",
    "# dataset.delete()"
   ],
   "metadata": {
    "id": "aAhkyvJlWK1p"
   },
   "execution_count": 68,
   "outputs": []
  }
 ]
}
