{
    "nbformat": 4,
    "nbformat_minor": 2,
    "metadata": {},
    "cells": [
        {
            "cell_type": "markdown",
            "id": "db768cda",
            "metadata": {},
            "source": [
                "<td>",
                "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>",
                "</td>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb5611d0",
            "metadata": {},
            "source": [
                "<td>",
                "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/prediction_upload/conversational_predictions.ipynb\" target=\"_blank\"><img",
                "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>",
                "</td>",
                "\n",
                "<td>",
                "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/prediction_upload/conversational_predictions.ipynb\" target=\"_blank\"><img",
                "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>",
                "</td>"
            ]
        },
        {
            "metadata": {},
            "source": [
                "# Conversational Text Prediction Import\n",
                "* This notebook will provide examples of each supported prediction type for conversational text assets, and also cover MAL and Label Import methods:\n",
                "\n",
                "Suported annotations that can be uploaded through the SDK\n",
                "\n",
                "* Classification Radio \n",
                "* Classification Checklist \n",
                "* Classification Free Text \n",
                "* NER\n",
                "\n",
                "**Not** supported annotations\n",
                "\n",
                "* Bouding box \n",
                "* Polygon \n",
                "* Point\n",
                "* Polyline \n",
                "* Segmentation Mask \n",
                "* Relationships\n",
                "\n",
                "\n"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": [
                "## Setup"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "%pip install -q \"labelbox[data]\"",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "import labelbox as lb\nimport uuid\nimport labelbox.types as lb_types",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Replace with your API key"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Add your api key\nAPI_KEY = \"\"\nclient = lb.Client(api_key=API_KEY)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Supported Predictions "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "########### Radio Classification ###########\n\n# Python annotation\nradio_prediction = lb_types.ClassificationAnnotation(\n    name=\"radio_question\",\n    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n        name=\"second_radio_answer\", confidence=0.5)),\n)\n\n# NDJSON\nradio_prediction_ndjson = {\n    \"name\": \"radio_question\",\n    \"answer\": {\n        \"name\": \"second_radio_answer\",\n        \"confidence\": 0.5\n    },\n}",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# message based classifications\nner_prediction = lb_types.ObjectAnnotation(\n    name=\"ner\",\n    confidence=0.5,\n    value=lb_types.ConversationEntity(start=0, end=8, message_id=\"4\"),\n)\n\nner_prediction_ndjson = {\n    \"name\": \"ner\",\n    \"confidence\": 0.5,\n    \"location\": {\n        \"start\": 0,\n        \"end\": 8\n    },\n    \"messageId\": \"4\",\n}",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "##### Classification free text #####\n# Confidence scores are not supported for text predictions\n\ntext_prediction = lb_types.ClassificationAnnotation(\n    name=\"text_convo\",\n    value=lb_types.Text(\n        answer=\"the answer to the text questions are right here\"),\n    message_id=\"0\",\n)\n\ntext_prediction_ndjson = {\n    \"name\": \"text_convo\",\n    \"answer\": \"the answer to the text questions are right here\",\n    \"messageId\": \"0\",\n}",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "##### Checklist Classification #######\n\nchecklist_prediction = lb_types.ClassificationAnnotation(\n    name=\"checklist_convo\",  # must match your ontology feature\"s name\n    value=lb_types.Checklist(answer=[\n        lb_types.ClassificationAnswer(name=\"first_checklist_answer\",\n                                      confidence=0.5),\n        lb_types.ClassificationAnswer(name=\"second_checklist_answer\",\n                                      confidence=0.5),\n    ]),\n    message_id=\"2\",\n)\n\nchecklist_prediction_ndjson = {\n    \"name\": \"checklist_convo\",\n    \"answers\": [\n        {\n            \"name\": \"first_checklist_answer\",\n            \"confidence\": 0.5\n        },\n        {\n            \"name\": \"second_checklist_answer\",\n            \"confidence\": 0.5\n        },\n    ],\n    \"messageId\": \"2\",\n}",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "######## Radio Classification ######\n\nradio_prediction = lb_types.ClassificationAnnotation(\n    name=\"radio_convo\",\n    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n        name=\"first_radio_answer\", confidence=0.5)),\n    message_id=\"0\",\n)\n\nradio_prediction_ndjson = {\n    \"name\": \"radio_convo\",\n    \"answer\": {\n        \"name\": \"first_radio_answer\",\n        \"confidence\": 0.5\n    },\n    \"messageId\": \"0\",\n}",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# ############ global nested classifications ###########\n\n# Message based\nnested_checklist_prediction = lb_types.ClassificationAnnotation(\n    name=\"nested_checklist_question\",\n    message_id=\"10\",\n    value=lb_types.Checklist(answer=[\n        lb_types.ClassificationAnswer(\n            name=\"first_checklist_answer\",\n            confidence=0.5,  # Confidence scores should be added to the answer\n            classifications=[\n                lb_types.ClassificationAnnotation(\n                    name=\"sub_checklist_question\",\n                    value=lb_types.Checklist(answer=[\n                        lb_types.ClassificationAnswer(\n                            name=\"first_sub_checklist_answer\",\n                            confidence=\n                            0.5,  # Confidence scores should be added to the answer\n                        )\n                    ]),\n                )\n            ],\n        )\n    ]),\n)\n# Message based\nnested_checklist_prediction_ndjson = {\n    \"name\":\n        \"nested_checklist_question\",\n    \"messageId\":\n        \"10\",\n    \"answer\": [{\n        \"name\":\n            \"first_checklist_answer\",\n        \"confidence\":\n            0.5,  # Confidence scores should be added to the answer\n        \"classifications\": [{\n            \"name\": \"sub_checklist_question\",\n            \"answer\": {\n                \"name\": \"first_sub_checklist_answer\",\n                \"confidence\":\n                    0.5,  # Confidence scores should be added to the answer\n            },\n        }],\n    }],\n}\n# Global\nnested_radio_prediction = lb_types.ClassificationAnnotation(\n    name=\"nested_radio_question\",\n    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n        name=\"first_radio_answer\",\n        confidence=0.5,  # Confidence scores should be added to the answer\n        classifications=[\n            lb_types.ClassificationAnnotation(\n                name=\"sub_radio_question\",\n                value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n                    name=\"first_sub_radio_answer\",\n                    confidence=\n                    0.5,  # Confidence scores should be added to the answer\n                )),\n            )\n        ],\n    )),\n)\n# Global\nnested_radio_prediction_ndjson = {\n    \"name\": \"nested_radio_question\",\n    \"answer\": {\n        \"name\":\n            \"first_radio_answer\",\n        \"confidence\":\n            0.5,\n        \"classifications\": [{\n            \"name\": \"sub_radio_question\",\n            \"answer\": {\n                \"name\": \"first_sub_radio_answer\",\n                \"confidence\": 0.5\n            },\n        }],\n    },\n}",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Step 1: Import data rows into Catalog "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Create one Labelbox dataset\n\nglobal_key = \"conversation-1.json\"\n\nasset = {\n    \"row_data\":\n        \"https://storage.googleapis.com/labelbox-developer-testing-assets/conversational_text/1000-conversations/conversation-1.json\",\n    \"global_key\":\n        global_key,\n}\n\ndataset = client.create_dataset(\n    name=\"conversational_annotation_import_demo_dataset\")\ntask = dataset.create_data_rows([asset])\ntask.wait_till_done()\nprint(\"Errors:\", task.errors)\nprint(\"Failed data rows: \", task.failed_data_rows)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Step 2: Create/select an Ontology for your model predictions\n",
                "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the name/instructions fields in your annotations to ensure the correct feature schemas are matched."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "ontology_builder = lb.OntologyBuilder(\n    tools=[lb.Tool(tool=lb.Tool.Type.NER, name=\"ner\")],\n    classifications=[\n        lb.Classification(\n            class_type=lb.Classification.Type.TEXT,\n            scope=lb.Classification.Scope.INDEX,\n            name=\"text_convo\",\n        ),\n        lb.Classification(\n            class_type=lb.Classification.Type.CHECKLIST,\n            scope=lb.Classification.Scope.INDEX,\n            name=\"checklist_convo\",\n            options=[\n                lb.Option(value=\"first_checklist_answer\"),\n                lb.Option(value=\"second_checklist_answer\"),\n            ],\n        ),\n        lb.Classification(\n            class_type=lb.Classification.Type.RADIO,\n            name=\"radio_convo\",\n            scope=lb.Classification.Scope.INDEX,\n            options=[\n                lb.Option(value=\"first_radio_answer\"),\n                lb.Option(value=\"second_radio_answer\"),\n            ],\n        ),\n        lb.Classification(\n            class_type=lb.Classification.Type.CHECKLIST,\n            name=\"nested_checklist_question\",\n            scope=lb.Classification.Scope.INDEX,\n            options=[\n                lb.Option(\n                    \"first_checklist_answer\",\n                    options=[\n                        lb.Classification(\n                            class_type=lb.Classification.Type.CHECKLIST,\n                            name=\"sub_checklist_question\",\n                            options=[lb.Option(\"first_sub_checklist_answer\")],\n                        )\n                    ],\n                )\n            ],\n        ),\n        lb.Classification(\n            class_type=lb.Classification.Type.RADIO,\n            name=\"nested_radio_question\",\n            scope=lb.Classification.Scope.GLOBAL,\n            options=[\n                lb.Option(\n                    \"first_radio_answer\",\n                    options=[\n                        lb.Classification(\n                            class_type=lb.Classification.Type.RADIO,\n                            name=\"sub_radio_question\",\n                            options=[lb.Option(\"first_sub_radio_answer\")],\n                        )\n                    ],\n                )\n            ],\n        ),\n    ],\n)\n\nontology = client.create_ontology(\"Ontology Conversation Annotations\",\n                                  ontology_builder.asdict())",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Step 3: Create a Mode and Model Run "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# create Model\nmodel = client.create_model(\n    name=\"Conversational_model_run_\" + str(uuid.uuid4()),\n    ontology_id=ontology.uid,\n)\n# create Model Run\nmodel_run = model.create_model_run(\"iteration 1\")",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Step 4: Send data rows to the Model Run "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "model_run.upsert_data_rows(global_keys=[global_key])",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Step 5: Create the predictions payload\n",
                "Create the prediction payload using the snippets of code in the **Supported Predcitions** section\n",
                "\n",
                "Labelbox support two formats for the annotations payload: NDJSON and Python Annotation types. Both are described below to compose your annotations into Labels attached to the data rows.\n",
                "\n",
                "The resulting payload should have exactly the same content for annotations that are supported by both"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": [
                "Python annotations"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "label_prediction = []\nlabel_prediction.append(\n    lb_types.Label(\n        data={\"global_key\": global_key},\n        annotations=[\n            ner_prediction,\n            checklist_prediction,\n            text_prediction,\n            radio_prediction,\n            nested_checklist_prediction,\n            nested_radio_prediction,\n        ],\n    ))",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "if using NDJSON : "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "label_prediction_ndjson = []\nfor annotations in [\n        ner_prediction_ndjson,\n        text_prediction_ndjson,\n        checklist_prediction_ndjson,\n        radio_prediction_ndjson,\n        nested_checklist_prediction_ndjson,\n        nested_radio_prediction_ndjson,\n]:\n    annotations.update({\"dataRow\": {\"globalKey\": global_key}})\n    label_prediction_ndjson.append(annotations)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Step 6: Upload the predictions payload to the Model Run"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Upload the prediction label to the Model Run\nupload_job_prediction = model_run.add_predictions(\n    name=\"prediction_upload_job\" + str(uuid.uuid4()),\n    predictions=label_prediction,\n)\n\n# Errors will appear for annotation uploads that failed.\nprint(\"Errors:\", upload_job_prediction.errors)\nprint(\"Status of uploads: \", upload_job_prediction.statuses)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Step 7 : Send annotations to the Model Run "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": [
                "7.1 Create a labelbox project"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "project = client.create_project(\n    name=\"Conversational Text Prediction Import Demo\",\n    media_type=lb.MediaType.Conversational,\n)\nproject.setup_editor(ontology)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "7.2 Create a batch to send to the project"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "project.create_batch(\n    \"batch_convo_prediction_demo\",  # Each batch in a project must have a unique name\n    global_keys=[\n        global_key\n    ],  # Paginated collection of data row objects, list of data row ids or global keys\n    priority=5,  # priority between 1(Highest) - 5(lowest)\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "7.3 Create the annotations payload"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "ner_annotation = lb_types.ObjectAnnotation(\n    name=\"ner\",\n    value=lb_types.ConversationEntity(start=0, end=8, message_id=\"4\"),\n)\n\ntext_annotation = lb_types.ClassificationAnnotation(\n    name=\"text_convo\",\n    value=lb_types.Text(\n        answer=\"the answer to the text questions are right here\"),\n    message_id=\"0\",\n)\n\nchecklist_annotation = lb_types.ClassificationAnnotation(\n    name=\"checklist_convo\",  # must match your ontology feature\"s name\n    value=lb_types.Checklist(answer=[\n        lb_types.ClassificationAnswer(name=\"first_checklist_answer\"),\n        lb_types.ClassificationAnswer(name=\"second_checklist_answer\"),\n    ]),\n    message_id=\"2\",\n)\n\nradio_annotation = lb_types.ClassificationAnnotation(\n    name=\"radio_convo\",\n    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n        name=\"first_radio_answer\")),\n    message_id=\"0\",\n)\n\nnested_checklist_annotation = lb_types.ClassificationAnnotation(\n    name=\"nested_checklist_question\",\n    message_id=\"10\",\n    value=lb_types.Checklist(answer=[\n        lb_types.ClassificationAnswer(\n            name=\"first_checklist_answer\",\n            classifications=[\n                lb_types.ClassificationAnnotation(\n                    name=\"sub_checklist_question\",\n                    value=lb_types.Checklist(answer=[\n                        lb_types.ClassificationAnswer(\n                            name=\"first_sub_checklist_answer\")\n                    ]),\n                )\n            ],\n        )\n    ]),\n)\n\nnested_radio_annotation = lb_types.ClassificationAnnotation(\n    name=\"nested_radio_question\",\n    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n        name=\"first_radio_answer\",\n        classifications=[\n            lb_types.ClassificationAnnotation(\n                name=\"sub_radio_question\",\n                value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n                    name=\"first_sub_radio_answer\")),\n            )\n        ],\n    )),\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "7.4 Create the label object"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "label = []\nlabel.append(\n    lb_types.Label(\n        data=lb_types.ConversationData(global_key=global_key),\n        annotations=[\n            ner_annotation,\n            text_annotation,\n            checklist_annotation,\n            radio_annotation,\n            nested_radio_annotation,\n            nested_checklist_annotation,\n        ],\n    ))",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "7.5 Upload annotations to the project using Label Import"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "upload_job_annotation = lb.LabelImport.create_from_objects(\n    client=client,\n    project_id=project.uid,\n    name=\"text_label_import_job\" + str(uuid.uuid4()),\n    labels=label,\n)\n\nupload_job_annotation.wait_until_done()\n# Errors will appear for annotation uploads that failed.\nprint(\"Errors:\", upload_job_annotation.errors)\nprint(\"Status of uploads: \", upload_job_annotation.statuses)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "7.6 Send the annotations to the Model Run "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# get the labels id from the project\nmodel_run.upsert_labels(project_id=project.uid)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "# Option deletions for cleanup"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# project.delete()\n# dataset.delete()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        }
    ]
}