{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>",
        "</td>\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/project_configuration/multimodal_chat_project.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/project_configuration/multimodal_chat_project.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Multimodal chat project setup\n",
        "\n",
        "This notebook will provide an example workflow of setting up a multimodal Chat (MMC) Project with the Labelbox-Python SDK.\n",
        "Multimodal Chat Projects are set up differently than other projects with its own unique method and modifications to existing methods:\n",
        "\n",
        "- `client.create_model_evaluation_project`: The main method used to create a live multimodal Chat project.\n",
        "  \n",
        "- `client.create_offline_model_evaluation_project`: The main method used to create a offline multimodal Chat project.\n",
        "\n",
        "- `client.create_ontology`: Methods used to create Labelbox ontologies for LMC project this requires an `ontology_kind` parameter set to `lb.OntologyKind.ModelEvaluation`.\n",
        "\n",
        "- `client.create_ontology_from_feature_schemas`: Similar to `client.create_ontology` but from a list of `feature schema ids` designed to allow you to use existing features instead of creating new features. This also requires an `ontology_kind` set to `lb.OntologyKind.ModelEvaluation`."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Set up"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "%pip install -q --upgrade \"labelbox[data]\"",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "import labelbox as lb",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## API key and client\n",
        "Please provide a valid API key below to connect to the Labelbox client properly. For more information, please review the [Create API key guide](https://docs.labelbox.com/reference/create-api-key)."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "API_KEY = None\nclient = lb.Client(api_key=API_KEY)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Example: Create multimodal Chat project\n",
        "\n",
        "The steps to creating a multimodal Chat Projects through the Labelbox-Python SDK are similar to creating a regular project. However, they vary slightly, and we will showcase the different methods in this example workflow."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Create a multimodal chat ontology\n",
        "\n",
        "You can create ontologies for multimodal chat projects in the same way as other project ontologies using two methods: `client.create_ontology` and `client.create_ontology_from_feature_schemas`. The only additional requirement is to pass an ontology_kind parameter, which needs to be set to `lb.OntologyKind.ModelEvaluation`."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### Option A: `client.create_ontology`\n",
        "\n",
        "Typically, you create ontologies and generate the associated features simultaneously. Below is an example of creating an ontology for your multimodal chat project using supported tools and classifications; for information on supported annotation types, visit our [multimodal chat evaluation guide](https://docs.labelbox.com/docs/multimodal-chat#supported-annotation-types) guide."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "ontology_builder = lb.OntologyBuilder(\n    tools=[\n        lb.Tool(\n            tool=lb.Tool.Type.MESSAGE_SINGLE_SELECTION,\n            name=\"single select feature\",\n        ),\n        lb.Tool(\n            tool=lb.Tool.Type.MESSAGE_MULTI_SELECTION,\n            name=\"multi select feature\",\n        ),\n        lb.Tool(tool=lb.Tool.Type.MESSAGE_RANKING, name=\"ranking feature\"),\n    ],\n    classifications=[\n        lb.Classification(\n            class_type=lb.Classification.Type.CHECKLIST,\n            name=\"checklist feature\",\n            options=[\n                lb.Option(value=\"option 1\", label=\"option 1\"),\n                lb.Option(value=\"option 2\", label=\"option 2\"),\n            ],\n        ),\n        lb.Classification(\n            class_type=lb.Classification.Type.RADIO,\n            name=\"radio_question\",\n            options=[\n                lb.Option(value=\"first_radio_answer\"),\n                lb.Option(value=\"second_radio_answer\"),\n            ],\n        ),\n    ],\n)\n\n# Create ontology\nontology = client.create_ontology(\n    \"LMC ontology\",\n    ontology_builder.asdict(),\n    media_type=lb.MediaType.Conversational,\n    ontology_kind=lb.OntologyKind.ModelEvaluation,\n)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Option B: `client.create_ontology_from_feature_schemas`\n",
        "Ontologies can also be created with feature schema IDs. This makes your ontologies with existing features compared to generating new features. You can get these features by going to the _Schema_ tab inside Labelbox. (uncomment the below code block for this option)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# ontology = client.create_ontology_from_feature_schemas(\n#     \"LMC ontology\",\n#     feature_schema_ids=[\"<list of feature schema ids\"],\n#     media_type=lb.MediaType.Conversational,\n#     ontology_kind=lb.OntologyKind.ModelEvaluation,\n# )",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Creating multimodal chat evaluation projects\n",
        "\n",
        "There are two versions of a multimodal chat evaluation projects:\n",
        "\n",
        "1. Offline multimodal chat evaluation projects: Data rows will need to be imported manually and have no live model invocation.\n",
        "\n",
        "2. Live multimodal chat evaluation projects: Empty data rows are generated on project creation and are filled out with live model invocation.\n",
        "\n",
        "We will discuss creating both types of projects with the Labelbox SDK."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Set up offline multimodal chat evaluation project\n",
        "\n",
        "For an offline multimodal chat evaluation project, you must import conversational version 2 data rows. For more information, please visit our [import multimodal chat evaluation data](https://docs.labelbox.com/reference/import-multimodal-chat-data) guide. Offline multimodal chat evaluation projects are created through the SDK with `client.create_offline_model_evaluation_project`. This method uses the same parameters as `client.create_project` but provides better validation to ensure the project is set up correctly."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "project = client.create_offline_model_evaluation_project(\n    name=\"<project_name>\",\n    description=\"<project_description>\",  # optional\n)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Set Up Live Multimodal Chat project\n",
        "You do not have to create data rows with a model evaluation project; instead, they are generated for you when you create the project. The method you use to create your project is `client.create_model_evaluation_project`, which takes the same parameters as the traditional `client.create_project` but with a few specific additional parameters. \n",
        "\n",
        "#### Parameters\n",
        "When using `client.create_model_evaluation_project` the following parameters are needed:\n",
        "\n",
        "- `create_model_evaluation_project` parameters:\n",
        "\n",
        "    - `name`: The name of your new project.\n",
        "\n",
        "    - `description`: An optional description of your project.\n",
        "\n",
        "    - `media_type`: The type of assets that this project will accept. This should be set to lb.MediaType.Conversational\n",
        "\n",
        "    - `dataset_name`: The name of the dataset where the generated data rows will be located. Include this parameter only if you want to create a new dataset.\n",
        "\n",
        "    - `dataset_id`: An optional dataset ID of an existing Labelbox dataset. Include this parameter if you are wanting to append to an existing LMC dataset.\n",
        "\n",
        "    - `data_row_count`: The number of data row assets that will be generated and used with your project.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "project = client.create_model_evaluation_project(\n    name=\"Demo LMC Project\",\n    media_type=lb.MediaType.Conversational,\n    dataset_name=\"Demo LMC dataset\",\n    data_row_count=100,\n)\n\n# Setup project with ontology created above\nproject.setup_editor(ontology)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setting up model config\n",
        "You can create, delete, attach and remove model configs from your Live Multimodal Chat project through the Labelbox-Python SDK. These are the model configs that you will be evaluating for your responses. "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Creating model config\n",
        "The main method associated with creating a model config is `client.create_model_config`. This method takes the following parameters:\n",
        "\n",
        "- `name`: Name of the model config.\n",
        "\n",
        "- `model_id`: The ID of the model to configure. You must obtain this through the UI by navigating to the Model tab, selecting the model you are trying to use, and copying the id inside the URL. For supported models, visit the [Live Multimodal Chat page](https://docs.labelbox.com/docs/live-multimodal-chat#supported-annotation-types).\n",
        "\n",
        "- `inference_params`: JSON of model configuration parameters. This will vary depending on the model you are trying to set up. It is recommended to first set up a model config inside the UI to learn all the associated parameters.\n",
        "\n",
        "For the example below, we will be setting up a Google Gemini 1.5 Pro model config."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "MODEL_ID = \"270a24ba-b983-40d6-9a1f-98a1bbc2fb65\"\n\ninference_params = {\"max_new_tokens\": 1024, \"use_attachments\": True}\n\nmodel_config = client.create_model_config(\n    name=\"Example model config\",\n    model_id=MODEL_ID,\n    inference_params=inference_params,\n)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Attaching model config to project\n",
        "You can attach and remove model configs to your project using `project.add_model_config` or `project.remove_model_config`. Both methods take just a `model_config` ID."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "project.add_model_config(model_config.uid)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Delete model config\n",
        "You can also delete model configs using the `client.delete_model_config`. You just need to pass in the `model_config` ID in order to delete your model config. You can obtain this ID from your created model config above or get the model configs directly from your project using `project.project_model_configs` and then iterating through the list of model configs attached to your project. Uncomment the code below to delete your model configs. "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# model_configs = project.project_model_configs()\n\n# for model_config in model_configs:\n#     client.delete_model_config(model_config.uid)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Mark project setup as completed\n",
        "\n",
        "Once you have finalized your project and set up your model configs, you must mark the project setup as completed.\n",
        "\n",
        "**Once the project is marked as \"setup complete\", a user can not add, modify, or delete existing project model configs.**"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "project.set_project_model_setup_complete()",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Exporting Live Multimodal Chat project\n",
        "Exporting from a Live Multimodal Chat project works the same as exporting from other projects. In this example, your export will be shown as empty unless you have created labels inside the Labelbox platform. Please review our [Live Multimodal Chat Export](https://docs.labelbox.com/reference/export-live-multimodal-chat-annotations) guide for a sample export."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Start export from project\nexport_task = project.export()\nexport_task.wait_till_done()\n\n# Conditional if task has errors\nif export_task.has_errors():\n    export_task.get_buffered_stream(stream_type=lb.StreamType.ERRORS).start(\n        stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    # Start export stream\n    stream = export_task.get_buffered_stream()\n\n    # Iterate through data rows\n    for data_row in stream:\n        print(data_row.json)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Clean up\n",
        "\n",
        "This section serves as an optional clean-up step to delete the Labelbox assets created within this guide. You will need to uncomment the delete methods shown."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# project.delete()\n# client.delete_unused_ontology(ontology.uid)\n# dataset.delete()",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}