{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "db768cda",
            "metadata": {},
            "source": [
                "<td>\n",
                "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
                "</td>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb5611d0",
            "metadata": {},
            "source": [
                "<td>\n",
                "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/integrations/huggingface/huggingface_custom_embeddings.ipynb\" target=\"_blank\"><img\n",
                "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
                "</td>\n",
                "\n",
                "<td>\n",
                "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/integrations/huggingface/huggingface_custom_embeddings.ipynb\" target=\"_blank\"><img\n",
                "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
                "</td>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Install required libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install -q \"labelbox[data]\"\n",
                "%pip install -q transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import labelbox as lb\n",
                "import transformers\n",
                "\n",
                "transformers.logging.set_verbosity(50)\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from PIL import Image\n",
                "import requests\n",
                "from tqdm import tqdm\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Labelbox Credentials"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add your API key\n",
                "API_KEY = \"\"\n",
                "client = lb.Client(API_KEY)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Select data rows in Labelbox for custom embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get images from a Labelbox dataset,\n",
                "# Ensure the images are available by obtaining a token from your cloud provider if necessary\n",
                "DATASET_ID = \"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = client.get_dataset(DATASET_ID)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "export_task = dataset.export_v2()\n",
                "\n",
                "export_task.wait_till_done()\n",
                "if export_task.errors:\n",
                "    print(export_task.errors)\n",
                "export_json = export_task.result\n",
                "\n",
                "data_row_urls = [dr_url[\"data_row\"][\"row_data\"] for dr_url in export_json]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Get a HuggingFace Model to generate custom embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get ResNet-50 from HuggingFace\n",
                "image_processor = transformers.AutoImageProcessor.from_pretrained(\n",
                "    \"microsoft/resnet-50\")\n",
                "model = transformers.ResNetModel.from_pretrained(\"microsoft/resnet-50\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pick an existing custom embedding in Labelbox, or create a custom embedding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a new embedding in your workspace, use the right dimensions to your use case, here we use 2048 for ResNet-50\n",
                "new_custom_embedding_id = client.create_embedding(\n",
                "    name=\"My new awesome embedding\", dims=2048).id\n",
                "\n",
                "# Or use an existing embedding from your workspace\n",
                "# existing_embedding_id = client.get_embedding_by_name(name=\"ResNet img 2048\").id"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Generate and upload custom embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "img_emb = []\n",
                "\n",
                "for url in tqdm(data_row_urls):\n",
                "    try:\n",
                "        response = requests.get(url, stream=True)\n",
                "        if response.status_code == 200:\n",
                "            # Open the image, convert to RGB, and resize to 224x224\n",
                "            image = Image.open(response.raw).convert(\"RGB\").resize((224, 224))\n",
                "\n",
                "            # Preprocess the image for model input\n",
                "            img_hf = image_processor(image, return_tensors=\"pt\")\n",
                "\n",
                "            # Pass the image through the model to get embeddings\n",
                "            with torch.no_grad():\n",
                "                last_layer = model(**img_hf,\n",
                "                                   output_hidden_states=True).last_hidden_state\n",
                "                resnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\n",
                "                resnet_embeddings = torch.flatten(resnet_embeddings,\n",
                "                                                  start_dim=1,\n",
                "                                                  end_dim=3)\n",
                "                img_emb.append(resnet_embeddings.cpu().numpy())\n",
                "        else:\n",
                "            continue\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing URL: {url}. Exception: {e}\")\n",
                "        continue\n",
                "\n",
                "data_rows = []\n",
                "\n",
                "# Create data rows payload to send to a dataset\n",
                "for url, embedding in tqdm(zip(data_row_urls, img_emb)):\n",
                "    data_rows.append({\n",
                "        \"row_data\":\n",
                "            url,\n",
                "        \"embeddings\": [{\n",
                "            \"embedding_id\": new_custom_embedding_id,\n",
                "            \"vector\": embedding[0].tolist(),\n",
                "        }],\n",
                "    })"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upload to a new dataset\n",
                "dataset = client.create_dataset(name=\"image_custom_embedding_resnet\",\n",
                "                                iam_integration=None)\n",
                "task = dataset.create_data_rows(data_rows)\n",
                "print(task.errors)"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
