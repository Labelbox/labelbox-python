{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>",
        "</td>\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/integrations/huggingface/huggingface_custom_embeddings.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/integrations/huggingface/huggingface_custom_embeddings.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Install required libraries"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "%pip install -q \"labelbox[data]\"\n%pip install -q transformers",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Imports"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "import labelbox as lb\nimport transformers\n\ntransformers.logging.set_verbosity(50)\nimport torch\nimport torch.nn.functional as F\nfrom PIL import Image\nimport requests\nfrom tqdm import tqdm\nimport numpy as np",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Labelbox Credentials"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Add your API key\nAPI_KEY = \"\"\nclient = lb.Client(API_KEY)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Select data rows in Labelbox for custom embeddings"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Get images from a Labelbox dataset,\n# Ensure the images are available by obtaining a token from your cloud provider if necessary\nDATASET_ID = \"\"",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "dataset = client.get_dataset(DATASET_ID)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "export_task = dataset.export_v2()\n\nexport_task.wait_till_done()\nif export_task.errors:\n    print(export_task.errors)\nexport_json = export_task.result\n\ndata_row_urls = [dr_url[\"data_row\"][\"row_data\"] for dr_url in export_json]",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Get a HuggingFace Model to generate custom embeddings"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Get ResNet-50 from HuggingFace\nimage_processor = transformers.AutoImageProcessor.from_pretrained(\n    \"microsoft/resnet-50\")\nmodel = transformers.ResNetModel.from_pretrained(\"microsoft/resnet-50\")",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Pick an existing custom embedding in Labelbox, or create a custom embedding"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Create a new embedding in your workspace, use the right dimensions to your use case, here we use 2048 for ResNet-50\nnew_custom_embedding_id = client.create_embedding(\n    name=\"My new awesome embedding\", dims=2048).id\n\n# Or use an existing embedding from your workspace\n# existing_embedding_id = client.get_embedding_by_name(name=\"ResNet img 2048\").id",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Generate and upload custom embeddings"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "img_emb = []\n\nfor url in tqdm(data_row_urls):\n    try:\n        response = requests.get(url, stream=True)\n        if response.status_code == 200:\n            # Open the image, convert to RGB, and resize to 224x224\n            image = Image.open(response.raw).convert(\"RGB\").resize((224, 224))\n\n            # Preprocess the image for model input\n            img_hf = image_processor(image, return_tensors=\"pt\")\n\n            # Pass the image through the model to get embeddings\n            with torch.no_grad():\n                last_layer = model(**img_hf,\n                                   output_hidden_states=True).last_hidden_state\n                resnet_embeddings = F.adaptive_avg_pool2d(last_layer, (1, 1))\n                resnet_embeddings = torch.flatten(resnet_embeddings,\n                                                  start_dim=1,\n                                                  end_dim=3)\n                img_emb.append(resnet_embeddings.cpu().numpy())\n        else:\n            continue\n    except Exception as e:\n        print(f\"Error processing URL: {url}. Exception: {e}\")\n        continue\n\ndata_rows = []\n\n# Create data rows payload to send to a dataset\nfor url, embedding in tqdm(zip(data_row_urls, img_emb)):\n    data_rows.append({\n        \"row_data\":\n            url,\n        \"embeddings\": [{\n            \"embedding_id\": new_custom_embedding_id,\n            \"vector\": embedding[0].tolist(),\n        }],\n    })",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "# Upload to a new dataset\ndataset = client.create_dataset(name=\"image_custom_embedding_resnet\",\n                                iam_integration=None)\ntask = dataset.create_data_rows(data_rows)\nprint(task.errors)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}