# uncompyle6 version 3.7.4
# Python bytecode 3.6 (3379)
# Decompiled from: Python 3.8.6 (default, Dec 16 2020, 17:27:54) 
# [GCC 9.3.0]
# Embedded file name: /home/vpraveen/.cache/dazel/_dazel_vpraveen/216c8b41e526c3295d3b802489ac2034/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/proto/inferencer_config_pb2.py
# Compiled at: 2021-02-05 20:37:47
# Size of source mod 2**32: 18364 bytes
import sys
_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
_sym_db = _symbol_database.Default()
DESCRIPTOR = _descriptor.FileDescriptor(name='iva/detectnet_v2/proto/inferencer_config.proto',
  package='',
  syntax='proto3',
  serialized_options=None,
  serialized_pb=(_b('\n.iva/detectnet_v2/proto/inferencer_config.proto"²\x01\n\x10CalibratorConfig\x12+\n\x11calibration_cache\x18\x01 \x01(\tR\x10calibrationCache\x125\n\x16calibration_tensorfile\x18\x02 \x01(\tR\x15calibrationTensorfile\x12\x1b\n\tn_batches\x18\x03 \x01(\x05R\x08nBatches\x12\x1d\n\nbatch_size\x18\x04 \x01(\x05R\tbatchSize"!\n\tTLTConfig\x12\x14\n\x05model\x18\x01 \x01(\tR\x05model"Þ\x03\n\x0eTensorRTConfig\x12.\n\x06parser\x18\x01 \x01(\x0e2\x16.TensorRTConfig.ParserR\x06parser\x12\x1e\n\ncaffemodel\x18\x02 \x01(\tR\ncaffemodel\x12\x1a\n\x08prototxt\x18\x03 \x01(\tR\x08prototxt\x12\x1b\n\tuff_model\x18\x04 \x01(\tR\x08uffModel\x12\x1d\n\netlt_model\x18\x05 \x01(\tR\tetltModel\x12K\n\x11backend_data_type\x18\x06 \x01(\x0e2\x1f.TensorRTConfig.BackendDataTypeR\x0fbackendDataType\x12\x1f\n\x0bsave_engine\x18\x07 \x01(\x08R\nsaveEngine\x12\x1d\n\ntrt_engine\x18\x08 \x01(\tR\ttrtEngine\x12>\n\x11calibrator_config\x18\t \x01(\x0b2\x11.CalibratorConfigR\x10calibratorConfig"&\n\x06Parser\x12\t\n\x05CAFFE\x10\x00\x12\x07\n\x03UFF\x10\x01\x12\x08\n\x04ETLT\x10\x02"/\n\x0fBackendDataType\x12\x08\n\x04FP32\x10\x00\x12\x08\n\x04FP16\x10\x01\x12\x08\n\x04INT8\x10\x02"º\x03\n\x10InferencerConfig\x12+\n\ntlt_config\x18\x01 \x01(\x0b2\n.TLTConfigH\x00R\ttltConfig\x12:\n\x0ftensorrt_config\x18\x02 \x01(\x0b2\x0f.TensorRTConfigH\x00R\x0etensorrtConfig\x12\x1f\n\x0binput_nodes\x18\x03 \x03(\tR\ninputNodes\x12!\n\x0coutput_nodes\x18\x04 \x03(\tR\x0boutputNodes\x12\x1d\n\nbatch_size\x18\x05 \x01(\x05R\tbatchSize\x12!\n\x0cimage_height\x18\x06 \x01(\x05R\x0bimageHeight\x12\x1f\n\x0bimage_width\x18\x07 \x01(\x05R\nimageWidth\x12%\n\x0eimage_channels\x18\x08 \x01(\x05R\rimageChannels\x12\x1b\n\tgpu_index\x18\t \x01(\x05R\x08gpuIndex\x12%\n\x0etarget_classes\x18\n \x03(\tR\rtargetClasses\x12\x16\n\x06stride\x18\x0b \x01(\x05R\x06strideB\x13\n\x11model_config_typeb\x06proto3')))
_TENSORRTCONFIG_PARSER = _descriptor.EnumDescriptor(name='Parser',
  full_name='TensorRTConfig.Parser',
  filename=None,
  file=DESCRIPTOR,
  values=[
 _descriptor.EnumValueDescriptor(name='CAFFE',
   index=0,
   number=0,
   serialized_options=None,
   type=None),
 _descriptor.EnumValueDescriptor(name='UFF',
   index=1,
   number=1,
   serialized_options=None,
   type=None),
 _descriptor.EnumValueDescriptor(name='ETLT',
   index=2,
   number=2,
   serialized_options=None,
   type=None)],
  containing_type=None,
  serialized_options=None,
  serialized_start=658,
  serialized_end=696)
_sym_db.RegisterEnumDescriptor(_TENSORRTCONFIG_PARSER)
_TENSORRTCONFIG_BACKENDDATATYPE = _descriptor.EnumDescriptor(name='BackendDataType',
  full_name='TensorRTConfig.BackendDataType',
  filename=None,
  file=DESCRIPTOR,
  values=[
 _descriptor.EnumValueDescriptor(name='FP32',
   index=0,
   number=0,
   serialized_options=None,
   type=None),
 _descriptor.EnumValueDescriptor(name='FP16',
   index=1,
   number=1,
   serialized_options=None,
   type=None),
 _descriptor.EnumValueDescriptor(name='INT8',
   index=2,
   number=2,
   serialized_options=None,
   type=None)],
  containing_type=None,
  serialized_options=None,
  serialized_start=698,
  serialized_end=745)
_sym_db.RegisterEnumDescriptor(_TENSORRTCONFIG_BACKENDDATATYPE)
_CALIBRATORCONFIG = _descriptor.Descriptor(name='CalibratorConfig',
  full_name='CalibratorConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
 _descriptor.FieldDescriptor(name='calibration_cache',
   full_name='CalibratorConfig.calibration_cache',
   index=0,
   number=1,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='calibrationCache',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='calibration_tensorfile',
   full_name='CalibratorConfig.calibration_tensorfile',
   index=1,
   number=2,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='calibrationTensorfile',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='n_batches',
   full_name='CalibratorConfig.n_batches',
   index=2,
   number=3,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='nBatches',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='batch_size',
   full_name='CalibratorConfig.batch_size',
   index=3,
   number=4,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='batchSize',
   file=DESCRIPTOR)],
  extensions=[],
  nested_types=[],
  enum_types=[],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[],
  serialized_start=51,
  serialized_end=229)
_TLTCONFIG = _descriptor.Descriptor(name='TLTConfig',
  full_name='TLTConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
 _descriptor.FieldDescriptor(name='model',
   full_name='TLTConfig.model',
   index=0,
   number=1,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='model',
   file=DESCRIPTOR)],
  extensions=[],
  nested_types=[],
  enum_types=[],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[],
  serialized_start=231,
  serialized_end=264)
_TENSORRTCONFIG = _descriptor.Descriptor(name='TensorRTConfig',
  full_name='TensorRTConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
 _descriptor.FieldDescriptor(name='parser',
   full_name='TensorRTConfig.parser',
   index=0,
   number=1,
   type=14,
   cpp_type=8,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='parser',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='caffemodel',
   full_name='TensorRTConfig.caffemodel',
   index=1,
   number=2,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='caffemodel',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='prototxt',
   full_name='TensorRTConfig.prototxt',
   index=2,
   number=3,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='prototxt',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='uff_model',
   full_name='TensorRTConfig.uff_model',
   index=3,
   number=4,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='uffModel',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='etlt_model',
   full_name='TensorRTConfig.etlt_model',
   index=4,
   number=5,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='etltModel',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='backend_data_type',
   full_name='TensorRTConfig.backend_data_type',
   index=5,
   number=6,
   type=14,
   cpp_type=8,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='backendDataType',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='save_engine',
   full_name='TensorRTConfig.save_engine',
   index=6,
   number=7,
   type=8,
   cpp_type=7,
   label=1,
   has_default_value=False,
   default_value=False,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='saveEngine',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='trt_engine',
   full_name='TensorRTConfig.trt_engine',
   index=7,
   number=8,
   type=9,
   cpp_type=9,
   label=1,
   has_default_value=False,
   default_value=(_b('').decode('utf-8')),
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='trtEngine',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='calibrator_config',
   full_name='TensorRTConfig.calibrator_config',
   index=8,
   number=9,
   type=11,
   cpp_type=10,
   label=1,
   has_default_value=False,
   default_value=None,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='calibratorConfig',
   file=DESCRIPTOR)],
  extensions=[],
  nested_types=[],
  enum_types=[
 _TENSORRTCONFIG_PARSER,
 _TENSORRTCONFIG_BACKENDDATATYPE],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[],
  serialized_start=267,
  serialized_end=745)
_INFERENCERCONFIG = _descriptor.Descriptor(name='InferencerConfig',
  full_name='InferencerConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
 _descriptor.FieldDescriptor(name='tlt_config',
   full_name='InferencerConfig.tlt_config',
   index=0,
   number=1,
   type=11,
   cpp_type=10,
   label=1,
   has_default_value=False,
   default_value=None,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='tltConfig',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='tensorrt_config',
   full_name='InferencerConfig.tensorrt_config',
   index=1,
   number=2,
   type=11,
   cpp_type=10,
   label=1,
   has_default_value=False,
   default_value=None,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='tensorrtConfig',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='input_nodes',
   full_name='InferencerConfig.input_nodes',
   index=2,
   number=3,
   type=9,
   cpp_type=9,
   label=3,
   has_default_value=False,
   default_value=[],
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='inputNodes',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='output_nodes',
   full_name='InferencerConfig.output_nodes',
   index=3,
   number=4,
   type=9,
   cpp_type=9,
   label=3,
   has_default_value=False,
   default_value=[],
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='outputNodes',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='batch_size',
   full_name='InferencerConfig.batch_size',
   index=4,
   number=5,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='batchSize',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='image_height',
   full_name='InferencerConfig.image_height',
   index=5,
   number=6,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='imageHeight',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='image_width',
   full_name='InferencerConfig.image_width',
   index=6,
   number=7,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='imageWidth',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='image_channels',
   full_name='InferencerConfig.image_channels',
   index=7,
   number=8,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='imageChannels',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='gpu_index',
   full_name='InferencerConfig.gpu_index',
   index=8,
   number=9,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='gpuIndex',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='target_classes',
   full_name='InferencerConfig.target_classes',
   index=9,
   number=10,
   type=9,
   cpp_type=9,
   label=3,
   has_default_value=False,
   default_value=[],
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='targetClasses',
   file=DESCRIPTOR),
 _descriptor.FieldDescriptor(name='stride',
   full_name='InferencerConfig.stride',
   index=10,
   number=11,
   type=5,
   cpp_type=1,
   label=1,
   has_default_value=False,
   default_value=0,
   message_type=None,
   enum_type=None,
   containing_type=None,
   is_extension=False,
   extension_scope=None,
   serialized_options=None,
   json_name='stride',
   file=DESCRIPTOR)],
  extensions=[],
  nested_types=[],
  enum_types=[],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
 _descriptor.OneofDescriptor(name='model_config_type',
   full_name='InferencerConfig.model_config_type',
   index=0,
   containing_type=None,
   fields=[])],
  serialized_start=748,
  serialized_end=1190)
_TENSORRTCONFIG.fields_by_name['parser'].enum_type = _TENSORRTCONFIG_PARSER
_TENSORRTCONFIG.fields_by_name['backend_data_type'].enum_type = _TENSORRTCONFIG_BACKENDDATATYPE
_TENSORRTCONFIG.fields_by_name['calibrator_config'].message_type = _CALIBRATORCONFIG
_TENSORRTCONFIG_PARSER.containing_type = _TENSORRTCONFIG
_TENSORRTCONFIG_BACKENDDATATYPE.containing_type = _TENSORRTCONFIG
_INFERENCERCONFIG.fields_by_name['tlt_config'].message_type = _TLTCONFIG
_INFERENCERCONFIG.fields_by_name['tensorrt_config'].message_type = _TENSORRTCONFIG
_INFERENCERCONFIG.oneofs_by_name['model_config_type'].fields.append(_INFERENCERCONFIG.fields_by_name['tlt_config'])
_INFERENCERCONFIG.fields_by_name['tlt_config'].containing_oneof = _INFERENCERCONFIG.oneofs_by_name['model_config_type']
_INFERENCERCONFIG.oneofs_by_name['model_config_type'].fields.append(_INFERENCERCONFIG.fields_by_name['tensorrt_config'])
_INFERENCERCONFIG.fields_by_name['tensorrt_config'].containing_oneof = _INFERENCERCONFIG.oneofs_by_name['model_config_type']
DESCRIPTOR.message_types_by_name['CalibratorConfig'] = _CALIBRATORCONFIG
DESCRIPTOR.message_types_by_name['TLTConfig'] = _TLTCONFIG
DESCRIPTOR.message_types_by_name['TensorRTConfig'] = _TENSORRTCONFIG
DESCRIPTOR.message_types_by_name['InferencerConfig'] = _INFERENCERCONFIG
_sym_db.RegisterFileDescriptor(DESCRIPTOR)
CalibratorConfig = _reflection.GeneratedProtocolMessageType('CalibratorConfig', (_message.Message,), dict(DESCRIPTOR=_CALIBRATORCONFIG,
  __module__='iva.detectnet_v2.proto.inferencer_config_pb2'))
_sym_db.RegisterMessage(CalibratorConfig)
TLTConfig = _reflection.GeneratedProtocolMessageType('TLTConfig', (_message.Message,), dict(DESCRIPTOR=_TLTCONFIG,
  __module__='iva.detectnet_v2.proto.inferencer_config_pb2'))
_sym_db.RegisterMessage(TLTConfig)
TensorRTConfig = _reflection.GeneratedProtocolMessageType('TensorRTConfig', (_message.Message,), dict(DESCRIPTOR=_TENSORRTCONFIG,
  __module__='iva.detectnet_v2.proto.inferencer_config_pb2'))
_sym_db.RegisterMessage(TensorRTConfig)
InferencerConfig = _reflection.GeneratedProtocolMessageType('InferencerConfig', (_message.Message,), dict(DESCRIPTOR=_INFERENCERCONFIG,
  __module__='iva.detectnet_v2.proto.inferencer_config_pb2'))
_sym_db.RegisterMessage(InferencerConfig)
# okay decompiling inferencer_config_pb2.pyc
