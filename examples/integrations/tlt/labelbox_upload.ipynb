{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "# Create training data using Labelbox\n",
        "* Download images and animal annotations\n",
        "* Upload them to labelbox using MAL"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import os\n",
        "import uuid\n",
        "import numpy as np"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Download Images and Annotations\n",
        "* The dataset contains images of animals in the wild and corresponding bounding boxes\n",
        "* Read more about the dataset here: https://beerys.github.io/CaltechCameraTraps/"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Download data from here: https://beerys.github.io/CaltechCameraTraps/\n",
        "# This file is 6GB so this might take a little while\n",
        "if not os.path.exists('eccv_18_all_images_sm'):\n",
        "    !wget http://www.vision.caltech.edu/~sbeery/datasets/caltechcameratraps18/eccv_18_all_images_sm.tar.gz\n",
        "    !tar -zxf eccv_18_all_images_sm.tar.gz"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Download the annotations\n",
        "if not os.path.exists('eccv_18_all_annotations'):\n",
        "    !wget http://www.vision.caltech.edu/~sbeery/datasets/caltechcameratraps18/eccv_18_all_annotations.tar.gz\n",
        "    !tar -zxf eccv_18_all_annotations.tar.gz"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Preprocess Data\n",
        "* Sample images from video sequences\n",
        "* Select only day time images and a subset of possible animals\n",
        "* Convert the data into a format that is compatible with labelbox"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "data = json.load(open('CaltechCameraTrapsECCV18.json'))\n",
        "data['categories'] = {d['id'] : d for d in data['categories']}\n",
        "annotations = defaultdict(lambda: [])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# One image per video sequence to reduce correlation between training/testing images.\n",
        "\n",
        "images = {}\n",
        "ids = set()\n",
        "for img in data['images']:\n",
        "    if img['seq_id'] in ids:\n",
        "        continue\n",
        "    ids.add(img['seq_id'])\n",
        "    images[img['id']] = img\n",
        "data['images'] = images\n",
        "\n",
        "\n",
        "for annotation in data['annotations']:\n",
        "    if annotation.get('bbox') is None:\n",
        "        if annotation['image_id'] in data['images']:\n",
        "            del data['images'][annotation['image_id']]\n",
        "        continue\n",
        "    annotations[annotation['image_id']].append(annotation)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# These ids correspond to locations with a lot of people in the images that we can label\n",
        "target_locations = {0,125,120}\n",
        "target_classes = {'dog', 'cat', 'deer', 'bobcat', 'fox'}\n",
        "min_border_distance = 50\n",
        "\n",
        "\n",
        "def process_image(image):\n",
        "    date_time_obj = datetime.datetime.strptime(image['date_captured'], '%Y-%m-%d %H:%M:%S')\n",
        "    if (not ((18 > date_time_obj.hour > 7)) or (date_time_obj.hour == 12)):\n",
        "        #Only train on day time images\n",
        "        return\n",
        "    \n",
        "    if image['location'] not in target_locations:\n",
        "        return\n",
        "    \n",
        "    annots = annotations[image['id']]\n",
        "    im = None \n",
        "    box_coords = []\n",
        "    \n",
        "    for annot in annots:\n",
        "        if not (data['categories'][annot['category_id']]['name'] in target_classes):\n",
        "            return\n",
        "            \n",
        "        h, w = image['height'], image['width']\n",
        "        bbox = annot.get('bbox')\n",
        "        assert bbox is not None\n",
        "        \n",
        "        # Don't train on images where the animal is on the edge of the image\n",
        "        if bbox[0] < min_border_distance or bbox[1] < min_border_distance:\n",
        "            return\n",
        "        \n",
        "        if (w - (bbox[0] + bbox[2])) < min_border_distance or (h - (bbox[1] + bbox[3])) < min_border_distance:\n",
        "            return \n",
        "        \n",
        "        if im is None:\n",
        "            im = np.array(Image.open(os.path.join('eccv_18_all_images_sm', image['file_name'])))\n",
        "            new_h, new_w = im.shape[:2]    \n",
        "            \n",
        "        scale = lambda x, y: (int((x / h) * new_h), int((y / w) * new_w))\n",
        "        start_pt = scale(bbox[0], bbox[1])\n",
        "        end_pt = scale(bbox[0] + bbox[2], bbox[1]+ bbox[3])\n",
        "        box_coords.append([start_pt, end_pt])\n",
        "    return im,box_coords, image['location']\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "examples = [process_image(ex) for ex in data['images'].values()]\n",
        "examples = [ex for ex in examples if ex is not None]\n",
        "print(len(examples))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "* Write the data to file so that we can reference it later for uploads and metadata"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "if not os.path.exists(\"uploaded_images\"):\n",
        "    os.mkdir(\"uploaded_images\")\n",
        "\n",
        "if not os.path.exists(\"labels\"): \n",
        "    os.mkdir(\"labels\")\n",
        "    \n",
        "image_paths = []\n",
        "\n",
        "for idx, example in enumerate(examples):\n",
        "    imm, coords, location = example\n",
        "    image_path = os.path.join(\"uploaded_images\", f\"{idx}.jpg\")\n",
        "    image_paths.append(image_path)\n",
        "    Image.fromarray(imm).save(image_path)\n",
        "    with open(os.path.join(\"labels\", f\"{idx}.json\"), 'w') as file:\n",
        "        file.write(json.dumps({'coords' : coords, 'location' : location}))\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Upload to Labelbox\n",
        "* Setup a project\n",
        "* Add the images to label\n",
        "* Upload annotations using MAL\n",
        "-----\n",
        "For more information on this process checkout the example notebooks covering mal:\n",
        "https://github.com/Labelbox/labelbox-python/tree/master/examples#model-assisted-labeling"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "client = lb.Client()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "project = client.create_project(name = \"animal_demo_proj\", media_type=lb.MediaType.Image)\n",
        "dataset = client.create_dataset(name = \"animal_demo_ds\")\n",
        "dataset.create_data_rows(image_paths)\n",
        "project.create_batches_from_dataset(\"batch\", dataset.uid)\n",
        "project.enable_model_assisted_labeling()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "editor = next(client.get_labeling_frontends(where=lb.LabelingFrontend.name == \"Editor\"))\n",
        "\n",
        "\n",
        "ontology_builder = lb.OntologyBuilder(tools=[\n",
        "    lb.Tool(tool=lb.Tool.Type.BBOX, name=\"person\"),\n",
        "    lb.Tool(tool=lb.Tool.Type.BBOX, name=\"animal\")\n",
        "])\n",
        "\n",
        "project.setup(editor, ontology_builder.asdict())\n",
        "\n",
        "# fetch ontology from api to get all of the ids\n",
        "ontology = ontology_builder.from_project(project)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "def get_labels(dr):\n",
        "    label_name = dr.external_id.split('/')[-1].replace('.jpg', '.json')\n",
        "    label_name = f\"labels/{label_name}\"\n",
        "    labels = json.load(open(label_name))\n",
        "    return labels"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "datarows = []\n",
        "for batch in list(project.batches()):\n",
        "    datarows.extend(list(batch.export_data_rows()))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "boxes = []\n",
        "for datarow in datarows:\n",
        "    label = get_labels(datarow)['coords'][0]\n",
        "    row = {\n",
        "        'name' : 'animal',\n",
        "        'dataRow' : {'id' : datarow.uid},\n",
        "        'bbox' : {\n",
        "            'top' : label[0][1],\n",
        "            'left' : label[0][0],\n",
        "            'height' : label[1][1] - label[0][1],\n",
        "            'width' : label[1][0] - label[0][0]            \n",
        "        }\n",
        "    }\n",
        "    boxes.append(row)\n",
        "    "
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "upload = project.upload_annotations(name = f\"upload-{uuid.uuid4()}\", annotations = boxes)\n",
        "upload.wait_until_done()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Go to Labelbox and Label\n",
        "* Most of the animal data is prelabeled we want to go through and make sure everything is correct\n",
        "    * Make sure to use the hot keys to label quickly!\n",
        "    * 'e' submits the image\n",
        "    * '1' selects the person bounding box\n",
        "    * '2' selects the animal bounding box\n",
        "    * There are other helpful ones too! Check out the keyboard shortcuts panel in the top right of the editor.\n",
        "* None of the people in the images have been labeled so we are also going to add those annotations"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "print(f\"https://app.labelbox.com/projects/{project.uid}/overview\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}