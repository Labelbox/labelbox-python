{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "# Labelbox Connector for Databricks Tutorial Notebook"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### Pre-requisites\n",
        "1. This tutorial notebook requires a Lablbox API Key. Please login to your [Labelbox Account](app.labelbox.com) and generate an [API Key](https://app.labelbox.com/account/api-keys)\n",
        "2. A few cells below will install the Labelbox SDK and Connector Library. This install is notebook-scoped and will not affect the rest of your cluster. \n",
        "3. Please make sure you are running at least the latest LTS version of Databricks. \n",
        "\n",
        "#### Notebook Preview\n",
        "This notebook will guide you through these steps: \n",
        "1. Connect to Labelbox via the SDK \n",
        "2. Create a labeling dataset from a table of unstructured data in Databricks\n",
        "3. Programmatically set up an ontology and labeling project in Labelbox\n",
        "4. Load Bronze and Silver annotation tables from an example labeled project \n",
        "5. Additional cells describe how to handle video annotations and use Labelbox Diagnostics and Catalog \n",
        "\n",
        "Additional documentation links are provided at the end of the notebook."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "Thanks for trying out the Databricks and Labelbox Connector! You or someone from your organization signed up for a Labelbox trial through Databricks Partner Connect. This notebook was loaded into your Shared directory to help illustrate how Labelbox and Databricks can be used together to power unstructured data workflows. \n",
        "\n",
        "Labelbox can be used to rapidly annotate a variety of unstructured data from your Data Lake ([images](https://labelbox.com/product/image), [video](https://labelbox.com/product/video), [text](https://labelbox.com/product/text), and [geospatial tiled imagery](https://docs.labelbox.com/docs/tiled-imagery-editor)) and the Labelbox Connector for Databricks makes it easy to bring the annotations back into your Lakehouse environment for AI/ML and analytical workflows. \n",
        "\n",
        "If you would like to watch a video of the workflow, check out our [Data & AI Summit Demo](https://databricks.com/session_na21/productionizing-unstructured-data-for-ai-and-analytics). \n",
        "\n",
        "\n",
        "<img src=\"https://labelbox.com/static/images/partnerships/collab-chart.svg\" alt=\"example-workflow\" width=\"800\"/>\n",
        "\n",
        "<h5>Questions or comments? Reach out to us at [ecosystem+databricks@labelbox.com](mailto:ecosystem+databricks@labelbox.com)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "%pip install labelbox labelspark"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#This will import Koalas or Pandas-on-Spark based on your DBR version. \n",
        "from pyspark import SparkContext\n",
        "from packaging import version\n",
        "sc = SparkContext.getOrCreate()\n",
        "if version.parse(sc.version) < version.parse(\"3.2.0\"):\n",
        "  import databricks.koalas as pd \n",
        "  needs_koalas = True  \n",
        "else:\n",
        "  import pyspark.pandas as pd\n",
        "  needs_koalas = False"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Configure the SDK\n",
        "\n",
        "Now that Labelbox and the Databricks libraries have been installed, you will need to configure the SDK. You will need an API key that you can create through the app [here](https://app.labelbox.com/account/api-keys). You can also store the key using Databricks Secrets API. The SDK will attempt to use the env var `LABELBOX_API_KEY`"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import labelspark\n",
        "\n",
        "API_KEY = \"\" \n",
        "\n",
        "if not(API_KEY):\n",
        "  raise ValueError(\"Go to Labelbox to get an API key\")\n",
        "  \n",
        "client = lb.Client(API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Create seed data\n",
        "\n",
        "Next we'll load a demo dataset into a Spark table so you can see how to easily load assets into Labelbox via URLs with the Labelbox Connector for Databricks. \n",
        "\n",
        "Also, Labelbox has native support for AWS, Azure, and GCP cloud storage. You can connect Labelbox to your storage via [Delegated Access](https://docs.labelbox.com/docs/iam-delegated-access) and easily load those assets for annotation. For more information, you can watch this [video](https://youtu.be/wlWo6EmPDV4).\n",
        "\n",
        "You can also add data to Labelbox [using the Labelbox SDK directly](https://docs.labelbox.com/docs/datasets-datarows). We recommend using the SDK if you have complicated dataset creation requirements (e.g. including metadata with your dataset) which aren't handled by the Labelbox Connector for Databricks."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "sample_dataset_dict = {\"external_id\":[\"sample1.jpg\",\n",
        "                                     \"sample2.jpg\",\n",
        "                                     \"sample3.jpg\",\n",
        "                                     \"sample4.jpg\",\n",
        "                                     \"sample5.jpg\",\n",
        "                                     \"sample6.jpg\",\n",
        "                                     \"sample7.jpg\",\n",
        "                                     \"sample8.jpg\",\n",
        "                                     \"sample9.jpg\",\n",
        "                                     \"sample10.jpg\"],\n",
        "                      \"row_data\":[\"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000247422.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000484849.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000215782.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_val2014_000000312024.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000486139.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000302713.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000523272.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000094514.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_val2014_000000050578.jpg\",\n",
        "                                  \"https://storage.googleapis.com/diagnostics-demo-data/coco/COCO_train2014_000000073727.jpg\"]}\n",
        "\n",
        "df = pd.DataFrame.from_dict(sample_dataset_dict).to_spark() #produces our demo Spark table of datarows for Labelbox"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# can parse the directory and make a Spark table of image URLs\n",
        "SAMPLE_TABLE = \"sample_unstructured_data\"\n",
        "\n",
        "tblList = spark.catalog.listTables()\n",
        "\n",
        "if not any([table.name == SAMPLE_TABLE for table in tblList]):\n",
        "  df.createOrReplaceTempView(SAMPLE_TABLE)\n",
        "  print(f\"Registered table: {SAMPLE_TABLE}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "You should now have a temporary table \"sample_unstructured_data\" which includes the file names and URLs for some demo images. We're going to use this table with Labelbox using the Labelbox Connector for Databricks!"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "display(sqlContext.sql(f\"select * from {SAMPLE_TABLE} LIMIT 5\"))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Create a Labeling Project\n",
        "\n",
        "Projects are where teams create labels. A project is requires a dataset of assets to be labeled and an ontology to configure the labeling interface.\n",
        "\n",
        "### Step 1: Create a dataaset\n",
        "\n",
        "The [Labelbox Connector for Databricks](https://pypi.org/project/labelspark/) expects a spark table with two columns; the first column \"external_id\" and second column \"row_data\"\n",
        "\n",
        "external_id is a filename, like \"birds.jpg\" or \"my_video.mp4\"\n",
        "\n",
        "row_data is the URL path to the file. Labelbox renders assets locally on your users' machines when they label, so your labeler will need permission to access that asset. \n",
        "\n",
        "Example: \n",
        "\n",
        "| external_id | row_data                             |\n",
        "|-------------|--------------------------------------|\n",
        "| image1.jpg  | https://url_to_your_asset/image1.jpg |\n",
        "| image2.jpg  | https://url_to_your_asset/image2.jpg |\n",
        "| image3.jpg  | https://url_to_your_asset/image3.jpg |"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "unstructured_data = spark.table(SAMPLE_TABLE)\n",
        "\n",
        "demo_dataset = labelspark.create_dataset(client, unstructured_data, name = \"Databricks Demo Dataset\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "print(\"Open the dataset in the App\")\n",
        "print(f\"https://app.labelbox.com/data/{demo_dataset.uid}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 2: Create a project\n",
        "\n",
        "You can use the labelbox SDK to build your ontology (we'll do that next) You can also set your project up entirely through our website at app.labelbox.com.\n",
        "\n",
        "Check out our [ontology creation documentation.](https://docs.labelbox.com/docs/configure-ontology)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a new project\n",
        "project_demo = client.create_project(name=\"Labelbox and Databricks Example\", media_type=lb.MediaType.Image)\n",
        "project_demo.datasets.connect(demo_dataset)  # add the dataset to the queue\n",
        "\n",
        "ontology = lb.OntologyBuilder()\n",
        "\n",
        "tools = [\n",
        "  lb.Tool(tool=lb.Tool.Type.BBOX, name=\"Car\"),\n",
        "  lb.Tool(tool=lb.Tool.Type.BBOX, name=\"Flower\"),\n",
        "  lb.Tool(tool=lb.Tool.Type.BBOX, name=\"Fruit\"),\n",
        "  lb.Tool(tool=lb.Tool.Type.BBOX, name=\"Plant\"),\n",
        "  lb.Tool(tool=lb.Tool.Type.SEGMENTATION, name=\"Bird\"),\n",
        "  lb.Tool(tool=lb.Tool.Type.SEGMENTATION, name=\"Person\"),\n",
        "  lb.Tool(tool=lb.Tool.Type.SEGMENTATION, name=\"Dog\"),\n",
        "  lb.Tool(tool=lb.Tool.Type.SEGMENTATION, name=\"Gemstone\"),\n",
        "]\n",
        "for tool in tools: \n",
        "  ontology.add_tool(tool)\n",
        "\n",
        "conditions = [\"clear\", \"overcast\", \"rain\", \"other\"]\n",
        "\n",
        "weather_classification = lb.Classification(\n",
        "    class_type=lb.Classification.Type.RADIO,\n",
        "    instructions=\"what is the weather?\", \n",
        "    options=[lb.Option(value=c) for c in conditions]\n",
        ")  \n",
        "ontology.add_classification(weather_classification)\n",
        "\n",
        "\n",
        "# Setup editor\n",
        "for editor in client.get_labeling_frontends():\n",
        "    if editor.name == 'Editor':\n",
        "        project_demo.setup(editor, ontology.asdict()) \n",
        "\n",
        "print(\"Project Setup is complete.\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 3: Go label data"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "print(\"Open the project to start labeling\")\n",
        "print(f\"https://app.labelbox.com/projects/{project_demo.uid}/overview\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "raise ValueError(\"Go label some data before continuing\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Exporting labels/annotations\n",
        "\n",
        "After creating labels in Labelbox you can export them to use in Databricks for model training and analysis."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "LABEL_TABLE = \"exported_labels\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "labels_table = labelspark.get_annotations(client, project_demo.uid, spark, sc)\n",
        "labels_table.createOrReplaceTempView(LABEL_TABLE)\n",
        "display(labels_table)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Other features of Labelbox\n",
        "\n",
        "[Model Assisted Labeling](https://docs.labelbox.com/docs/model-assisted-labeling)\n",
        "<br>Once you train a model on your initial set of unstructured data, you can plug that model into Labelbox to support a Model Assisted Labeling workflow. Review the outputs of your model, make corrections, and retrain with ease! You can reduce future labeling costs by >50% by leveraging model assisted labeling.\n",
        "\n",
        "<img src=\"https://files.readme.io/4c65e12-model-assisted-labeling.png\" alt=\"MAL\" width=\"800\"/>\n",
        "\n",
        "[Catalog](https://docs.labelbox.com/docs/catalog)\n",
        "<br>Once you've created datasets and annotations in Labelbox, you can easily browse your datasets and curate new ones in Catalog. Use your model embeddings to find images by similarity search. \n",
        "\n",
        "<img src=\"https://files.readme.io/14f82d4-catalog-marketing.jpg\" alt=\"Catalog\" width=\"800\"/>\n",
        "\n",
        "[Model Diagnostics](https://labelbox.com/product/model-diagnostics)\n",
        "<br>Labelbox complements your MLFlow experiment tracking with the ability to easily visualize experiment predictions at scale. Model Diagnostics helps you quickly identify areas where your model is weak so you can collect the right data and refine the next model iteration. \n",
        "\n",
        "<img src=\"https://images.ctfassets.net/j20krz61k3rk/4LfIELIjpN6cou4uoFptka/20cbdc38cc075b82f126c2c733fb7082/identify-patterns-in-your-model-behavior.png\" alt=\"Diagnostics\" width=\"800\"/>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "While using the Labelbox Connector for Databricks, you will likely use the Labelbox SDK (e.g. for programmatic ontology creation). These resources will help familiarize you with the Labelbox Python SDK: \n",
        "* [Visit our docs](https://labelbox.com/docs/python-api) to learn how the SDK works\n",
        "* Checkout our [notebook examples](https://github.com/Labelbox/labelspark/tree/master/notebooks) to follow along with interactive tutorials\n",
        "* view our [API reference](https://labelbox.com/docs/python-api/api-reference).\n",
        "\n",
        "<b>Questions or comments? Reach out to us at [ecosystem+databricks@labelbox.com](mailto:ecosystem+databricks@labelbox.com)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "Copyright Labelbox, Inc. 2022. The source in this notebook is provided subject to the [Labelbox Terms of Service](https://docs.labelbox.com/page/terms-of-service).  All included or referenced third party libraries are subject to the licenses set forth below.\n",
        "\n",
        "|Library Name|Library license | Library License URL | Library Source URL |\n",
        "|---|---|---|---|\n",
        "|Labelbox Python SDK|Apache-2.0 License |https://github.com/Labelbox/labelbox-python/blob/develop/LICENSE|https://github.com/Labelbox/labelbox-python\n",
        "|Labelbox Connector for Databricks|Apache-2.0 License |https://github.com/Labelbox/labelspark/blob/master/LICENSE|https://github.com/Labelbox/labelspark\n",
        "|Python|Python Software Foundation (PSF) |https://github.com/python/cpython/blob/master/LICENSE|https://github.com/python/cpython|\n",
        "|Apache Spark|Apache-2.0 License |https://github.com/apache/spark/blob/master/LICENSE|https://github.com/apache/spark|"
      ],
      "cell_type": "markdown"
    }
  ]
}