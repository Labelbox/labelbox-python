{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/model_experiments/model_diagnostics/model_diagnostics_demo.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/model_experiments/model_diagnostics/model_diagnostics_demo.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "# Model Diagnostics\n",
        "\n",
        "\n",
        "Throughout the process of training your machine learning (ML) model, you may want to investigate your model's failures in order to understand which areas need improvement. Looking at an error analysis after each training iteration can help you understand whether you need to revise your annotations, make your ontology more clear, or create more training data that targets a specific area.\n",
        "Labelbox now offers a Model Diagnostics tool that analyzes the performance of your model's predictions in a single interface.\n",
        "With Model Diagnostics, you can:\n",
        "*   Inspect model behavior across experiments\n",
        "*   Adjust model hyperparameters and visualize model failures\n",
        "*   Use the Python SDK to create the analysis pipeline\n",
        "\n",
        "## How it works\n",
        "\n",
        "Configuring Model Diagnostics is all done via the SDK. We have created a Google colab notebook to demonstrate this process. The notebook also includes a section that leverages MAL in order to quickly create ground truth annotations.\n",
        "An Experiment is a specific instance of a model generating output in the form of predictions.\n",
        "In Labelbox, the `Model` object represents your ML model and it is what you'll be performing experiments on. It references a set of annotations specified by an ontology. \n",
        "The `Model Run` object represents the experiment itself. It is a specific instance of a `Model` with preconfigured hyperparameters (training data). You can upload inferences across each `Model Run`, filter by IoU score, and compare your model's predictions against the annotations from your training data.\n",
        "\n",
        "## Steps\n",
        "1. Make sure you are signed up for the beta. If not navigate here https://labelbox.com/product/model-diagnostics\n",
        "2. Have a set of ground truth labels in a project\n",
        "3. Install the latest SDK release\n",
        "4. Create a `Model`\n",
        "5. Create a `Model Run`\n",
        "6. Compute predictions\n",
        "7. Compute model performance metrics\n",
        "8. Upload labels, predictions, and metrics\n",
        "9. Navigate to the `Models` tab on Labelbox\n",
        "\n",
        "## Best practices\n",
        "Currently there is a limit of 2000 images per model run. We suggest uploading lower performing examples from your test set.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "from labelbox.schema.conflict_resolution_strategy import ConflictResolutionStrategy\n",
        "import uuid"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Install dependencies"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q \"labelbox[data]\""
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# API Key and Client\n",
        "\n",
        "Provide a valid API key below in order to properly connect to the Labelbox Client."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Add your API key\n",
        "API_KEY = \"\"\n",
        "# To get your API key go to: Workspace settings -> API -> Create API Key\n",
        "client = lb.Client(api_key=API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# End-to-end Demo: Setup Labelbox and Create Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Import data rows into catelog"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# send a sample image as data row for a dataset\n",
        "global_key = str(uuid.uuid4())\n",
        "\n",
        "test_img_url = {\n",
        "    \"row_data\":\n",
        "        \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/2560px-Kitano_Street_Kobe01s5s4110.jpeg\",\n",
        "    \"global_key\":\n",
        "        global_key\n",
        "}\n",
        "\n",
        "dataset = client.create_dataset(name=\"foundry-demo-dataset\")\n",
        "task = dataset.create_data_rows([test_img_url])\n",
        "task.wait_till_done()\n",
        "\n",
        "print(f\"Errors: {task.errors}\")\n",
        "print(f\"Failed data rows: {task.failed_data_rows}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Create/select an ontology that matches model\n",
        "\n",
        "We will be using Foundry to generate our predictions.\n",
        "\n",
        "The project that you will be using must have the correct ontology setup with all the tools and classifications supported for your model and data type.\n",
        "\n",
        "For example, in this tutorial we will be using Google Gem you would need to create a bounding box annotation for your ontology since it only supports object detection."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create ontology with two bounding boxes that is included with Amazon Rekognition: Car and Person \n",
        "ontology_builder = lb.OntologyBuilder(\n",
        "    classifications=[],\n",
        "    tools=[\n",
        "        lb.Tool(tool=lb.Tool.Type.BBOX, name=\"Car\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.BBOX, name=\"Person\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Model Diagnostics Demo\",\n",
        "                                  ontology_builder.asdict(),\n",
        "                                  media_type=lb.MediaType.Image)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Create a labeling project\n",
        "\n",
        "Connect the ontology to the labeling project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "project = client.create_project(name=\"Model Diagnostics Model Demo\",\n",
        "                                media_type=lb.MediaType.Image)\n",
        "\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Create foundry application in UI\n",
        "\n",
        "Currently we do not support this workflow through the SDK\n",
        "#### Workflow:\n",
        "\n",
        "1. Navigate to model and select ***Create*** > ***App***\n",
        "\n",
        "2. Select ***Amazon Rekognition*** and name your foundry application\n",
        "\n",
        "3. Customize your perimeters and then select ***Save & Create***"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#Select your foundry application inside the UI and copy the APP ID from the top right corner\n",
        "AMAZON_REKOGNITION_APP_ID = \"\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 5: Run foundry app on data rows\n",
        "\n",
        "This step is meant to generate predictions that can later be used for your model run. You must provide your app ID from the previous step for this method to run, please see the [Foundry Apps Guide](https://docs.labelbox.com/docs/foundry-apps#run-app-using-sdk) for more information."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "task = client.run_foundry_app(model_run_name=f\"Amazon-{str(uuid.uuid4())}\",\n",
        "                              data_rows=lb.GlobalKeys(\n",
        "                                  [global_key] # Provide a list of global keys \n",
        "                                  ), \n",
        "                              app_id=AMAZON_REKOGNITION_APP_ID)\n",
        "\n",
        "task.wait_till_done()\n",
        "\n",
        "print(f\"Errors: {task.errors}\") \n",
        "\n",
        "#Obtain model run ID from task\n",
        "MODEL_RUN_ID = task.metadata[\"modelRunId\"]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Create Predictions\n",
        "* Use foundry to create predictions"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# --- setup dataset ---\n",
        "# load mapillary sample\n",
        "sample_csv_url = \"https://raw.githubusercontent.com/Labelbox/labelbox-python/master/examples/assets/mapillary_sample.csv\"\n",
        "with requests.get(sample_csv_url, stream=True) as r:\n",
        "    image_data = [\n",
        "        row.split(',')\n",
        "        for row in (line.decode('utf-8') for line in r.iter_lines())\n",
        "    ]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "predictions = list()\n",
        "for (image_url, external_id) in notebook.tqdm(image_data[:10]):\n",
        "    image = lb_types.ImageData(url=image_url, external_id=external_id)\n",
        "    height, width = image.value.shape[:2]\n",
        "    prediction = predict(np.array([image.im_bytes]),\n",
        "                         min_score=0.5,\n",
        "                         height=height,\n",
        "                         width=width)\n",
        "    boxes, classes, seg_masks = prediction[\"boxes\"], prediction[\n",
        "        \"class_indices\"], prediction[\"seg_masks\"]\n",
        "    annotations = []\n",
        "    for box, class_idx, seg in zip(boxes, classes, seg_masks):\n",
        "        if class_idx in class_mappings:\n",
        "            class_info = class_mappings.get(class_idx)\n",
        "            if class_info['kind'] == lb.Tool.Type.POLYGON:\n",
        "                contours = measure.find_contours(seg, 0.5)\n",
        "                pts = contours[0].astype(np.int32)\n",
        "                value = lb_types.Polygon(points=[\n",
        "                    lb_types.Point(x=x, y=y) for x, y in np.roll(pts, 1, axis=-1)\n",
        "                ])\n",
        "            elif class_info['kind'] == lb.Tool.Type.BBOX:\n",
        "                value = lb_types.Rectangle(start=lb_types.Point(x=box[1], y=box[0]),\n",
        "                                  end=lb_types.Point(x=box[3], y=box[2]))\n",
        "            elif class_info['kind'] == lb.Tool.Type.POINT:\n",
        "                value = lb_types.Point(x=(box[1] + box[3]) / 2.,\n",
        "                              y=(box[0] + box[2]) / 2.)\n",
        "            elif class_info['kind'] == lb.Tool.Type.SEGMENTATION:\n",
        "                value = lb_types.Mask(mask=lb_types.MaskData.from_2D_arr(seg *\n",
        "                                                       class_info['color']),\n",
        "                             color=(class_info['color'],) * 3)\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\"Unsupported kind found. {class_info['kind']}\")\n",
        "            annotations.append(\n",
        "                lb_types.ObjectAnnotation(name=class_info['name'], value=value))\n",
        "    predictions.append(lb_types.Label(data=image, annotations=annotations))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup a project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# --- Use the class mapping specified above ( Will include all specified classes )\n",
        "tools = []\n",
        "for target in class_mappings.values():\n",
        "    tools.append(lb.Tool(tool=target['kind'], name=target[\"name\"]))\n",
        "ontology_builder = lb.OntologyBuilder(tools=tools)\n",
        "\n",
        "# --- Optionally Setup ontology from predictions ( Only will include predicted classes )\n",
        "#ontology_builder = predictions.get_ontology()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "print(f\"Setting up: {PROJECT_NAME}\")\n",
        "\n",
        "project = client.create_project(name=PROJECT_NAME, media_type=lb.MediaType.Image)\n",
        "editor = next(\n",
        "    client.get_labeling_frontends(where=lb.LabelingFrontend.name == \"Editor\"))\n",
        "project.setup(editor, ontology_builder.asdict())\n",
        "\n",
        "dataset = client.create_dataset(name=\"Mapillary Diagnostics Demo\")\n",
        "print(f\"Dataset Created: {dataset.uid}\")\n",
        "project.create_batches_from_dataset(\"batch\", dataset.uid)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Prepare for upload\n",
        "* Our local annotations need the following:\n",
        "    1. signed url for segmentation masks\n",
        "    2. data rows in labelbox\n",
        "    3. feature schema ids"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "signer = lambda _bytes: client.upload_data(content=_bytes, sign=True)\n",
        "predictions.add_url_to_masks(signer) \\\n",
        "         .add_url_to_data(signer) \\\n",
        "         .add_to_dataset(dataset, client.upload_data)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## **Optional** - Create labels with [Model Assisted Labeling](https://docs.labelbox.com/en/core-concepts/model-assisted-labeling)\n",
        "\n",
        "* Pre-label image so that we can quickly create ground truth\n",
        "* Create ground truth data for Model Diagnostics\n",
        "* Click on link below to label"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "RUN_MAL = True\n",
        "if RUN_MAL:\n",
        "    project.enable_model_assisted_labeling()\n",
        "    # Convert from annotation types to import format\n",
        "    upload_task = lb.MALPredictionImport.create_from_objects(\n",
        "        client, project.uid, f'mal-import-{uuid.uuid4()}', predictions)\n",
        "    upload_task.wait_until_done()\n",
        "    print(upload_task.state, '\\n')"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "print(f\"https://app.labelbox.com/go-label/{project.uid}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Export Labels\n",
        "\n",
        "We do not support `Skipped` labels and have a limit of **2000**"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "MAX_LABELS = 2000\n",
        "labels = [\n",
        "    l for idx, l in enumerate(project.label_generator()) if idx < MAX_LABELS\n",
        "]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Model & Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "lb_model = client.create_model(name=MODEL_NAME,\n",
        "                               ontology_id=project.ontology().uid)\n",
        "lb_model_run = lb_model.create_model_run(MODEL_VERSION)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Select label ids to upload"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "lb_model_run.upsert_labels([label.uid for label in labels])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Compute Metrics"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "pairs = get_label_pairs(labels, predictions, filter_mismatch=True)\n",
        "for (ground_truth, prediction) in pairs.values():\n",
        "    metrics = []\n",
        "    metrics.extend(\n",
        "        feature_miou_metric(ground_truth.annotations, prediction.annotations))\n",
        "    metrics.extend(\n",
        "        feature_confusion_matrix_metric(ground_truth.annotations,\n",
        "                                        prediction.annotations))\n",
        "    prediction.annotations.extend(metrics)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Upload to Labelbox"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_task = lb_model_run.add_predictions(\n",
        "    f'diagnostics-import-{uuid.uuid4()}', predictions)\n",
        "upload_task.wait_until_done()\n",
        "print(upload_task.state)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Open Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "for idx, model_run_data_row in enumerate(lb_model_run.model_run_data_rows()):\n",
        "    if idx == 5:\n",
        "        break\n",
        "    print(model_run_data_row.url)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Export model run labels"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "MODEL_ID = ''\n",
        "MODEL_RUN_ID = ''\n",
        "model = client.get_model(MODEL_ID)\n",
        "\n",
        "model_run = next(filter(lambda run: run['id'] == MODEL_RUN_ID, model.model_runs), None)\n",
        "labels = model_run.export_labels(download=True)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}