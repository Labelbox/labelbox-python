{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>",
        "</td>\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/basics/data_rows.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/basics/data_rows.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Data rows"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "* Data rows are the assets that are being labeled. We currently support the following asset types:\n",
        "    * Image\n",
        "    * Text\n",
        "    * Video\n",
        "    * Geospatial / Tiled Imagery\n",
        "    * Audio\n",
        "    * Documents \n",
        "    * HTML \n",
        "    * DICOM \n",
        "    * Conversational\n",
        "* A data row cannot exist without belonging to a dataset.\n",
        "* Data rows are added to labeling tasks by first attaching them to datasets and then creating batches in projects"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "%pip install labelbox -q",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "import labelbox as lb\nimport uuid\nimport json",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# API Key and Client\n",
        "Provide a valid api key below in order to properly connect to the Labelbox Client."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Add your api key\nAPI_KEY = \"\"\nclient = lb.Client(api_key=API_KEY)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Get data rows from projects"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Pick a project with batches that have data rows with global keys\nPROJECT_ID = \"<PROJECT-ID>\"\nproject = client.get_project(PROJECT_ID)\nbatches = list(project.batches())\nprint(batches)\n# This is the same as\n# -> dataset = client.get_dataset(dataset_id)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Fetch data rows from project's batches\n",
        "\n",
        "Batches will need to be exported from your project as a export parameter. Before you can export from a project you will need an ontology attached."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "client.enable_experimental = True\n\nbatch_ids = [batch.uid for batch in batches]\n\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"performance_details\": True,\n    \"batch_ids\":\n        batch_ids,  # Include batch ids if you only want to export specific batches, otherwise,\n    # you can export all the data without using this parameter\n}\nfilters = {}\n\n# A task is returned, this provides additional information about the status of your task, such as\n# any errors encountered\nexport_task = project.export(params=export_params, filters=filters)\nexport_task.wait_till_done()",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "data_rows = []\n\n\ndef json_stream_handler(output: lb.BufferedJsonConverterOutput):\n    data_row = output.json\n    data_rows.append(data_row)\n\n\nif export_task.has_errors():\n    export_task.get_buffered_stream(stream_type=lb.StreamType.ERRORS).start(\n        stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    export_json = export_task.get_buffered_stream(\n        stream_type=lb.StreamType.RESULT).start(\n            stream_handler=json_stream_handler)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "# Get single data row\ndata_row = data_rows[0]\nprint(data_row)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Get labels from the data row"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "print(\"Associated label(s)\", data_row[\"projects\"][project.uid][\"labels\"])\nprint(\"Global key\", data_row[\"data_row\"][\"global_key\"])",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Get data row ids by using global keys"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "global_key = \"<ENTER GLOBAL KEY>\"\ntask = client.get_data_row_ids_for_global_keys([global_key])\nprint(f\"Data row id: {task['results']}\")",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Create\n",
        "We recommend the following methods to create data rows : `dataset.upsert_data_rows()`, and `dataset.create_data_rows()`, "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Create data rows via `dataset.upsert_data_rows()`"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Create a dataset\ndataset = client.create_dataset(name=\"data_rows_demo_dataset_6\")\n# You can also upload metadata along with your data row\nmdo = client.get_data_row_metadata_ontology()",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "uploads = []\n# Generate data rows\nfor i in range(1, 8):\n    uploads.append({\n        \"row_data\":\n            f\"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_000{i}.jpeg\",\n        \"global_key\":\n            \"TEST-ID-%id\" % uuid.uuid1(),\n        ## add metadata (optional)\n        \"metadata_fields\": [\n            lb.DataRowMetadataField(\n                schema_id=mdo.reserved_by_name[\"tag\"].\n                uid,  # specify the schema id\n                value=\"tag_string\",  # typed inputs\n            ),\n        ],\n        \"attachments\": [\n            {\n                \"type\":\n                    \"IMAGE_OVERLAY\",\n                \"value\":\n                    \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/disease_attachment.jpeg\",\n            },\n            {\n                \"type\": \"RAW_TEXT\",\n                \"value\": \"IOWA, Zone 2232, June 2022 [Text string]\",\n            },\n            {\n                \"type\":\n                    \"TEXT_URL\",\n                \"value\":\n                    \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/text_attachment.txt\",\n            },\n            {\n                \"type\":\n                    \"IMAGE\",\n                \"value\":\n                    \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/disease_attachment.jpeg\",\n            },\n            {\n                \"type\":\n                    \"VIDEO\",\n                \"value\":\n                    \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/drone_video.mp4\",\n            },\n            {\n                \"type\":\n                    \"HTML\",\n                \"value\":\n                    \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/windy.html\",\n            },\n            {\n                \"type\":\n                    \"PDF_URL\",\n                \"value\":\n                    \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483.pdf\",\n            },\n        ],\n    })\n\ntask1 = dataset.upsert_data_rows(uploads)\ntask1.wait_till_done()\nprint(\"ERRORS: \", task1.errors)\nprint(\"RESULTS:\", task1.result)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Create data rows from data in your local path "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "from PIL import Image\n\n# Create dummy empty jpeg file\nwidth = 400\nheight = 300\ncolor = (255, 255, 255)  # White color\nimage = Image.new(\"RGB\", (width, height), color)\n\n# Save the image as a JPEG file\nimage.save(\"dummy.jpg\")\n\nlocal_data_path = \"dummy.jpg\"\n\ndata = {\"row_data\": local_data_path, \"global_key\": str(uuid.uuid4())}\n\ntask3 = dataset.upsert_data_rows([data])\ntask3.wait_till_done()\nprint(\"ERRORS: \", task3.errors)\nprint(\"RESULTS:\", task3.result)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "# You can mix local files with urls when creating data rows\ntask4 = dataset.upsert_data_rows([\n    {\n        \"row_data\":\n            \"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_0009.jpeg\",\n        \"global_key\":\n            str(uuid.uuid4()),\n    },\n    {\n        \"row_data\": local_data_path,\n        \"global_key\": str(uuid.uuid4())\n    },\n])\ntask4.wait_till_done()\nprint(\"ERRORS: \", task4.errors)\nprint(\"RESULTS:\", task4.result)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Create data rows via `dataset.create_data_rows()`\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "dataset_2 = client.create_dataset(name=\"data_rows_demo_dataset_3\")",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "uploads = []\n# Generate data rows\nfor i in range(1, 9):\n    uploads.append({\n        \"row_data\":\n            f\"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_000{i}.jpeg\",\n        \"global_key\":\n            \"TEST-ID-%id\" % uuid.uuid1(),\n        ## add metadata (optional)\n        \"metadata_fields\": [\n            lb.DataRowMetadataField(\n                schema_id=mdo.reserved_by_name[\"tag\"].\n                uid,  # specify the schema id\n                value=\"tag_string\",  # typed inputs\n            ),\n        ],\n    })\n\ntask1_2 = dataset_2.create_data_rows(uploads)\ntask1_2.wait_till_done()\nprint(\"ERRORS: \", task1_2.errors)\nprint(\"RESULTS:\", task1_2.result)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Update\n",
        "`dataset.upsert_data_rows()` can also be use to update data rows\n",
        "\n",
        "To update data rows using this method, you need to pass a `key`, which can reference either a global key or a data row ID. Additionally, include any fields that you wish to update along with their new values.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Fetch a data row from the first dataset example\nts = dataset.export()\nts.wait_till_done()\nDATA_ROW_ID = [output.json for output in ts.get_buffered_stream()\n              ][0][\"data_row\"][\"id\"]\nGLOBAL_KEY = [output.json for output in ts.get_buffered_stream()\n             ][0][\"data_row\"][\"global_key\"]\n\nprint(f\"Pick either a data row id : {DATA_ROW_ID} or global key: {GLOBAL_KEY}\")",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": "# Update the global key assodicated with the DATAROW_ID or GLOBAL_KEY, and include a additional metadata\ndata = {\n    \"key\":\n        lb.UniqueId(DATA_ROW_ID),\n    \"global_key\":\n        \"NEW-ID-%id\" % uuid.uuid1(),\n    \"metadata_fields\": [\n        # New metadata\n        lb.DataRowMetadataField(\n            schema_id=mdo.reserved_by_name[\"captureDateTime\"].uid,\n            value=\"2000-01-01 00:00:00\",\n        ),\n        # Include original metadata otherwise it will be removed\n        lb.DataRowMetadataField(\n            schema_id=mdo.reserved_by_name[\"tag\"].uid,\n            value=\"tag_string\",\n        ),\n    ],\n}\n\ntask5 = dataset_2.upsert_data_rows([data])\ntask5.wait_till_done()\nprint(\"ERRORS: \", task5.errors)\nprint(\"RESULTS:\", task5.result)",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Create a single attachment on an existing data row"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# You can only create one attachment at the time.\nDATA_ROW_ID = \"<DATA-ROW-ID>\"\ndata_row = client.get_data_row(DATA_ROW_ID)\nattachment = data_row.create_attachment(\n    attachment_type=\"RAW_TEXT\", attachment_value=\"LABELERS WILL SEE THIS\")",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Update a recently created attachment "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "attachment.update(type=\"RAW_TEXT\", value=\"NEW RAW TEXT\")",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Delete"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "* Delete a single data row"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "DATAROW_ID_TO_DELETE = \"<DATA-ROW-ID>\"\ndata_row = client.get_data_row(DATAROW_ID_TO_DELETE)\ndata_row.delete()",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "* Bulk delete data row objects"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": "# Bulk delete a list of data_rows ( limit: 4K data rows per call)\nlb.DataRow.bulk_delete(list(dataset.data_rows()))",
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}