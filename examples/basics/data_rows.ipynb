{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/basics/data_rows.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/basics/data_rows.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Data rows"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "* Data rows are the assets that are being labeled. We currently support the following asset types:\n",
        "    * Image\n",
        "    * Text\n",
        "    * Video\n",
        "    * Geospatial / Tiled Imagery\n",
        "    * Audio\n",
        "    * Documents \n",
        "    * HTML \n",
        "    * DICOM \n",
        "    * Conversational\n",
        "* A data row cannot exist without belonging to a dataset.\n",
        "* Data rows are added to labeling tasks by first attaching them to datasets and then creating batches in projects"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install labelbox -q"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import uuid\n",
        "import json"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# API Key and Client\n",
        "Provide a valid api key below in order to properly connect to the Labelbox Client."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Add your api key\n",
        "API_KEY = \"\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Get data rows from projects"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Pick a project with batches that have data rows with global keys\n",
        "PROJECT_ID = \"<PROJECT-ID>\"\n",
        "project = client.get_project(PROJECT_ID)\n",
        "batches = list(project.batches())\n",
        "print(batches)\n",
        "# This is the same as\n",
        "# -> dataset = client.get_dataset(dataset_id)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Fetch data rows from project's batches\n",
        "\n",
        "Batches will need to be exported from your project as a export parameter. Before you can export from a project you will need an ontology attached."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "client.enable_experimental = True\n",
        "\n",
        "batch_ids = [batch.uid for batch in batches]\n",
        "\n",
        "export_params = {\n",
        " \"attachments\": True,\n",
        "  \"metadata_fields\": True,\n",
        "  \"data_row_details\": True,\n",
        "  \"project_details\": True,\n",
        "  \"performance_details\": True,\n",
        "  \"batch_ids\" : batch_ids # Include batch ids if you only want to export specific batches, otherwise,\n",
        "  #you can export all the data without using this parameter\n",
        "}\n",
        "filters = {}\n",
        "\n",
        "# A task is returned, this provides additional information about the status of your task, such as\n",
        "# any errors encountered\n",
        "export_task = project.export(params=export_params, filters=filters)\n",
        "export_task.wait_till_done()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "data_rows = []\n",
        "\n",
        "def json_stream_handler(output: lb.JsonConverterOutput):\n",
        "  data_row = json.loads(output.json_str)\n",
        "  data_rows.append(data_row)\n",
        "\n",
        "\n",
        "if export_task.has_errors():\n",
        "  export_task.get_stream(\n",
        "  converter=lb.JsonConverter(),\n",
        "  stream_type=lb.StreamType.ERRORS\n",
        "  ).start(stream_handler=lambda error: print(error))\n",
        "\n",
        "if export_task.has_result():\n",
        "  export_json = export_task.get_stream(\n",
        "    converter=lb.JsonConverter(),\n",
        "    stream_type=lb.StreamType.RESULT\n",
        "  ).start(stream_handler=json_stream_handler)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Get single data row\n",
        "data_row = data_rows[0]\n",
        "print(data_row)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Get labels from the data row"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "print(\"Associated label(s)\", data_row[\"projects\"][project.uid][\"labels\"])\n",
        "print(\"Global key\", data_row[\"data_row\"][\"global_key\"])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Get data row ids by using global keys"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "global_key = \"<ENTER GLOBAL KEY>\"\n",
        "task = client.get_data_row_ids_for_global_keys([global_key])\n",
        "print(f\"Data row id: {task['results']}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Create\n",
        "We recommend the following methods to create data rows : `dataset.upsert_data_rows()`, and `dataset.create_data_rows()`, "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Create data rows via `dataset.upsert_data_rows()`"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a dataset\n",
        "dataset = client.create_dataset(name=\"data_rows_demo_dataset_6\")\n",
        "# You can also upload metadata along with your data row\n",
        "mdo = client.get_data_row_metadata_ontology()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "uploads = []\n",
        "# Generate data rows\n",
        "for i in range(1,8):\n",
        "    uploads.append({\n",
        "        \"row_data\":  f\"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_000{i}.jpeg\",\n",
        "        \"global_key\": \"TEST-ID-%id\" % uuid.uuid1(),\n",
        "        ## add metadata (optional)\n",
        "        \"metadata_fields\": [\n",
        "            lb.DataRowMetadataField(\n",
        "                schema_id=mdo.reserved_by_name[\"tag\"].uid,  # specify the schema id\n",
        "                value=\"tag_string\", # typed inputs\n",
        "            ),\n",
        "        ],\n",
        "        \"attachments\": [\n",
        "            {\n",
        "                \"type\": \"IMAGE_OVERLAY\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/disease_attachment.jpeg\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"RAW_TEXT\",\n",
        "                \"value\": \"IOWA, Zone 2232, June 2022 [Text string]\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"TEXT_URL\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/text_attachment.txt\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"IMAGE\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/disease_attachment.jpeg\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"VIDEO\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/drone_video.mp4\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"HTML\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/windy.html\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"PDF_URL\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483.pdf\"\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        "\n",
        "task1 = dataset.upsert_data_rows(uploads)\n",
        "task1.wait_till_done()\n",
        "print(\"ERRORS: \" , task1.errors)\n",
        "print(\"RESULTS:\" , task1.result)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Create data rows from data in your local path "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Create dummy empty jpeg file\n",
        "width = 400\n",
        "height = 300\n",
        "color = (255, 255, 255)  # White color\n",
        "image = Image.new(\"RGB\", (width, height), color)\n",
        "\n",
        "# Save the image as a JPEG file\n",
        "image.save(\"dummy.jpg\")\n",
        "\n",
        "local_data_path = \"dummy.jpg\"\n",
        "\n",
        "data = {\n",
        "  \"row_data\" : local_data_path,\n",
        "  \"global_key\": str(uuid.uuid4())\n",
        "}\n",
        "\n",
        "task3 = dataset.upsert_data_rows([data])\n",
        "task3.wait_till_done()\n",
        "print(\"ERRORS: \" , task3.errors)\n",
        "print(\"RESULTS:\" , task3.result)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# You can mix local files with urls when creating data rows\n",
        "task4 = dataset.upsert_data_rows([{\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_0009.jpeg\",\n",
        "    \"global_key\": str(uuid.uuid4())\n",
        "    }, {\n",
        "    \"row_data\": local_data_path,\n",
        "    \"global_key\": str(uuid.uuid4())\n",
        "    }])\n",
        "task4.wait_till_done()\n",
        "print(\"ERRORS: \" , task4.errors)\n",
        "print(\"RESULTS:\" , task4.result)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Create data rows via `dataset.create_data_rows()`\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "dataset_2 = client.create_dataset(name=\"data_rows_demo_dataset_3\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "uploads = []\n",
        "# Generate data rows\n",
        "for i in range(1,9):\n",
        "    uploads.append({\n",
        "        \"row_data\":  f\"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_000{i}.jpeg\",\n",
        "        \"global_key\": \"TEST-ID-%id\" % uuid.uuid1(),\n",
        "        ## add metadata (optional)\n",
        "        \"metadata_fields\": [\n",
        "            lb.DataRowMetadataField(\n",
        "                schema_id=mdo.reserved_by_name[\"tag\"].uid,  # specify the schema id\n",
        "                value=\"tag_string\", # typed inputs\n",
        "            ),\n",
        "        ]\n",
        "    })\n",
        "\n",
        "task1_2 = dataset_2.create_data_rows(uploads)\n",
        "task1_2.wait_till_done()\n",
        "print(\"ERRORS: \" , task1_2.errors)\n",
        "print(\"RESULTS:\" , task1_2.result)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Update\n",
        "`dataset.upsert_data_rows()` can also be use to update data rows\n",
        "\n",
        "To update data rows using this method, you need to pass a `key`, which can reference either a global key or a data row ID. Additionally, include any fields that you wish to update along with their new values.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Fetch a data row from the first dataset example\n",
        "ts = dataset.export()\n",
        "ts.wait_till_done()\n",
        "DATA_ROW_ID = [json.loads(output.json_str) for output in ts.get_stream()][0]['data_row']['id']\n",
        "GLOBAL_KEY = [json.loads(output.json_str) for output in ts.get_stream()][0]['data_row']['global_key']\n",
        "\n",
        "print(f\"Pick either a data row id : {DATA_ROW_ID} or global key: {GLOBAL_KEY}\")\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Update the global key assodicated with the DATAROW_ID or GLOBAL_KEY, and include a additional metadata\n",
        "data = {\n",
        "    \"key\": lb.UniqueId(DATA_ROW_ID),\n",
        "    \"global_key\": \"NEW-ID-%id\" % uuid.uuid1(),\n",
        "    \"metadata_fields\": [\n",
        "        # New metadata\n",
        "        lb.DataRowMetadataField(\n",
        "            schema_id=mdo.reserved_by_name['captureDateTime'].uid,\n",
        "            value=\"2000-01-01 00:00:00\"\n",
        "        ),\n",
        "        # Include original metadata otherwise it will be removed\n",
        "        lb.DataRowMetadataField(\n",
        "            schema_id=mdo.reserved_by_name[\"tag\"].uid,\n",
        "            value=\"tag_string\",\n",
        "        ),\n",
        "    ]\n",
        "}\n",
        "\n",
        "task5 = dataset_2.upsert_data_rows([data])\n",
        "task5.wait_till_done()\n",
        "print(\"ERRORS: \" , task5.errors)\n",
        "print(\"RESULTS:\" , task5.result)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Create a single attachment on an existing data row"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# You can only create one attachment at the time.\n",
        "DATA_ROW_ID = \"<DATA-ROW-ID>\"\n",
        "data_row = client.get_data_row(DATA_ROW_ID)\n",
        "attachment = data_row.create_attachment(attachment_type=\"RAW_TEXT\",\n",
        "                           attachment_value=\"LABELERS WILL SEE THIS\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Update a recently created attachment "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "attachment.update(type= \"RAW_TEXT\", value=\"NEW RAW TEXT\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Delete"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "* Delete a single data row"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "DATAROW_ID_TO_DELETE = \"<DATA-ROW-ID>\"\n",
        "data_row = client.get_data_row(DATAROW_ID_TO_DELETE)\n",
        "data_row.delete()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "* Bulk delete data row objects"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Bulk delete a list of data_rows ( limit: 4K data rows per call)\n",
        "lb.DataRow.bulk_delete(list(dataset.data_rows()))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}
