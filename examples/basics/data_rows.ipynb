{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/basics/data_rows.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/basics/data_rows.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Data rows are the assets that are being labeled. We currently support the following asset types:\n",
        "    * Image\n",
        "    * Text\n",
        "    * Video\n",
        "    * Geospatial / Tiled Imagery\n",
        "    * Audio\n",
        "    * Documents \n",
        "    * HTML \n",
        "    * DICOM \n",
        "    * Conversational\n",
        "* A data row cannot exist without belonging to a dataset.\n",
        "* Data rows are added to labeling tasks by first attaching them to datasets and then creating batches in projects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce83490f",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install labelbox -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "705b20eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import labelbox as lb\n",
        "import uuid\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# API Key and Client\n",
        "Provide a valid api key below in order to properly connect to the Labelbox Client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add your api key\n",
        "API_KEY = \"\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get data rows from projects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "AuthenticationError",
          "evalue": "Invalid API key('Invalid API key', None)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pick a project with batches that have data rows with global keys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m PROJECT_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<PROJECT-ID>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(project\u001b[38;5;241m.\u001b[39mbatches())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(batches)\n",
            "File \u001b[0;32m~/repos/labelbox-python/env/lib/python3.10/site-packages/labelbox/client.py:480\u001b[0m, in \u001b[0;36mClient.get_project\u001b[0;34m(self, project_id)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_project\u001b[39m(\u001b[38;5;28mself\u001b[39m, project_id) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Project:\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Gets a single Project with the given ID.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03m    >>> project = client.get_project(\"<project_id>\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m            Project with the given ID.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEntity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/repos/labelbox-python/env/lib/python3.10/site-packages/labelbox/client.py:459\u001b[0m, in \u001b[0;36mClient._get_single\u001b[0;34m(self, db_object_type, uid)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Fetches a single object of the given type, for the given ID.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m        of the given type for the given ID.\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m query_str, params \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mget_single(db_object_type, uid)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m res \u001b[38;5;241m=\u001b[39m res \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39mget(utils\u001b[38;5;241m.\u001b[39mcamel_case(db_object_type\u001b[38;5;241m.\u001b[39mtype_name()))\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/repos/labelbox-python/env/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/repos/labelbox-python/env/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
            "File \u001b[0;32m~/repos/labelbox-python/env/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
            "File \u001b[0;32m~/repos/labelbox-python/env/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
            "File \u001b[0;32m~/repos/labelbox-python/env/lib/python3.10/site-packages/labelbox/client.py:256\u001b[0m, in \u001b[0;36mClient.execute\u001b[0;34m(self, query, params, data, files, timeout, experimental, error_log_key)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_errors([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUTHENTICATION_ERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextensions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    255\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m labelbox\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mAuthenticationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid API key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    258\u001b[0m authorization_error \u001b[38;5;241m=\u001b[39m check_errors([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUTHORIZATION_ERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    259\u001b[0m                                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextensions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m authorization_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Invalid API key('Invalid API key', None)"
          ]
        }
      ],
      "source": [
        "# Pick a project with batches that have data rows with global keys\n",
        "PROJECT_ID = \"<PROJECT-ID>\"\n",
        "project = client.get_project(PROJECT_ID)\n",
        "batches = list(project.batches())\n",
        "print(batches)\n",
        "# This is the same as\n",
        "# -> dataset = client.get_dataset(dataset_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetch data rows from project's batches\n",
        "\n",
        "Batches will need to be exported from your project as a export parameter. Before you can export from a project you will need an ontology attached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.enable_experimental = True\n",
        "\n",
        "batch_ids = [batch.uid for batch in batches]\n",
        "\n",
        "export_params = {\n",
        " \"attachments\": True,\n",
        "  \"metadata_fields\": True,\n",
        "  \"data_row_details\": True,\n",
        "  \"project_details\": True,\n",
        "  \"performance_details\": True,\n",
        "  \"batch_ids\" : batch_ids # Include batch ids if you only want to export specific batches, otherwise,\n",
        "  #you can export all the data without using this parameter\n",
        "}\n",
        "filters = {}\n",
        "\n",
        "# A task is returned, this provides additional information about the status of your task, such as\n",
        "# any errors encountered\n",
        "export_task = project.export(params=export_params, filters=filters)\n",
        "export_task.wait_till_done()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_rows = []\n",
        "\n",
        "def json_stream_handler(output: lb.JsonConverterOutput):\n",
        "  data_row = json.loads(output.json_str)\n",
        "  data_rows.append(data_row)\n",
        "\n",
        "\n",
        "if export_task.has_errors():\n",
        "  export_task.get_stream(\n",
        "  converter=lb.JsonConverter(),\n",
        "  stream_type=lb.StreamType.ERRORS\n",
        "  ).start(stream_handler=lambda error: print(error))\n",
        "\n",
        "if export_task.has_result():\n",
        "  export_json = export_task.get_stream(\n",
        "    converter=lb.JsonConverter(),\n",
        "    stream_type=lb.StreamType.RESULT\n",
        "  ).start(stream_handler=json_stream_handler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get single data row\n",
        "data_row = data_rows[0]\n",
        "print(data_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get labels from the data row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Associated label(s)\", data_row[\"projects\"][project.uid][\"labels\"])\n",
        "print(\"Global key\", data_row[\"data_row\"][\"global_key\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get data row ids by using global keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "global_key = \"<ENTER GLOBAL KEY>\"\n",
        "task = client.get_data_row_ids_for_global_keys([global_key])\n",
        "print(f\"Data row id: {task['results']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create\n",
        "We recommend the following methods to create data rows : `dataset.upsert_data_rows()`, and `dataset.create_data_rows()`, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create data rows via `dataset.upsert_data_rows()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dataset\n",
        "dataset = client.create_dataset(name=\"data_rows_demo_dataset_6\")\n",
        "# You can also upload metadata along with your data row\n",
        "mdo = client.get_data_row_metadata_ontology()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uploads = []\n",
        "# Generate data rows\n",
        "for i in range(1,8):\n",
        "    uploads.append({\n",
        "        \"row_data\":  f\"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_000{i}.jpeg\",\n",
        "        \"global_key\": \"TEST-ID-%id\" % uuid.uuid1(),\n",
        "        ## add metadata (optional)\n",
        "        \"metadata_fields\": [\n",
        "            lb.DataRowMetadataField(\n",
        "                schema_id=mdo.reserved_by_name[\"tag\"].uid,  # specify the schema id\n",
        "                value=\"tag_string\", # typed inputs\n",
        "            ),\n",
        "        ],\n",
        "        \"attachments\": [\n",
        "            {\n",
        "                \"type\": \"IMAGE_OVERLAY\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/disease_attachment.jpeg\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"RAW_TEXT\",\n",
        "                \"value\": \"IOWA, Zone 2232, June 2022 [Text string]\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"TEXT_URL\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/text_attachment.txt\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"IMAGE\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/disease_attachment.jpeg\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"VIDEO\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/drone_video.mp4\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"HTML\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-sample-datasets/Docs/windy.html\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"PDF_URL\",\n",
        "                \"value\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483.pdf\"\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        "\n",
        "task1 = dataset.upsert_data_rows(uploads)\n",
        "task1.wait_till_done()\n",
        "print(\"ERRORS: \" , task1.errors)\n",
        "print(\"RESULTS:\" , task1.result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create data rows from data in your local path "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Create dummy empty jpeg file\n",
        "width = 400\n",
        "height = 300\n",
        "color = (255, 255, 255)  # White color\n",
        "image = Image.new(\"RGB\", (width, height), color)\n",
        "\n",
        "# Save the image as a JPEG file\n",
        "image.save(\"dummy.jpg\")\n",
        "\n",
        "local_data_path = \"dummy.jpg\"\n",
        "\n",
        "data = {\n",
        "  \"row_data\" : local_data_path,\n",
        "  \"global_key\": str(uuid.uuid4())\n",
        "}\n",
        "\n",
        "task3 = dataset.upsert_data_rows([data])\n",
        "task3.wait_till_done()\n",
        "print(\"ERRORS: \" , task3.errors)\n",
        "print(\"RESULTS:\" , task3.result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can mix local files with urls when creating data rows\n",
        "task4 = dataset.upsert_data_rows([{\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_0009.jpeg\",\n",
        "    \"global_key\": str(uuid.uuid4())\n",
        "    }, {\n",
        "    \"row_data\": local_data_path,\n",
        "    \"global_key\": str(uuid.uuid4())\n",
        "    }])\n",
        "task4.wait_till_done()\n",
        "print(\"ERRORS: \" , task4.errors)\n",
        "print(\"RESULTS:\" , task4.result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create data rows via `dataset.create_data_rows()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_2 = client.create_dataset(name=\"data_rows_demo_dataset_3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uploads = []\n",
        "# Generate data rows\n",
        "for i in range(1,9):\n",
        "    uploads.append({\n",
        "        \"row_data\":  f\"https://storage.googleapis.com/labelbox-datasets/People_Clothing_Segmentation/jpeg_images/IMAGES/img_000{i}.jpeg\",\n",
        "        \"global_key\": \"TEST-ID-%id\" % uuid.uuid1(),\n",
        "        ## add metadata (optional)\n",
        "        \"metadata_fields\": [\n",
        "            lb.DataRowMetadataField(\n",
        "                schema_id=mdo.reserved_by_name[\"tag\"].uid,  # specify the schema id\n",
        "                value=\"tag_string\", # typed inputs\n",
        "            ),\n",
        "        ]\n",
        "    })\n",
        "\n",
        "task1_2 = dataset_2.create_data_rows(uploads)\n",
        "task1_2.wait_till_done()\n",
        "print(\"ERRORS: \" , task1_2.errors)\n",
        "print(\"RESULTS:\" , task1_2.result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Update\n",
        "`dataset.upsert_data_rows()` can also be use to update data rows\n",
        "\n",
        "To update data rows using this method, you need to pass a `key`, which can reference either a global key or a data row ID. Additionally, include any fields that you wish to update along with their new values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch a data row from the first dataset example\n",
        "ts = dataset.export()\n",
        "ts.wait_till_done()\n",
        "DATA_ROW_ID = [json.loads(output.json_str) for output in ts.get_stream()][0]['data_row']['id']\n",
        "GLOBAL_KEY = [json.loads(output.json_str) for output in ts.get_stream()][0]['data_row']['global_key']\n",
        "\n",
        "print(f\"Pick either a data row id : {DATA_ROW_ID} or global key: {GLOBAL_KEY}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the global key assodicated with the DATAROW_ID or GLOBAL_KEY, and include a additional metadata\n",
        "data = {\n",
        "    \"key\": lb.UniqueId(DATA_ROW_ID),\n",
        "    \"global_key\": \"NEW-ID-%id\" % uuid.uuid1(),\n",
        "    \"metadata_fields\": [\n",
        "        # New metadata\n",
        "        lb.DataRowMetadataField(\n",
        "            schema_id=mdo.reserved_by_name['captureDateTime'].uid,\n",
        "            value=\"2000-01-01 00:00:00\"\n",
        "        ),\n",
        "        # Include original metadata otherwise it will be removed\n",
        "        lb.DataRowMetadataField(\n",
        "            schema_id=mdo.reserved_by_name[\"tag\"].uid,\n",
        "            value=\"tag_string\",\n",
        "        ),\n",
        "    ]\n",
        "}\n",
        "\n",
        "task5 = dataset_2.upsert_data_rows([data])\n",
        "task5.wait_till_done()\n",
        "print(\"ERRORS: \" , task5.errors)\n",
        "print(\"RESULTS:\" , task5.result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a single attachment on an existing data row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can only create one attachment at the time.\n",
        "DATA_ROW_ID = \"<DATA-ROW-ID>\"\n",
        "data_row = client.get_data_row(DATA_ROW_ID)\n",
        "attachment = data_row.create_attachment(attachment_type=\"RAW_TEXT\",\n",
        "                           attachment_value=\"LABELERS WILL SEE THIS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Update a recently created attachment "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attachment.update(type= \"RAW_TEXT\", value=\"NEW RAW TEXT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Delete a single data row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATAROW_ID_TO_DELETE = \"<DATA-ROW-ID>\"\n",
        "data_row = client.get_data_row(DATAROW_ID_TO_DELETE)\n",
        "data_row.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Bulk delete data row objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bulk delete a list of data_rows ( limit: 4K data rows per call)\n",
        "lb.DataRow.bulk_delete(list(dataset.data_rows()))"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
