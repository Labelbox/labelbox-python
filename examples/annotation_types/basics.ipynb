{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incoming-linux",
   "metadata": {},
   "source": [
    "## Annotation Types\n",
    "This is a common format for representing human and machine generated annotations. A standard interface allows us to build one set of tools that is compatible with all of our data. For example, if model predictions and labels are all represented by a common format we can write all of our etl, visualization code, training code to work with a single interface. Annotation types can also provide a seamless transition between local modeling and using labelbox. Some of the helper functions include:\n",
    "* Build annotations locally with local file paths, numpy arrays, or urls and create data rows with a single line of code\n",
    "* Easily upload model predictions for MAL or MEA by converting annotation objects to the import format\n",
    "* Configure project ontologies from a set of model inferences\n",
    "* Easily access video data without having to worry about downloading each frame's annotations.\n",
    "* Helper functions for drawing annotations, converting them into shapely objects, and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-accreditation",
   "metadata": {},
   "source": [
    "------- \n",
    "## Installation\n",
    "* Installing annotation types requires a slightly different pattern\n",
    "    - `pip install \"labelbox[data]\"`\n",
    "* `pip install labelbox` is still valid but it won't add the required dependencies. If you only want the client functionality of the SDK then don't add the [data] extras. However, you will likely get import errors if attempting to use the annotation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"labelbox[data]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-marina",
   "metadata": {},
   "source": [
    "## Imports\n",
    "* All annotation types can be imported from `labelbox.data.annotation_types`\n",
    "* Helper functions that are compatible with annotation types can be found under `labelbox.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox.data.annotation_types import (\n",
    "    Label,\n",
    "    ImageData,\n",
    "    MaskData,\n",
    "    LabelList,\n",
    "    TextData,\n",
    "    VideoData,\n",
    "    ObjectAnnotation,\n",
    "    ClassificationAnnotation,    \n",
    "    Polygon,\n",
    "    Rectangle,\n",
    "    Line,\n",
    "    Mask,\n",
    "    Point,\n",
    "    Checklist,\n",
    "    Radio,\n",
    "    Text,\n",
    "    TextEntity,\n",
    "    ClassificationAnswer\n",
    ")\n",
    "from labelbox import (\n",
    "    LabelingFrontend,\n",
    "    Client, \n",
    "    OntologyBuilder, \n",
    "    Tool, \n",
    "    Classification, \n",
    "    Option\n",
    ")\n",
    "from shapely.ops import transform\n",
    "from shapely.affinity import affine_transform\n",
    "import requests\n",
    "import IPython\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to give google access to drive you can skip this cell\n",
    "# and manually set `API_KEY` below.\n",
    "COLAB = \"google.colab\" in str(get_ipython())\n",
    "if COLAB:\n",
    "    !pip install colab-env -qU\n",
    "    from colab_env import envvar_handler\n",
    "    envvar_handler.envload()\n",
    "\n",
    "API_KEY = os.environ.get(\"LABELBOX_API_KEY\")\n",
    "if not os.environ.get(\"LABELBOX_API_KEY\"):\n",
    "    API_KEY = getpass(\"Please enter your labelbox api key\")\n",
    "    if COLAB:\n",
    "        envvar_handler.add_env(\"LABELBOX_API_KEY\", API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only update this if you have an on-prem deployment\n",
    "ENDPOINT = \"https://api.labelbox.com/graphql\"\n",
    "client = Client(api_key=API_KEY, endpoint=ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-jerusalem",
   "metadata": {},
   "source": [
    "## Basic Introduction\n",
    "* Construct annotations, labels, and label collections to create a common representation for all data\n",
    "    * A `LabelCollection` is essentially a list or generator for working with a collection of Labels\n",
    "    * A `Label` is a type of data and its associated annotations. E.g. an image and image annotations\n",
    "    * An annotation is either an `ObjectAnnotation` or a `ClassificationAnnotation`. These annotations contain a name and a `Geometry`, `Classification`, or some `Text` data. They also support a classifications field for subclasses.\n",
    "* In addition to create common interfaces for reducing the amount of etl work, each of these types have a set of helper functions that make ML workflows much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-atmosphere",
   "metadata": {},
   "source": [
    "### Constructing Annotation Objects\n",
    "* Annotation objects can be created in one of three ways:\n",
    "1. Manually construct them - usually used for model inferences\n",
    "    - Covered in this notebook\n",
    "2. Export labels to an annotation generator\n",
    "    - `project.label_generator()`\n",
    "    - `project.video_label_generator()`\n",
    "3. Use a converter to load from another format\n",
    "    - Covered in the converters.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-implementation",
   "metadata": {},
   "source": [
    "### Basic LabelCollection\n",
    "* A Label collection is either a `labelList` or `LabelGenerator` containing `Labels`\n",
    "    * More on this in label_containers.ipynb\n",
    "* Each label contains:\n",
    "    1. Data\n",
    "    2. Annotations associated with that data\n",
    "* The individual data and annotations will be explained below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [Label(\n",
    "    data = ImageData(url = \"http://my-img.jpg\"),\n",
    "    annotations = [\n",
    "        ObjectAnnotation(\n",
    "            value = Point(x = 10, y = 10),\n",
    "            name = \"target\"\n",
    "        )\n",
    "    ]\n",
    ")]\n",
    "labels = LabelList(labels) # or LabelList(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-router",
   "metadata": {},
   "source": [
    "* All models are pydantic models so we can easily convert all of our objects to dictionaries and view the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].schema()\n",
    "labels[0].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-involvement",
   "metadata": {},
   "source": [
    "# Data \n",
    "* There are three classes to represent data\n",
    "    * TextData\n",
    "    * VideoData\n",
    "    * ImageData\n",
    "* The data objects can be constructed from various representations\n",
    "    - remote (url, uri)\n",
    "    - disk ( file path)\n",
    "    - compressed (image bytes)\n",
    "    - memory ( numpy array )\n",
    "* Then the access pattern is consistent regardless of the format used to construct the object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-cutting",
   "metadata": {},
   "source": [
    "### ImageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can be instantiated with any of the following\n",
    "image = ImageData(im_bytes = b'bytes')\n",
    "image = ImageData(arr = np.zeros((10,10,3)).astype(np.uint8))\n",
    "image = ImageData(file_path = '/tmp/img.jpg')\n",
    "image_url = \"https://picsum.photos/id/1003/200/300\"\n",
    "image = ImageData(url = image_url)\n",
    "# All of these can access the numpy representation the same way:\n",
    "np_data = image.value\n",
    "\n",
    "\n",
    "im = Image.fromarray(np_data)\n",
    "im.resize((im.size[0]//2, im.size[1]//2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-harvey",
   "metadata": {},
   "source": [
    "### TextData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text has the same access pattern as imagery.\n",
    "text = TextData(file_path = \"/tmp/some local file.txt\")\n",
    "text = TextData(text = \" some text content...\")\n",
    "text = TextData(url = \"https://filesamples.com/samples/document/txt/sample3.txt\")\n",
    "\n",
    "print(text.value[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-seattle",
   "metadata": {},
   "source": [
    "### VideoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4\"\n",
    "\n",
    "video = VideoData(file_path = \"some video path.mp4\")\n",
    "video = VideoData(frames = { 1: np.zeros((32, 32, 3), dtype = np.uint8)})\n",
    "video = VideoData(url=video_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, frame in video.value:\n",
    "    # Show every 50th frame\n",
    "    if idx % 50 == 0:\n",
    "        video_im = Image.fromarray(frame)\n",
    "        w,h = video_im.size\n",
    "        IPython.display.display( video_im.resize((w//16, h//16) ))        \n",
    "    if idx > 250:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-blackberry",
   "metadata": {},
   "source": [
    "### Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-blackberry",
   "metadata": {},
   "source": [
    "#### Adding data row information\n",
    "* This is not required ( and can be added at a later time but you can add data row information to your data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TextData(text = \"some text\", uid = \"ckrey6o07000008l50uk2gcr3\", external_id = \"my_text_data_row\")\n",
    "rd = ImageData(url = image_url, uid = \"ckrey7te2000108l5hl8564dr\", external_id = \"my_raster_data_row\")\n",
    "vd = VideoData(url = video_url, uid = \"ckrey7xef000208l57hwfgi3v\", external_id = \"my_video_data_row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-venice",
   "metadata": {},
   "source": [
    "#### Non-public urls\n",
    "* If the urls in your data is not publicly accessible you can override the fetching logic\n",
    "* For `TextData` and `ImageData` overwrite the following function and make sure it has the same signature. `data.fetch_remote(self) -> bytes`.\n",
    "* For `VideoData`, the signature is `VideoData.fetch_remote(self, local_path)`. This function needs to download the video file locally to that local_path to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.set_fetch_fn(lambda self: requests.get(self.url, headers = {...}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-jacket",
   "metadata": {},
   "source": [
    "# Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-minute",
   "metadata": {},
   "source": [
    "* There are 4 types of annotations\n",
    "    1. `ObjectAnnotation`\n",
    "        - Objects with location information\n",
    "        - Annotations that are found in the object field of the labelbox export\n",
    "        - Classes: `Point`, `Polygon`, `Mask`, `Line`, `Rectangle`, `TextEntity`\n",
    "    2. `ClassificationAnnotation`\n",
    "        - Classifications that can apply to data or another annotation\n",
    "        - Classes: `Checklist`, `Radio`, `Text`, `Dropdown`\n",
    "    3. `VideoObjectAnnotation`\n",
    "        - Same as object annotation but there are extra fields for video information\n",
    "    4. `VideoClassificationAnnotation`\n",
    "        - Same as classification annotation but there are extra fields for video information    \n",
    "-------- \n",
    "* Create an annotation by providing the following:\n",
    "1. Value\n",
    "    - Must be either a `Geometry`, `TextEntity`, or `Classification`\n",
    "    - This is the same as a top level tool in labelbox\n",
    "2. Name or feature_schema_id\n",
    "    - This is the id that corresponds to a particular class or just simply the class name\n",
    "    - If uploading to labelbox this must match a field in an ontology.\n",
    "3. (Optional) Classifications \n",
    "    - List of `ClassificationAnnotations`. This self referencing field enables infinite nesting of classifications.\n",
    "    - Be careful with how you use the tool. Labelbox does not support nesting classifications\n",
    "    - E.g. you can have tool.classifications but not tool.classifications[0].classifications\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-inspection",
   "metadata": {},
   "source": [
    "### ObjectAnnotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-fruit",
   "metadata": {},
   "source": [
    "##### Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_annotation = ObjectAnnotation(\n",
    "    value = Point(x = 5, y = 3),\n",
    "    name = \"point class name\"\n",
    ")\n",
    "\n",
    "point_annotation = ObjectAnnotation(\n",
    "    value = Point(x = 5, y = 3),\n",
    "    feature_schema_id = \"ckrgcgl89000108jtggc9e687\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-karen",
   "metadata": {},
   "source": [
    "##### Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given some polygon:\n",
    "xy_poly = [\n",
    "    [60, 161], [67, 177], [76, 180], [77, 222], [82, 246], [78, 291], [72, 300], [87, 300], \n",
    "    [94, 244], [103, 243], [100, 269], [90, 290], [95, 296], [104, 292], [108, 272], \n",
    "    [111, 300], [121, 300], [117, 244], [128, 236], [133, 298], [142, 297], [137, 250], \n",
    "    [146, 208], [138, 185], [120, 180], [105, 189], [112, 162], [93, 156], [72, 160], \n",
    "]\n",
    "\n",
    "polygon_annotation = ObjectAnnotation(\n",
    "        value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            name = \"polygon class name\"\n",
    ")\n",
    "\n",
    "polygon_annotation = ObjectAnnotation(\n",
    "        value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            feature_schema_id = \"ckrgcel71000008jtd9mn0szu\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-sharing",
   "metadata": {},
   "source": [
    "##### Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_line = [[0,0], [10,5], [15,5]]\n",
    "\n",
    "line_annotation = ObjectAnnotation(\n",
    "        value = Line(points = [Point(x = x, y = y) for x,y in xy_line]),\n",
    "            name = \"line class name\"\n",
    ")\n",
    "\n",
    "line_annotation = ObjectAnnotation(\n",
    "        value = Line(points = [Point(x = x, y = y) for x,y in xy_line]),\n",
    "            feature_schema_id = \"ckrgcel71000008jtd9mn0szu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-april",
   "metadata": {},
   "source": [
    "##### Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = Point(x = 0, y = 0)\n",
    "end = Point(x = 5, y = 10)\n",
    "\n",
    "rectangle_annotation = ObjectAnnotation(\n",
    "        value = Rectangle(start = start, end = end),\n",
    "            name = \"rectangle class name\"\n",
    ")\n",
    "\n",
    "rectangle_annotation = ObjectAnnotation(\n",
    "        value = Rectangle(start = start, end = end),\n",
    "            feature_schema_id = \"ckrgcel71000008jtd9mn0szu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-earthquake",
   "metadata": {},
   "source": [
    "##### Mask\n",
    "* The mask can be any ImageData object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_annotation = ObjectAnnotation(\n",
    "        value = Mask(mask =  MaskData(arr = np.zeros((32,32,3), dtype = np.uint8)), color = (255,255,255)),\n",
    "            name = \"mask class name\"\n",
    ")\n",
    "\n",
    "mask_annotation = ObjectAnnotation(\n",
    "        value = Mask(mask =  MaskData(arr = np.zeros((32,32,3), dtype = np.uint8)), color = (255,255,255)),\n",
    "            feature_schema_id = \"ckrgcel71000008jtd9mn0szu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-short",
   "metadata": {},
   "source": [
    "* Multiple mask objects can reference the same mask to save memory and reduce the number of files that need to be uploaded (i.e. one seg mask for multiple classes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_data = MaskData(arr = np.zeros((32,32,3), dtype = np.uint8))\n",
    "mask_annotation = ObjectAnnotation(\n",
    "        value = Mask(mask  = raster_data, color = [255,255,255]),\n",
    "            name = \"eyes\"\n",
    ")\n",
    "\n",
    "mask_annotation = ObjectAnnotation(\n",
    "        value = Mask(mask = raster_data, color = [0,255,255]),\n",
    "            name = \"nose\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-seeker",
   "metadata": {},
   "source": [
    "* The Mask class support either RGB masks only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_data = MaskData(arr = np.zeros((32,32, 3), dtype = np.uint8))\n",
    "mask_annotation = ObjectAnnotation(\n",
    "        value = Mask(mask  = raster_data, color = (128,255,255)),\n",
    "            name = \"eye\"\n",
    ")\n",
    "\n",
    "mask_annotation = ObjectAnnotation(\n",
    "        value = Mask(mask = raster_data, color =(255,255,255)),\n",
    "            name = \"nose\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-coast",
   "metadata": {},
   "source": [
    "##### Text Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entity_annotation = ObjectAnnotation(\n",
    "        value = TextEntity(start  = 10, end = 12),\n",
    "            name = \"person\"\n",
    ")\n",
    "\n",
    "entity_annotation = ObjectAnnotation(\n",
    "        value = TextEntity(start  = 10, end = 12),\n",
    "            feature_schema_id = \"ckrgddyli000108mk0c0t9qya\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-collaboration",
   "metadata": {},
   "source": [
    "##### Geometry Utilities\n",
    "* All of the previous objects except TextEntity inherit from the Geometry base class\n",
    "* They have the following properties and functions\n",
    "    1. draw(height width, kwargs)\n",
    "    2. shape - property\n",
    "    3. geometry - property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_annotation.value.shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-yeast",
   "metadata": {},
   "source": [
    "* Flip because shapely origin is different from image coords\n",
    "```\n",
    "      Shapely Coordinates           Image Coordinates\n",
    "           ------                        -------    \n",
    "                               0 → → Greater X → →\n",
    "    ↑                          ↓\n",
    "Greater Y                    ↓\n",
    "    ↑                       Greater Y\n",
    "    ↑                          ↓\n",
    "    0 → → Greater X → →\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_y_axis(poly, height):\n",
    "    return affine_transform(poly,[1, 0, 0, -1, 0, height])\n",
    "\n",
    "flip_y_axis(polygon_annotation.value.shapely, im.size[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-novel",
   "metadata": {},
   "source": [
    "##### Shape to Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = (255,255,255)\n",
    "np_mask = polygon_annotation.value.draw(height = im.size[1], width = im.size[0], color = color)\n",
    "Image.fromarray(np.hstack([np_mask, np_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-narrow",
   "metadata": {},
   "source": [
    "##### Mask to Shape\n",
    "* Adds extra vertices to be as accurate as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_annotation = Mask(\n",
    "    mask = MaskData(arr = np_mask),\n",
    "    color = color \n",
    ")\n",
    "\n",
    "flip_y_axis(mask_annotation.shapely, im.size[1])\n",
    "# Simplify with mask_annotation.shapely.simplify(<float> simplification error tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-shareware",
   "metadata": {},
   "source": [
    "#### Masks with multiple annotations\n",
    "* Since masks can contain multiple classes you can split them up by calling raster on an individual annotation.\n",
    "* E.g. eyes and nose for our deer image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a combined mask from polygons\n",
    "eye_color, nose_color = (255,255,255), (255,0,0)\n",
    "h,w = np_data.shape[:2]\n",
    "eyes = [\n",
    "    Polygon(points = [Point(x=x,y=y) for x,y in [[82, 180], [83, 184], [88, 184], [86, 180]]]),\n",
    "    Polygon(points = [Point(x=x,y=y) for x,y in [[97, 182], [99, 184], [102, 183], [101, 180], [98, 180]]]),    \n",
    "]\n",
    "eye_masks = np.max([eye.draw(height = h, width = w) for eye in eyes], axis = 0)\n",
    "nose = Polygon(points =[ Point(x=x,y=y) for x,y in [[95, 192], [93, 197], [96, 198], [100, 197], [100, 194], [100, 192], [96, 192]]])\n",
    "nose_mask = nose.draw(height = h, width = w, color = nose_color)\n",
    "# Picks the brighter color if there is overlap. \n",
    "# If you don't want overlap then just simply create separate masks\n",
    "np_seg_mask = np.max([nose_mask, eye_masks], axis = 0)\n",
    "Image.fromarray(np.hstack([np_seg_mask, np_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-state",
   "metadata": {},
   "source": [
    "* Create two mask annotations from this one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data = MaskData(arr = np_seg_mask)\n",
    "eye_mask = Mask(mask = mask_data, color = eye_color)\n",
    "nose_mask = Mask(mask = mask_data, color = nose_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-storm",
   "metadata": {},
   "source": [
    "* Calling `mask.draw()` will return a mask with pixels equal to the specified color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_raster = eye_mask.draw()\n",
    "nose_raster = nose_mask.draw()\n",
    "Image.fromarray(np.hstack([eye_raster,nose_raster, np_data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-montana",
   "metadata": {},
   "source": [
    "### Classification Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-stomach",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_annotation = ClassificationAnnotation(\n",
    "    name = \"my text class\", \n",
    "    value = Text(answer = \"some text answer\")                               \n",
    ")\n",
    "\n",
    "text_annotation = ClassificationAnnotation(\n",
    "    feature_schema_id = \"my text class\", \n",
    "    value = Text(answer = \"some text answer\")                               \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-japan",
   "metadata": {},
   "source": [
    "#### Radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_annotation = ClassificationAnnotation(\n",
    "    name = \"is dog\",\n",
    "    value = Radio(answer = ClassificationAnswer(name = \"dog\")) \n",
    ")\n",
    "\n",
    "\n",
    "radio_annotation = ClassificationAnnotation(\n",
    "    feature_schema_id = \"ckresqdg7000001jnb70v4zcc\",\n",
    "    value = Radio(answer = ClassificationAnswer(feature_schema_id = \"ckrdy06ia000007ky94h04qlj\")) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-manual",
   "metadata": {},
   "source": [
    "##### Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checklist_annotation = ClassificationAnnotation(\n",
    "    feature_schema_id = \"ckrestd5g000101jnhudjf29a\",\n",
    "    value = Checklist(answer = [ClassificationAnswer(feature_schema_id = \"ckrdy06ia000007ky94h04qlj\")])\n",
    ")\n",
    "                                \n",
    "checklist_annotation = ClassificationAnnotation(\n",
    "    name = \"weather\",\n",
    "    value = Checklist(answer = [ClassificationAnswer(name = \"cloudy\")]) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-sauce",
   "metadata": {},
   "source": [
    "### Subclassifications\n",
    "* Objects can have nested classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_annotation = ObjectAnnotation(\n",
    "    value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "    name = \"deer\",\n",
    "    classifications = [\n",
    "        checklist_annotation, radio_annotation\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-brass",
   "metadata": {},
   "source": [
    "# Labels\n",
    "* Labels connect a list of annotations to data such as images, text, and video.\n",
    "* Labels have a convenient set of functions for dealing with that collection of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = Label(\n",
    "    data = ImageData(url = image_url),\n",
    "    annotations = [\n",
    "        ObjectAnnotation(\n",
    "            value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            name = \"deer\"\n",
    "        ),\n",
    "        ObjectAnnotation(\n",
    "            name = \"deer_eyes\",\n",
    "            value = Mask(mask = MaskData(arr = np_mask), color = color)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-preservation",
   "metadata": {},
   "source": [
    "### Interacting with labelbox:\n",
    "* For this label to be compatible with labelbox we need the following:\n",
    "    - all named features must have feature_schema_ids\n",
    "    - all data must have urls\n",
    "        - masks\n",
    "        - images\n",
    "        - videos\n",
    "        - text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-behavior",
   "metadata": {},
   "source": [
    "### Uploading Urls\n",
    "* It doesn't matter how urls are set\n",
    "* Manually setting urls or use helper functions are both valid for working with labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set just by adding a value:\n",
    "image = ImageData(arr = np_data)\n",
    "image.url = \"http://myurl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-indiana",
   "metadata": {},
   "source": [
    "* Use functions to upload urls:\n",
    "    - Upload image urls : `Label.add_url_to_data(signer)`\n",
    "    - Upload segmentation masks : `label.add_url_to_masks(signer)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-blond",
   "metadata": {},
   "source": [
    "----- \n",
    "* Define the signer\n",
    "    - Creating urls requires a function that maps bytes to a str (url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signing_function(obj_bytes: bytes) -> str:\n",
    "    # Do not use this signer. You will not be able to resign these images at a later date\n",
    "    url = client.upload_data(content=obj_bytes, sign=True)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-milan",
   "metadata": {},
   "source": [
    "* Create a complex label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label = Label(\n",
    "    data = ImageData(arr = np_data),\n",
    "    annotations = [\n",
    "         ObjectAnnotation(\n",
    "            name = \"deer_nose\",\n",
    "            value = nose_mask,\n",
    "            classifications = [\n",
    "                ClassificationAnnotation(\n",
    "                    name = \"description\",\n",
    "                    value = Radio(\n",
    "                        answer = ClassificationAnswer(name = \"wet\")\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        ObjectAnnotation(\n",
    "            name = \"deer_eyes\",\n",
    "            value = eye_mask\n",
    "        ),\n",
    "        ObjectAnnotation(\n",
    "            value = Polygon(points = [Point(x = x, y = y) for x,y in xy_poly]),\n",
    "            name = \"deer\"\n",
    "        ),\n",
    "        ClassificationAnnotation(name = \"image_description\", \n",
    "            value = Checklist(answer = [\n",
    "                ClassificationAnswer(name = \"bright\"),\n",
    "                ClassificationAnswer(name = \"not_blurry\"),            \n",
    "         ])),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-murray",
   "metadata": {},
   "source": [
    "* Check that the image does not have a url\n",
    "* Add the url\n",
    "* Check that the url was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before\",label.data.url)\n",
    "label.add_url_to_data(signing_function)\n",
    "print(\"After\", label.data.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-outdoors",
   "metadata": {},
   "source": [
    "* Masks also need urls for annotation imports\n",
    "* Note that the url is the same when uploaded.\n",
    "    - The url is only uploaded once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also have a mask that needs a url:\n",
    "mask_annotations = [annot for annot in label.annotations if isinstance(annot.value, Mask)]\n",
    "for annot in mask_annotations:\n",
    "    print(f\"{annot.name} before\" , annot.value.mask.url)\n",
    "    \n",
    "    \n",
    "label.add_url_to_masks(signing_function)\n",
    "\n",
    "\n",
    "for annot in mask_annotations:\n",
    "    print(f\"{annot.name} after\" , annot.value.mask.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-disabled",
   "metadata": {},
   "source": [
    "### Creating Data Rows\n",
    "* `Labels` objects are great for working with locally but we might want to upload to labelbox\n",
    "* This is required for MAL, MEA, and to add additional labels to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.create_dataset(name = \"label_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the signing function is only used if a url is not already provided\n",
    "print(label.data.uid)\n",
    "label.create_data_row(dataset, signing_function)\n",
    "print(label.data.uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-steam",
   "metadata": {},
   "source": [
    "### Assigning Schema Ids:\n",
    "* All tools, classifications, and options either have names or feature_schema_ids.\n",
    "* Locally it is convenient to provide a name so that we don't need a labelbox project to use these interfaces.\n",
    "* To use MAL and MEA schema ids are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When uploading for MAL or MEA we need an ontology.\n",
    "# So let's create one\n",
    "\n",
    "\n",
    "# These names have to match our object names exactly!!\n",
    "ontology_builder = OntologyBuilder(tools=[\n",
    "    Tool(tool=Tool.Type.POLYGON, name=\"deer\"),\n",
    "    Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_nose\", \n",
    "         classifications = [\n",
    "             Classification(\n",
    "                 class_type = Classification.Type.RADIO, \n",
    "                 instructions = \"description\", \n",
    "                 options = [Option(value = \"wet\")]\n",
    "             )]),\n",
    "    Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_eyes\")    \n",
    "], classifications = [\n",
    "    Classification(\n",
    "        Classification.Type.CHECKLIST, \n",
    "        instructions = \"image_description\", \n",
    "        options = [Option(value = \"bright\"), Option(value = \"not_blurry\"), Option(value = \"dark\")])])\n",
    "\n",
    "\n",
    "editor = next(\n",
    "    client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
    "project = client.create_project(name=\"test_annotation_types\")\n",
    "project.setup(editor, ontology_builder.asdict())\n",
    "project.datasets.connect(dataset)\n",
    "\n",
    "ontology = OntologyBuilder.from_project(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_schema_ids(label):\n",
    "    for annotation in label.annotations:\n",
    "        print(f\"Object : {annotation.name} - {annotation.feature_schema_id}\")\n",
    "        for classification in getattr(annotation, 'classifications', []):\n",
    "            print(f\"--- Subclass : {classification.name} - {classification.feature_schema_id}\")\n",
    "            option = classification.value\n",
    "            print(f\"--- --- Options: {option.answer.name} - {option.answer.feature_schema_id}\")\n",
    "\n",
    "        if isinstance(annotation, ClassificationAnnotation):\n",
    "            for option in annotation.value.answer:\n",
    "                print(f\"--- Options: {option.name} - {option.feature_schema_id}\")\n",
    "show_feature_schema_ids(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.assign_feature_schema_ids(ontology)\n",
    "show_feature_schema_ids(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-prerequisite",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "* Annotation types should be thought of as low level interfaces\n",
    "* We are working on a set of tools to make working with annotation types less verbose. Please provide any feedback!\n",
    "* Checkout other notebooks to see how to use higher level tools that are compatible with these interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "dataset.delete()\n",
    "project.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-programming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-courage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-album",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
