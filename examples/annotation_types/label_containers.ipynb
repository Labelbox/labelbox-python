{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "db768cda",
            "metadata": {},
            "source": [
                "<td>\n",
                "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
                "</td>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb5611d0",
            "metadata": {},
            "source": [
                "<td>\n",
                "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/annotation_types/label_containers.ipynb\" target=\"_blank\"><img\n",
                "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
                "</td>\n",
                "\n",
                "<td>\n",
                "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/annotation_types/label_containers.ipynb\" target=\"_blank\"><img\n",
                "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
                "</td>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "increasing-operator",
            "metadata": {},
            "source": [
                "# Label Containers\n",
                "* There are two high level containers for labels\n",
                "    1. [`LabelList`](#LabelList)\n",
                "    2. [`LabelGenerator`](#LabelGenerator)\n",
                "* Tools that are built to convert between formats, help with etl, and model training all will operate on these containers\n",
                "* Make sure to read basics. Explanations are not repeated here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "stuffed-thanks",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install \"labelbox[data]\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "sized-tamil",
            "metadata": {},
            "outputs": [],
            "source": [
                "from labelbox import Client\n",
                "from labelbox.data.annotation_types import LabelList, LabelGenerator\n",
                "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
                "from labelbox import LabelingFrontend\n",
                "from labelbox.data.annotation_types import (Label, ImageData, MaskData, Mask,\n",
                "                                            Point, Polygon,\n",
                "                                            ClassificationAnswer, Radio,\n",
                "                                            Checklist, ObjectAnnotation,\n",
                "                                            ClassificationAnnotation)\n",
                "import requests\n",
                "import numpy as np\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ec0019f3",
            "metadata": {},
            "source": [
                "# API Key and Client\n",
                "Provide a valid api key below in order to properly connect to the Labelbox Client."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "extraordinary-installation",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add your api key\n",
                "API_KEY = None\n",
                "client = Client(api_key=API_KEY)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cubic-burlington",
            "metadata": {},
            "source": [
                "### Helper Functions\n",
                "* The following functions are explained in the [basics notebooks](https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/annotation_types/basics.ipynb)\n",
                "* Please skip to the [LabelList](#LabelList) section to continue with this tutorial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "fewer-thread",
            "metadata": {},
            "outputs": [],
            "source": [
                "def signing_function(obj_bytes: bytes) -> str:\n",
                "    # Do not use this signer. You will not be able to resign these images at a later date.\n",
                "    url = client.upload_data(content=obj_bytes, sign=True)\n",
                "    return url"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "alive-memorial",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_polygon():\n",
                "    # Given some polygon:\n",
                "    xy_poly = [\n",
                "        [60, 161],\n",
                "        [67, 177],\n",
                "        [76, 180],\n",
                "        [77, 222],\n",
                "        [82, 246],\n",
                "        [78, 291],\n",
                "        [72, 300],\n",
                "        [87, 300],\n",
                "        [94, 244],\n",
                "        [103, 243],\n",
                "        [100, 269],\n",
                "        [90, 290],\n",
                "        [95, 296],\n",
                "        [104, 292],\n",
                "        [108, 272],\n",
                "        [111, 300],\n",
                "        [121, 300],\n",
                "        [117, 244],\n",
                "        [128, 236],\n",
                "        [133, 298],\n",
                "        [142, 297],\n",
                "        [137, 250],\n",
                "        [146, 208],\n",
                "        [138, 185],\n",
                "        [120, 180],\n",
                "        [105, 189],\n",
                "        [112, 162],\n",
                "        [93, 156],\n",
                "        [72, 160],\n",
                "    ]\n",
                "    return Polygon(points=[Point(x=x, y=y) for x, y in xy_poly])\n",
                "\n",
                "\n",
                "def get_labels():\n",
                "    im_h, im_w = 300, 200\n",
                "    image_url = \"https://picsum.photos/id/1003/200/300\"\n",
                "    nose_color, eye_color = (0, 255, 0), (255, 0, 0)\n",
                "    nose_mask = Point(x=96, y=194).draw(im_h, im_w, thickness=3)\n",
                "    eye_masks = [\n",
                "        Point(x=84, y=182).draw(im_h, im_w, thickness=3),\n",
                "        Point(x=99, y=181).draw(im_h, im_w, thickness=3),\n",
                "    ]\n",
                "    mask_arr = np.max([*eye_masks, nose_mask], axis=0)\n",
                "    mask = MaskData(arr=mask_arr)\n",
                "    return [\n",
                "        Label(data=ImageData(im_bytes=requests.get(image_url).content),\n",
                "              annotations=[\n",
                "                  ObjectAnnotation(value=get_polygon(), name=\"deer\"),\n",
                "                  ObjectAnnotation(name=\"deer_eyes\",\n",
                "                                   value=Mask(mask=mask, color=eye_color)),\n",
                "                  ObjectAnnotation(\n",
                "                      name=\"deer_nose\",\n",
                "                      value=Mask(mask=mask, color=nose_color),\n",
                "                      classifications=[\n",
                "                          ClassificationAnnotation(\n",
                "                              name=\"nose_description\",\n",
                "                              value=Radio(answer=ClassificationAnswer(\n",
                "                                  name=\"wet\")))\n",
                "                      ]),\n",
                "                  ClassificationAnnotation(\n",
                "                      name=\"image_description\",\n",
                "                      value=Checklist(\n",
                "                          answer=[ClassificationAnswer(name=\"bright\")]))\n",
                "              ])\n",
                "    ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "distant-republic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_feature_schema_ids(label):\n",
                "    for annotation in label.annotations:\n",
                "        print(f\"Object : {annotation.name} - {annotation.feature_schema_id}\")\n",
                "        for classification in getattr(annotation, 'classifications', []):\n",
                "            print(\n",
                "                f\"--- Subclass : {classification.name} - {classification.feature_schema_id}\"\n",
                "            )\n",
                "            option = classification.value\n",
                "            print(\n",
                "                f\"--- --- Options: {option.answer.name} - {option.answer.feature_schema_id}\"\n",
                "            )\n",
                "\n",
                "        if isinstance(annotation, ClassificationAnnotation):\n",
                "            for option in annotation.value.answer:\n",
                "                print(\n",
                "                    f\"--- Options: {option.name} - {option.feature_schema_id}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "disciplinary-cylinder",
            "metadata": {},
            "outputs": [],
            "source": [
                "def setup_project():\n",
                "    # These names have to match our object names exactly!!\n",
                "    ontology_builder = OntologyBuilder(tools=[\n",
                "        Tool(tool=Tool.Type.POLYGON, name=\"deer\"),\n",
                "        Tool(tool=Tool.Type.SEGMENTATION,\n",
                "             name=\"deer_nose\",\n",
                "             classifications=[\n",
                "                 Classification(class_type=Classification.Type.RADIO,\n",
                "                                instructions=\"nose_description\",\n",
                "                                options=[Option(value=\"wet\")])\n",
                "             ]),\n",
                "        Tool(tool=Tool.Type.SEGMENTATION, name=\"deer_eyes\")\n",
                "    ],\n",
                "                                       classifications=[\n",
                "                                           Classification(\n",
                "                                               Classification.Type.CHECKLIST,\n",
                "                                               instructions=\"image_description\",\n",
                "                                               options=[\n",
                "                                                   Option(value=\"bright\"),\n",
                "                                                   Option(value=\"not_blurry\"),\n",
                "                                                   Option(value=\"dark\")\n",
                "                                               ])\n",
                "                                       ])\n",
                "\n",
                "    editor = next(\n",
                "        client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
                "    project = client.create_project(name=\"test_annotation_types\")\n",
                "    project.setup(editor, ontology_builder.asdict())\n",
                "    dataset = client.create_dataset(name='my_ds')\n",
                "    project.datasets.connect(dataset)\n",
                "\n",
                "    ontology = OntologyBuilder.from_project(project)\n",
                "    return ontology, dataset, project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "moved-eligibility",
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_mask_urls(label):\n",
                "    for annotation in label.annotations:\n",
                "        if isinstance(annotation.value, Mask):\n",
                "            print(annotation.value.mask.url)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "processed-exchange",
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_references(label):\n",
                "    print('\\n---  schema ids ---\\n')\n",
                "    show_feature_schema_ids(label)\n",
                "    print(\"\\n--- mask urls ---\\n\")\n",
                "    print_mask_urls(label)\n",
                "    print('\\n--- image url ---\\n')\n",
                "    print(label.data.url)\n",
                "    print('\\n--- data row reference ---\\n')\n",
                "    print(original_label.data.uid)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "virtual-ocean",
            "metadata": {},
            "source": [
                "# LabelList\n",
                "* This object is essentially a list of Labels with a set of helpful utilties\n",
                "* It is simple and fast at the expense of memory\n",
                "    * Larger datasets shouldn't use label list ( or at least will require more memory )\n",
                "* Why use label list over just a list of labels?\n",
                "    * Multithreaded utilities (faster)\n",
                "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "trained-leadership",
            "metadata": {},
            "outputs": [],
            "source": [
                "labels = get_labels()\n",
                "label_list = LabelList(labels)\n",
                "\n",
                "# Also build LabelLists iteratively\n",
                "label_list = LabelList()\n",
                "for label in labels:\n",
                "    label_list.append(label)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "italic-command",
            "metadata": {},
            "source": [
                "## Iterate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "cubic-lunch",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Iterable, behaves like a list\n",
                "for label in label_list:\n",
                "    print(type(label))\n",
                "# Get length\n",
                "print(len(label_list))\n",
                "# By index\n",
                "print(type(label_list[0]))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "completed-league",
            "metadata": {},
            "source": [
                "### Upload segmentation masks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "senior-platform",
            "metadata": {},
            "outputs": [],
            "source": [
                "### Add urls to all segmentation masks:\n",
                "# (in parallel)\n",
                "for label in label_list:\n",
                "    print_mask_urls(label)\n",
                "\n",
                "label_list.add_url_to_masks(signing_function)\n",
                "\n",
                "for label in label_list:\n",
                "    print_mask_urls(label)\n",
                "# Again note that these all share the same segmentation mask\n",
                "# ( This is determined by the fact that they share the same reference )\n",
                "# This mask is only uploaded once"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "approximate-tactics",
            "metadata": {},
            "source": [
                "### Create signed urls for data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "shared-arkansas",
            "metadata": {},
            "outputs": [],
            "source": [
                "### Add urls to all segmentation masks:\n",
                "# (in parallel)\n",
                "print(label_list[0].data.url)\n",
                "label_list.add_url_to_data(signing_function)\n",
                "print(label_list[0].data.url)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "animal-miracle",
            "metadata": {},
            "source": [
                "### Add to labelbox dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "oriented-processing",
            "metadata": {},
            "outputs": [],
            "source": [
                "# For the next two sections we need an ontology and dataset\n",
                "ontology, dataset, project = setup_project()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "greatest-prediction",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(label_list[0].data.uid)\n",
                "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
                "label_list.add_to_dataset(dataset, signing_function)\n",
                "print(label_list[0].data.uid)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vital-translation",
            "metadata": {},
            "source": [
                "### Add schema ids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "quality-daughter",
            "metadata": {},
            "outputs": [],
            "source": [
                "for label in label_list:\n",
                "    show_feature_schema_ids(label)\n",
                "# Note that this function will assign a uuid as the external id if it isn't provided.\n",
                "label_list.assign_feature_schema_ids(ontology)\n",
                "print('-' * 50)\n",
                "for label in label_list:\n",
                "    show_feature_schema_ids(label)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "collectible-paris",
            "metadata": {},
            "outputs": [],
            "source": [
                "# cleanup:\n",
                "dataset.delete()\n",
                "project.delete()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "innovative-auditor",
            "metadata": {},
            "source": [
                "# LabelGenerator\n",
                "* This object generates labels and provides a set of helpful utilties\n",
                "* This object is complex and slower than the `LabelList` in order to be highly memory efficient\n",
                "    * Larger datasets should use label generators\n",
                "* Why use label generator over just a generator that yields labels?\n",
                "    * Parallel io operations are run in the background to prepare results\n",
                "    * Compatible with converter functions (functions useful for translating between formats, etl, and training )\n",
                "* The first qsize elements run serially from when the chained functions are added.\n",
                "    * After that iterating will get much faster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "hidden-reaction",
            "metadata": {},
            "outputs": [],
            "source": [
                "labels = get_labels()\n",
                "label_generator = LabelGenerator(labels)\n",
                "ontology, dataset, project = setup_project()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "endangered-touch",
            "metadata": {},
            "outputs": [],
            "source": [
                "# So we can't show the before and afters because the generator is not repeatable\n",
                "\n",
                "try:\n",
                "    label = next(label_generator)\n",
                "    print(\"Ran once\")\n",
                "    label = next(label_generator)\n",
                "    print(\"Ran twice\")\n",
                "except StopIteration:\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "cellular-standard",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Does not support indexing ( it is a generator.. )\n",
                "try:\n",
                "    label_generator[0]\n",
                "    print(\"Can index\")\n",
                "except TypeError:\n",
                "    print(\"Unable to index\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "artistic-opportunity",
            "metadata": {},
            "source": [
                "### Functions to modify results\n",
                "* We can set functions to run on the result of the generator\n",
                "* Since these are run in background threads it is a lot faster than applying them on each label individually\n",
                "* The functions are lazily evaluated"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "cooked-opera",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Recreate because we already went through all of the items when we showed that it isn't repeatable\n",
                "original_label = labels[0]\n",
                "\n",
                "show_references(original_label)\n",
                "label_generator = LabelGenerator(labels) \\\n",
                "        .add_url_to_masks(signing_function) \\\n",
                "        .add_to_dataset(dataset, signing_function) \\\n",
                "        .assign_feature_schema_ids(ontology)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "reliable-hughes",
            "metadata": {},
            "outputs": [],
            "source": [
                "show_references(original_label)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "unable-vehicle",
            "metadata": {},
            "outputs": [],
            "source": [
                "label = next(label_generator)\n",
                "show_references(original_label)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "sufficient-blood",
            "metadata": {},
            "source": [
                "* Note that the first qsize elements run serially from when the chained functions are added.\n",
                "* After that iterating will get much faster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "mounted-immunology",
            "metadata": {},
            "outputs": [],
            "source": [
                "# LabelGenerators can be converted to a LabelList\n",
                "LabelGenerator(labels).as_list()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "quarterly-compatibility",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset.delete()\n",
                "project.delete()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
