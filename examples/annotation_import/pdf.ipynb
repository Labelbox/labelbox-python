{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/annotation_import/pdf.ipynb\" target=\"_blank\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/annotation_import/pdf.ipynb\" target=\"_blank\"><img\n",
    "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Annotation Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF Annotation Import\n",
    "Supported annotations for PDF assets with text layers\n",
    "\n",
    "#### Entity annotations\n",
    "Supported annotations for PDF assets without text layers\n",
    "\n",
    "*Annotation types*\n",
    "- Checklist classification (including nested classifications)\n",
    "- Radio classifications (including nested classifications)\n",
    "- Free text classifications\n",
    "\n",
    "\n",
    "*NDJson*\n",
    "- Checklist classification (including nested classifications)\n",
    "- Radio classifications (including nested classifications)\n",
    "- Free text classifications\n",
    "- Bounding box \n",
    "- Entities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'labelbox[data]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -e ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "import uuid\n",
    "from uuid import uuid4\n",
    "\n",
    "import labelbox as lb\n",
    "import labelbox.types as lb_types\n",
    "from labelbox.schema.queue_mode import QueueMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace with your API key\n",
    "Guides on https://docs.labelbox.com/docs/create-an-api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your api key\n",
    "API_KEY = None\n",
    "client = lb.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Entity ##########\n",
    "# NDJSON\n",
    "entities_annotations_ndjson = { \n",
    "    \"name\": \"named_entity\",\n",
    "    \"textSelections\": [\n",
    "        {\n",
    "            \"tokenIds\": [\n",
    "                \"<UUID>\",\n",
    "            ],\n",
    "            \"groupId\": \"<UUID>\",\n",
    "            \"page\": 1,\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Radio Classification #########\n",
    "\n",
    "# Annotation types \n",
    "radio_annotation = lb_types.ClassificationAnnotation(\n",
    "    name=\"radio_question\",\n",
    "    value=lb_types.Radio(answer = \n",
    "        lb_types.ClassificationAnswer(name = \"first_radio_answer\")\n",
    "    )\n",
    ")\n",
    "# NDJSON\n",
    "radio_annotation_ndjson = {\n",
    "  'name': 'radio_question',\n",
    "  'answer': {'name': 'first_radio_answer'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Checklist Classification ###########\n",
    "\n",
    "# Annotation types \n",
    "checklist_annotation = lb_types.ClassificationAnnotation(\n",
    "    name=\"checklist_question\",\n",
    "    value=lb_types.Checklist(answer = [\n",
    "        lb_types.ClassificationAnswer(name = \"first_checklist_answer\"),\n",
    "        lb_types.ClassificationAnswer(name = \"second_checklist_answer\")\n",
    "    ])\n",
    "  )\n",
    "\n",
    "\n",
    "# NDJSON\n",
    "checklist_annotation_ndjson = {\n",
    "  'name': 'checklist_question',\n",
    "  'answer': [\n",
    "    {'name': 'first_checklist_answer'},\n",
    "    {'name': 'second_checklist_answer'}\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Bounding Box ###########\n",
    "\n",
    "bbox_annotation_ndjson = {\n",
    "  'name': 'bounding_box',\n",
    "  'bbox': {\n",
    "          \"top\": 42.799,\n",
    "          \"left\": 86.498,\n",
    "          \"height\": 141.911,\n",
    "          \"width\": 303.195\n",
    "      },\n",
    "  'page': 0,\n",
    "  'unit': \"POINTS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############ nested classifications ###########\n",
    "\n",
    "nested_checklist_annotation_ndjson = {\n",
    "  \"name\": \"nested_checklist_question\",\n",
    "  \"answer\": [{\n",
    "      \"name\": \"first_checklist_answer\", \n",
    "      \"classifications\" : [\n",
    "        {\n",
    "          \"name\": \"sub_checklist_question\", \n",
    "          \"answer\": {\"name\": \"first_sub_checklist_answer\"}\n",
    "        }          \n",
    "      ]         \n",
    "  }]\n",
    "}\n",
    "\n",
    "nested_radio_annotation_ndjson = {\n",
    "  'name': 'nested_radio_question',\n",
    "  'answer': {\n",
    "      'name': 'first_radio_answer',\n",
    "      'classifications': [{\n",
    "          'name':'sub_radio_question',\n",
    "          'answer': { 'name' : 'first_sub_radio_answer'}\n",
    "        }]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Classification Free-form text ############## \n",
    "\n",
    "text_annotation = lb_types.ClassificationAnnotation(\n",
    "  name=\"free_text\",  # must match your ontology feature's name\n",
    "  value=lb_types.Text(answer=\"sample text\")\n",
    ")\n",
    "\n",
    "\n",
    "text_annotation_ndjson = {\n",
    "  'name': 'free_text',\n",
    "  'answer': 'sample text'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Annotations - putting it all together "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import data rows into Catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text layer url is required for uploading entity annotations\n",
    "img_url = {\n",
    "    \"row_data\": {\n",
    "      \"pdf_url\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483.pdf\",\n",
    "      \"text_layer_url\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json\"\n",
    "    },\n",
    "    \"global_key\": str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "\n",
    "dataset = client.create_dataset(name=\"pdf_demo_dataset\")\n",
    "\n",
    "data_row = dataset.create_data_row(img_url)\n",
    "\n",
    "print(data_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create/select an Ontology for your project\n",
    "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the name/instructions fields in your annotations to ensure the correct feature schemas are matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup the ontology and link the tools created above.\n",
    "\n",
    "ontology_builder = lb.OntologyBuilder(\n",
    "  classifications=[ # List of Classification objects\n",
    "    lb.Classification( \n",
    "      class_type=lb.Classification.Type.RADIO,\n",
    "      name=\"radio_question\", \n",
    "      scope = lb.Classification.Scope.GLOBAL,\n",
    "      options=[\n",
    "        lb.Option(value=\"first_radio_answer\"),\n",
    "        lb.Option(value=\"second_radio_answer\")\n",
    "      ]\n",
    "    ),\n",
    "    lb.Classification(\n",
    "      class_type=lb.Classification.Type.CHECKLIST,\n",
    "      name=\"checklist_question\", \n",
    "      scope = lb.Classification.Scope.GLOBAL,\n",
    "      options=[\n",
    "        lb.Option(value=\"first_checklist_answer\"),\n",
    "        lb.Option(value=\"second_checklist_answer\")\n",
    "      ]\n",
    "    ), \n",
    "    lb.Classification(\n",
    "      class_type=lb.Classification.Type.TEXT,\n",
    "      name=\"free_text\",\n",
    "      scope = lb.Classification.Scope.GLOBAL\n",
    "    ),\n",
    "    lb.Classification(\n",
    "        class_type=lb.Classification.Type.RADIO,\n",
    "        name=\"nested_radio_question\",\n",
    "        scope = lb.Classification.Scope.GLOBAL,\n",
    "        options=[\n",
    "            lb.Option(\"first_radio_answer\",\n",
    "                options=[\n",
    "                    lb.Classification(\n",
    "                        class_type=lb.Classification.Type.RADIO,\n",
    "                        name=\"sub_radio_question\",\n",
    "                        options=[lb.Option(\"first_sub_radio_answer\")]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "          ] \n",
    "        ),\n",
    "    lb.Classification(\n",
    "      class_type=lb.Classification.Type.CHECKLIST,\n",
    "      name=\"nested_checklist_question\",\n",
    "      scope = lb.Classification.Scope.GLOBAL,\n",
    "      options=[\n",
    "          lb.Option(\"first_checklist_answer\",\n",
    "            options=[\n",
    "              lb.Classification(\n",
    "                  class_type=lb.Classification.Type.CHECKLIST,\n",
    "                  name=\"sub_checklist_question\", \n",
    "                  options=[lb.Option(\"first_sub_checklist_answer\")]\n",
    "              )\n",
    "          ]\n",
    "        )\n",
    "      ]\n",
    "    ),      \n",
    "  ],\n",
    "  tools=[ # List of Tool objects\n",
    "    lb.Tool( \n",
    "      tool=lb.Tool.Type.BBOX,\n",
    "      name=\"bounding_box\"), \n",
    "    lb.Tool(\n",
    "        tool=lb.Tool.Type.NER, \n",
    "        name=\"named_entity\")]\n",
    ")\n",
    "\n",
    "ontology = client.create_ontology(\"Document Annotation Import Demo\",\n",
    "                                  ontology_builder.asdict(),\n",
    "                                  media_type=lb.MediaType.Document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creating a labeling project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Labelbox project\n",
    "project = client.create_project(name=\"PDF_annotation_demo\",                                    \n",
    "                                    queue_mode=QueueMode.Batch,\n",
    "                                    media_type=lb.MediaType.Document)\n",
    "project.setup_editor(ontology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Send a batch of data rows to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.create_batch(\n",
    "  \"PDF_annotation_batch\", # Each batch in a project must have a unique name\n",
    "  list(dataset.export_data_rows()), # A list of data rows or data row ids\n",
    "  5 # priority between 1(Highest) - 5(lowest)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Create the annotation payload\n",
    "Create the annotations payload using the snippets of code in Supported predictions section.\n",
    "\n",
    "Labelbox support NDJSON only for this data type.\n",
    "\n",
    "The resulting label_ndjson should have exactly the same content for annotations that are supported by both (with exception of the uuid strings that are generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to construct our entity annotation using our text layer. \n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "## To learn how to generate a text layer for your documents please refer to the following repositories/files: \n",
    "# https://github.com/Labelbox/PDF-OCR-Transform-CLI/blob/main/src/scripts/gcloud/gcp-vision-to-lb-text-layer.py\n",
    "# https://github.com/Labelbox/PDF-OCR-Transform-CLI/blob/main/src/scripts/adobe/adobe-ocr-to-lb-text-layer.py\n",
    "\n",
    "text_layer = \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json\"\n",
    "\n",
    "## Fetch the content of the text layer\n",
    "res = requests.get(text_layer) \n",
    "\n",
    "\n",
    "\n",
    "## Parse the text layer\n",
    "text_selections = []\n",
    "for obj in json.loads(res.text):\n",
    "  for group in obj['groups']: \n",
    "    ## Find the text group that we are interested in annotating\n",
    "    if group['content'] == \"Metal-insulator (MI) transitions have been one of the\":\n",
    "      ## We now need all the tokens associated with each word in this text group\n",
    "      list_tokens = [x['id'] for x in group['tokens']]\n",
    "      document_text_selection = lb_types.DocumentTextSelection(groupId=group['id'], tokenIds=list_tokens, page=1)\n",
    "      text_selections.append(document_text_selection)\n",
    "      entities_annotations_ndjson.update(\n",
    "        {\n",
    "          \"textSelections\": [\n",
    "            {\n",
    "              \"groupId\": group['id'], #id associated with the group of words\n",
    "              \"tokenIds\": list_tokens, #id associated with each word in a sentence group\n",
    "              \"page\": 1,\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      )\n",
    "entities_annotation_document_entity = lb_types.DocumentEntity(name=\"named_entity\", \n",
    "                                          textSelections = text_selections)\n",
    "entities_annotation = lb_types.ObjectAnnotation(name=\"named_entity\",\n",
    "                                                value=entities_annotation_document_entity)\n",
    "        \n",
    "print(f\"entities_annotations_ndjson={entities_annotations_ndjson}\")\n",
    "print(f\"entities_annotation={entities_annotation}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python annotation\n",
    "Here we create the complete labels ndjson payload of annotations only using python annotation format. There is one annotation for each reference to an annotation that we created. Note that only a handful of python annotation types are supported for PDF documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Label\n",
    "\n",
    "labels = []\n",
    "for data_row in dataset.export_data_rows():\n",
    "  labels.append(lb_types.Label(\n",
    "      data=lb_types.TextData(\n",
    "          uid=data_row.uid),\n",
    "      annotations = [\n",
    "          entities_annotation,\n",
    "          checklist_annotation, \n",
    "          text_annotation,\n",
    "          radio_annotation\n",
    "      ]\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDJson annotations\n",
    "Here we create the complete labels ndjson payload of annotations only using NDJSON format. There is one annotation for each reference to an annotation that we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ndjson_annotation = []\n",
    "for annot in [\n",
    "    entities_annotations_ndjson,\n",
    "    bbox_annotation_ndjson,\n",
    "    text_annotation_ndjson,\n",
    "    checklist_annotation_ndjson,\n",
    "    nested_checklist_annotation_ndjson,\n",
    "    nested_radio_annotation_ndjson,\n",
    "    radio_annotation_ndjson\n",
    "  ]:\n",
    "  annot.update({\n",
    "      'dataRow': {'id': data_row.uid},\n",
    "  })\n",
    "  ndjson_annotation.append(annot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Import the annotation payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option A: Upload to a labeling project as pre-labels (MAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_job = lb.MALPredictionImport.create_from_objects(\n",
    "#     client = client,\n",
    "#     project_id = project.uid,\n",
    "#     name=\"pdf_annotation_upload\" + str(uuid.uuid4()),\n",
    "#     predictions=ndjson_annotation)\n",
    "\n",
    "upload_job = lb.MALPredictionImport.create_from_objects(\n",
    "    client = client,\n",
    "    project_id = project.uid,\n",
    "    name=\"pdf_annotation_upload\" + str(uuid.uuid4()),\n",
    "    predictions=labels)\n",
    "\n",
    "upload_job.wait_until_done()\n",
    "# Errors will appear for annotation uploads that failed.\n",
    "print(\"Errors:\", upload_job.errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option B: Upload to a labeling project using ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upload_job = lb.LabelImport.create_from_objects(\n",
    "    client = client, \n",
    "    project_id = project.uid, \n",
    "    name=\"label_import_job\"+str(uuid.uuid4()),  \n",
    "    labels=ndjson_annotation)\n",
    "\n",
    "print(\"Errors:\", upload_job.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
