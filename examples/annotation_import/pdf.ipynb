{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/annotation_import/pdf.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/annotation_import/pdf.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PDF Annotation Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Supported annotations for PDF assets \n",
        "\n",
        "*Annotation types*\n",
        "- Checklist classification \n",
        "- Radio classifications \n",
        "- Free text classifications\n",
        "- Entities\n",
        "\n",
        "\n",
        "*NDJson*\n",
        "- Checklist classification (including nested classifications)\n",
        "- Radio classifications (including nested classifications)\n",
        "- Free text classifications\n",
        "- Bounding box \n",
        "- Entities "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q 'labelbox[data]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "from labelbox.schema.queue_mode import QueueMode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Replace with your API key\n",
        "Guides on https://docs.labelbox.com/docs/create-an-api-key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add your api key\n",
        "API_KEY = \"\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Supported Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "########## Entity ##########\n",
        "\n",
        "# Annotation Types\n",
        "entities_annotations = lb_types.ObjectAnnotation(\n",
        "    name=\"named_entity\",\n",
        "    value= lb_types.DocumentEntity(\n",
        "        name=\"named_entity\",\n",
        "        textSelections=[\n",
        "            lb_types.DocumentTextSelection(\n",
        "                token_ids=[],\n",
        "                group_id=\"\",\n",
        "                page=1\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "entities_annotations_ndjson = { \n",
        "    \"name\": \"named_entity\",\n",
        "    \"textSelections\": [\n",
        "        {\n",
        "            \"tokenIds\": [\n",
        "                \"<UUID>\",\n",
        "            ],\n",
        "            \"groupId\": \"<UUID>\",\n",
        "            \"page\": 1,\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "########### Radio Classification #########\n",
        "\n",
        "# Annotation types \n",
        "radio_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_question\",\n",
        "    value=lb_types.Radio(answer = \n",
        "        lb_types.ClassificationAnswer(name = \"first_radio_answer\")\n",
        "    )\n",
        ")\n",
        "# NDJSON\n",
        "radio_annotation_ndjson = {\n",
        "  'name': 'radio_question',\n",
        "  'answer': {'name': 'first_radio_answer'}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "############ Checklist Classification ###########\n",
        "\n",
        "# Annotation types \n",
        "checklist_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"checklist_question\",\n",
        "    value=lb_types.Checklist(answer = [\n",
        "        lb_types.ClassificationAnswer(name = \"first_checklist_answer\"),\n",
        "        lb_types.ClassificationAnswer(name = \"second_checklist_answer\")\n",
        "    ])\n",
        "  )\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "checklist_annotation_ndjson = {\n",
        "  'name': 'checklist_question',\n",
        "  'answer': [\n",
        "    {'name': 'first_checklist_answer'},\n",
        "    {'name': 'second_checklist_answer'}\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "############ Bounding Box ###########\n",
        "\n",
        "bbox_annotation_ndjson = {\n",
        "  'name': 'bounding_box',\n",
        "  'bbox': {\n",
        "          \"top\": 42.799,\n",
        "          \"left\": 86.498,\n",
        "          \"height\": 141.911,\n",
        "          \"width\": 303.195\n",
        "      },\n",
        "  'page': 0,\n",
        "  'unit': \"POINTS\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ############ nested classifications ###########\n",
        "\n",
        "nested_checklist_annotation_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\", \n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\", \n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\"}\n",
        "        }          \n",
        "      ]         \n",
        "  }]\n",
        "}\n",
        "\n",
        "nested_radio_annotation_ndjson = {\n",
        "  'name': 'nested_radio_question',\n",
        "  'answer': {\n",
        "      'name': 'first_radio_answer',\n",
        "      'classifications': [{\n",
        "          'name':'sub_radio_question',\n",
        "          'answer': { 'name' : 'first_sub_radio_answer'}\n",
        "        }]\n",
        "    }\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "############## Classification Free-form text ############## \n",
        "\n",
        "text_annotation = lb_types.ClassificationAnnotation(\n",
        "  name=\"free_text\",  # must match your ontology feature's name\n",
        "  value=lb_types.Text(answer=\"sample text\")\n",
        ")\n",
        "\n",
        "\n",
        "text_annotation_ndjson = {\n",
        "  'name': 'free_text',\n",
        "  'answer': 'sample text'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Annotations - putting it all together "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Import data rows into Catalog "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Text layer url is required for uploading entity annotations\n",
        "global_key = \"0801.3483.pd\"\n",
        "img_url = {\n",
        "    \"row_data\": {\n",
        "      \"pdf_url\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483.pdf\",\n",
        "      \"text_layer_url\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json\"\n",
        "    },\n",
        "    \"global_key\": global_key\n",
        "}\n",
        "\n",
        "\n",
        "dataset = client.create_dataset(name=\"pdf_demo_dataset\")\n",
        "task = dataset.create_data_rows([img_url])\n",
        "task.wait_till_done()\n",
        "print(\"Errors:\",task.errors)\n",
        "print(\"Failed data rows:\", task.failed_data_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Create/select an Ontology for your project\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Setup the ontology and link the tools created above.\n",
        "\n",
        "ontology_builder = lb.OntologyBuilder(\n",
        "  classifications=[ # List of Classification objects\n",
        "    lb.Classification( \n",
        "      class_type=lb.Classification.Type.RADIO,\n",
        "      name=\"radio_question\", \n",
        "      scope = lb.Classification.Scope.GLOBAL,\n",
        "      options=[\n",
        "        lb.Option(value=\"first_radio_answer\"),\n",
        "        lb.Option(value=\"second_radio_answer\")\n",
        "      ]\n",
        "    ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.CHECKLIST,\n",
        "      name=\"checklist_question\", \n",
        "      scope = lb.Classification.Scope.GLOBAL,\n",
        "      options=[\n",
        "        lb.Option(value=\"first_checklist_answer\"),\n",
        "        lb.Option(value=\"second_checklist_answer\")\n",
        "      ]\n",
        "    ), \n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.TEXT,\n",
        "      name=\"free_text\",\n",
        "      scope = lb.Classification.Scope.GLOBAL\n",
        "    ),\n",
        "    lb.Classification(\n",
        "        class_type=lb.Classification.Type.RADIO,\n",
        "        name=\"nested_radio_question\",\n",
        "        scope = lb.Classification.Scope.GLOBAL,\n",
        "        options=[\n",
        "            lb.Option(\"first_radio_answer\",\n",
        "                options=[\n",
        "                    lb.Classification(\n",
        "                        class_type=lb.Classification.Type.RADIO,\n",
        "                        name=\"sub_radio_question\",\n",
        "                        options=[lb.Option(\"first_sub_radio_answer\")]\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "          ] \n",
        "        ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.CHECKLIST,\n",
        "      name=\"nested_checklist_question\",\n",
        "      scope = lb.Classification.Scope.GLOBAL,\n",
        "      options=[\n",
        "          lb.Option(\"first_checklist_answer\",\n",
        "            options=[\n",
        "              lb.Classification(\n",
        "                  class_type=lb.Classification.Type.CHECKLIST,\n",
        "                  name=\"sub_checklist_question\", \n",
        "                  options=[lb.Option(\"first_sub_checklist_answer\")]\n",
        "              )\n",
        "          ]\n",
        "        )\n",
        "      ]\n",
        "    ),      \n",
        "  ],\n",
        "  tools=[ # List of Tool objects\n",
        "    lb.Tool( \n",
        "      tool=lb.Tool.Type.BBOX,\n",
        "      name=\"bounding_box\"), \n",
        "    lb.Tool(\n",
        "        tool=lb.Tool.Type.NER, \n",
        "        name=\"named_entity\")]\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Document Annotation Import Demo\",\n",
        "                                  ontology_builder.asdict(),\n",
        "                                  media_type=lb.MediaType.Document)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Creating a labeling project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a Labelbox project\n",
        "project = client.create_project(name=\"PDF_annotation_demo\",                                    \n",
        "                                    queue_mode=QueueMode.Batch,\n",
        "                                    media_type=lb.MediaType.Document)\n",
        "project.setup_editor(ontology)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Send a batch of data rows to the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Batch ID: e2152a50-c402-11ed-9933-959d2b6c8c3c>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project.create_batch(\n",
        "  \"PDF_annotation_batch\", # Each batch in a project must have a unique name\n",
        "  global_keys=global_key, # A list of data rows or data row ids\n",
        "  priority=5 # priority between 1(Highest) - 5(lowest)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5. Create the annotation payload\n",
        "Create the annotations payload using the snippets of code in Supported predictions section.\n",
        "\n",
        "Labelbox support NDJSON only for this data type.\n",
        "\n",
        "The resulting label should have exactly the same content for annotations that are supported by both (with exception of the uuid strings that are generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### First, we need to populate the text selections for Entity annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entities_annotations_ndjson={'name': 'named_entity', 'textSelections': [{'groupId': '2f4336f4-a07e-4e0a-a9e1-5629b03b719b', 'tokenIds': ['3f984bf3-1d61-44f5-b59a-9658a2e3440f', '3bf00b56-ff12-4e52-8cc1-08dbddb3c3b8', '6e1c3420-d4b7-4c5a-8fd6-ead43bf73d80', '87a43d32-af76-4a1d-b262-5c5f4d5ace3a', 'e8606e8a-dfd9-4c49-a635-ad5c879c75d0', '67c7c19e-4654-425d-bf17-2adb8cf02c30', '149c5e80-3e07-49a7-ab2d-29ddfe6a38fa', 'b0e94071-2187-461e-8e76-96c58738a52c'], 'page': 1}]}\n",
            "entities_annotation=confidence=None name='named_entity' feature_schema_id=None extra={} value=DocumentEntity(text_selections=[DocumentTextSelection(token_ids=['3f984bf3-1d61-44f5-b59a-9658a2e3440f', '3bf00b56-ff12-4e52-8cc1-08dbddb3c3b8', '6e1c3420-d4b7-4c5a-8fd6-ead43bf73d80', '87a43d32-af76-4a1d-b262-5c5f4d5ace3a', 'e8606e8a-dfd9-4c49-a635-ad5c879c75d0', '67c7c19e-4654-425d-bf17-2adb8cf02c30', '149c5e80-3e07-49a7-ab2d-29ddfe6a38fa', 'b0e94071-2187-461e-8e76-96c58738a52c'], group_id='2f4336f4-a07e-4e0a-a9e1-5629b03b719b', page=1)]) classifications=[]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "# To learn how to generate a text layer for your documents please refer to the following repositories/files: \n",
        "# https://github.com/Labelbox/PDF-OCR-Transform-CLI/blob/main/src/scripts/gcloud/gcp-vision-to-lb-text-layer.py\n",
        "# https://github.com/Labelbox/PDF-OCR-Transform-CLI/blob/main/src/scripts/adobe/adobe-ocr-to-lb-text-layer.py\n",
        "\n",
        "text_layer = \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json\"\n",
        "\n",
        "# Fetch the content of the text layer\n",
        "res = requests.get(text_layer) \n",
        "\n",
        "\n",
        "\n",
        "# Parse the text layer\n",
        "text_selections = []\n",
        "for obj in json.loads(res.text):\n",
        "  for group in obj['groups']: \n",
        "    # Find the text group that we are interested in annotating\n",
        "    if group['content'] == \"Metal-insulator (MI) transitions have been one of the\":\n",
        "      # We now need all the tokens associated with each word in this text group\n",
        "      list_tokens = [x['id'] for x in group['tokens']]\n",
        "      # build text selections for Annotation Types\n",
        "      document_text_selection = lb_types.DocumentTextSelection(groupId=group['id'], tokenIds=list_tokens, page=1)\n",
        "      text_selections.append(document_text_selection)\n",
        "      \n",
        "      # build text selection for the NDJson annotation\n",
        "      entities_annotations_ndjson.update(\n",
        "        {\n",
        "          \"textSelections\": [\n",
        "            {\n",
        "              \"groupId\": group['id'], #id associated with the group of words\n",
        "              \"tokenIds\": list_tokens, #id associated with each word in a sentence group\n",
        "              \"page\": 1,\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      )\n",
        "# re-write the entity annotation with text selections (annotation types)\n",
        "entities_annotation_document_entity = lb_types.DocumentEntity(name=\"named_entity\", \n",
        "                                          textSelections = text_selections)\n",
        "entities_annotation = lb_types.ObjectAnnotation(name=\"named_entity\",\n",
        "                                                value=entities_annotation_document_entity)\n",
        "        \n",
        "print(f\"entities_annotations_ndjson={entities_annotations_ndjson}\")\n",
        "print(f\"entities_annotation={entities_annotation}\")\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Python annotation\n",
        "Here we create the complete labels ndjson payload of annotations only using python annotation format. There is one annotation for each reference to an annotation that we created. Note that only a handful of python annotation types are supported for PDF documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a Label\n",
        "\n",
        "labels = []\n",
        "\n",
        "labels.append(lb_types.Label(\n",
        "    data=lb_types.DocumentData(\n",
        "        global_key=global_key),\n",
        "    annotations = [\n",
        "        entities_annotation,\n",
        "        checklist_annotation, \n",
        "        text_annotation,\n",
        "        radio_annotation\n",
        "    ]\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### NDJson annotations\n",
        "Here we create the complete labels ndjson payload of annotations only using NDJSON format. There is one annotation for each reference to an annotation that we created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ndjson_annotation = []\n",
        "for annot in [\n",
        "    entities_annotations_ndjson,\n",
        "    bbox_annotation_ndjson,\n",
        "    text_annotation_ndjson,\n",
        "    checklist_annotation_ndjson,\n",
        "    nested_checklist_annotation_ndjson,\n",
        "    nested_radio_annotation_ndjson,\n",
        "    radio_annotation_ndjson\n",
        "  ]:\n",
        "  annot.update({\n",
        "      'dataRow': {'globalKey': global_key},\n",
        "  })\n",
        "  ndjson_annotation.append(annot)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Import the annotation payload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Option A: Upload to a labeling project as pre-labels (MAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "upload_job = lb.MALPredictionImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid,\n",
        "    name=\"pdf_annotation_upload\" + str(uuid.uuid4()),\n",
        "    predictions=ndjson_annotation)\n",
        "\n",
        "upload_job.wait_until_done()\n",
        "# Errors will appear for annotation uploads that failed.\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Option B: Upload to a labeling project using ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "upload_job = lb.LabelImport.create_from_objects(\n",
        "    client = client, \n",
        "    project_id = project.uid, \n",
        "    name=\"label_import_job\"+str(uuid.uuid4()),  \n",
        "    labels=ndjson_annotation)\n",
        "\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
