{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/annotation_import/video.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/annotation_import/video.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td> "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Video Annotation Import\n",
        "\n",
        "* Annotations must be created and uploaded using NDJSON\n",
        "* Supported annotations that can be uploaded through the SDK:\n",
        "    * Bounding box\n",
        "    * Point\n",
        "    * Polyline \n",
        "    * Radio classifications \n",
        "    * Checklist classifications \n",
        "* **NOT** supported:\n",
        "    * Polygons \n",
        "    * Segmentation masks\n",
        "    * Free form text classifications\n",
        "\n",
        "Please note that this list of unsupported annotations only refers to limitations for importing annotations. For example, when using the Labelbox editor, segmentation masks can be created and edited on video assets."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Setup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q 'labelbox[data]'"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import uuid"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Replace with your API key \n",
        "Guides on [Create an API key](https://docs.labelbox.com/docs/create-an-api-key)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Add your api key\n",
        "API_KEY=None\n",
        "client = lb.Client(api_key=API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Supported annotations for video\n",
        "Only NDJSON annotations are supported with video assets"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Supported NDJSON annotations"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "######## Bounding box  ###########\n",
        "\n",
        "# NDJSON\n",
        "bbox_annotation_ndjson = {\n",
        "    \"name\" : \"bbox_video\",\n",
        "    \"segments\" : [{\n",
        "        \"keyframes\" : [\n",
        "            {\n",
        "              \"frame\": 13,\n",
        "              \"bbox\" : {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              }  \n",
        "           },\n",
        "           {\n",
        "              \"frame\": 14,\n",
        "              \"bbox\" : {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              }  \n",
        "           },\n",
        "           {\n",
        "              \"frame\": 15,\n",
        "              \"bbox\" : {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              }  \n",
        "           }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Point ########\n",
        "\n",
        "#NDJSON\n",
        "point_annotation_ndjson = {\n",
        "    \"name\": \"point_video\", \n",
        "    \"segments\": [{\n",
        "        \"keyframes\": [{\n",
        "            \"frame\": 17,\n",
        "            \"point\" : {\n",
        "                \"x\": 660.134 ,\n",
        "                \"y\": 407.926\n",
        "            }\n",
        "        }]\n",
        "    }] \n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Polyline ########\n",
        "\n",
        "# NDJSON (frame based annotations are supported with NDJSON format)\n",
        "polyline_frame_annotation_ndjson = {\n",
        "  \"name\": \"line_video_frame\", \n",
        "  \"segments\": [\n",
        "      {\n",
        "        \"keyframes\": [\n",
        "          {\n",
        "            \"frame\": 5,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 100\n",
        "            },{\n",
        "              \"x\": 100,\n",
        "              \"y\": 190\n",
        "            },{\n",
        "              \"x\": 190,\n",
        "              \"y\": 220\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 12,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 280\n",
        "            },{\n",
        "              \"x\": 300,\n",
        "              \"y\": 380\n",
        "            },{\n",
        "              \"x\": 400,\n",
        "              \"y\": 460\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 20,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 180\n",
        "            },{\n",
        "              \"x\": 100,\n",
        "              \"y\": 200\n",
        "            },{\n",
        "              \"x\": 200,\n",
        "              \"y\": 260\n",
        "            }]\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"keyframes\": [\n",
        "          {\n",
        "            \"frame\": 24,\n",
        "            \"line\": [{\n",
        "              \"x\": 300,\n",
        "              \"y\": 310\n",
        "            },{\n",
        "              \"x\": 330,\n",
        "              \"y\": 430\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 45,\n",
        "            \"line\": [{\n",
        "              \"x\": 600,\n",
        "              \"y\": 810\n",
        "            },{\n",
        "              \"x\": 900,\n",
        "              \"y\": 930\n",
        "            }]\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## classifications ########\n",
        "\n",
        "## NDJSON\n",
        "\n",
        "## frame specific\n",
        "frame_checklist_classification_ndjson = {\n",
        "    \"name\": \"checklist_class\", \n",
        "    \"answer\": [\n",
        "        { \"name\": \"first_checklist_answer\" , \"frames\": [{\"start\": 29, \"end\": 35 }, {\"start\": 48, \"end\": 65}]},\n",
        "        { \"name\": \"second_checklist_answer\", \"frames\": [{\"start\": 29, \"end\": 35 }, {\"start\": 48, \"end\": 65}]} \n",
        "  ]      \n",
        "}\n",
        "\n",
        "# Global \n",
        "global_radio_classification_ndjson = {\n",
        "    \"name\": \"radio_class_global\", \n",
        "    \"answer\": { \"name\": \"first_radio_answer\" }\n",
        "}\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Nested Global Classification ########### \n",
        "\n",
        "nested_radio_classification = {\n",
        "  'name': 'radio_question_nested',\n",
        "  'answer': {'name': 'first_radio_question'},\n",
        "  'classifications' : [\n",
        "    {'name': 'sub_question_radio', 'answer': {'name': 'sub_answer'}}\n",
        "   ]\n",
        "}\n",
        "\n",
        "nested_checklist_annotation_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\",\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\",\n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\"}\n",
        "        }\n",
        "      ]\n",
        "  }]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Classifications under frame base tools ##########\n",
        "\n",
        "# Frame base nested classifications do not support using the feature's name to extract ontology features. \n",
        "# For this single case we are going to use the classification's featureSchemaId and the answers' featureSchemaId \n",
        "# We will update the annotation object with the featureSchemaIds on step 5 after we create the ontology in step 2\n",
        "\n",
        "\n",
        "frame_bbox_with_checklist_subclass_ndjson = {\n",
        "    \"name\": \"bbox_class\",\n",
        "    \"segments\": [{\n",
        "        \"keyframes\": [\n",
        "            {\n",
        "            \"frame\": 10,\n",
        "            \"bbox\": {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              },\n",
        "            \"classifications\" : [\n",
        "              {'schemaId' : '', 'answer' : {'schemaId': '' }}\n",
        "            ]     \n",
        "          },\n",
        "          {  \n",
        "          \"frame\": 11,\n",
        "            \"bbox\": {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              },\n",
        "            \"classifications\" : [\n",
        "              {'schemaId' : '', 'answer' : {'schemaId': '' }}\n",
        "            ]  \n",
        "          },\n",
        "          {  \n",
        "          \"frame\": 13,\n",
        "            \"bbox\": {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              },\n",
        "            \"classifications\" : [\n",
        "              {'schemaId' : '', 'answer' : {'schemaId': '' }}\n",
        "            ]  \n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Upload Annotations - putting it all together"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Step 1: Import data rows into Catalog"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "asset = {\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/video-sample-data/sample-video-2.mp4\", \n",
        "    \"global_key\": str(uuid.uuid4()),\n",
        "    \"media_type\": \"VIDEO\"\n",
        "}\n",
        "\n",
        "dataset = client.create_dataset(name=\"video_demo_dataset\")\n",
        "data_row = dataset.create_data_row(asset)\n",
        "print(data_row.uid)\n",
        "print(data_row)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cldxj6yxi0a4o07yc8qkf0bvm\n",
            "<DataRow {\n",
            "    \"created_at\": \"2023-02-09 20:07:18+00:00\",\n",
            "    \"external_id\": null,\n",
            "    \"global_key\": \"d8a068c5-4531-43c5-959b-fe0c34f7f2d0\",\n",
            "    \"media_attributes\": {},\n",
            "    \"metadata\": [],\n",
            "    \"metadata_fields\": [],\n",
            "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/video-sample-data/sample-video-2.mp4\",\n",
            "    \"uid\": \"cldxj6yxi0a4o07yc8qkf0bvm\",\n",
            "    \"updated_at\": \"2023-02-09 20:07:18+00:00\"\n",
            "}>\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 2: Create/select an ontology\n",
        "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the `name` fields in your annotations to ensure the correct feature schemas are matched.\n",
        "\n",
        "For example, when we create the bounding box annotation above, we provided the `name` as `bbox_video`. Now, when we setup our ontology, we must ensure that the name of my bounding box tool is also `bbox_video`. The same alignment must hold true for the other tools and classifications we create in our ontology.\n",
        "\n",
        "\n",
        "[Documentation for reference ](https://docs.labelbox.com/reference/import-text-annotations)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "ontology_builder = lb.OntologyBuilder(\n",
        "    tools=[\n",
        "        lb.Tool(tool=lb.Tool.Type.BBOX, name=\"bbox_video\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.POINT, name=\"point_video\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.LINE, name=\"line_video_frame\"),\n",
        "        lb.Tool(\n",
        "          tool=lb.Tool.Type.BBOX, name=\"bbox_class\",\n",
        "          classifications=[\n",
        "            lb.Classification(\n",
        "              class_type=lb.Classification.Type.RADIO,\n",
        "              name=\"bbox_radio\",\n",
        "              scope = lb.Classification.Scope.INDEX,\n",
        "              options=[\n",
        "                lb.Option(value=\"bbox_radio_answer_1\"),\n",
        "                lb.Option(value=\"bbox_radio_answer_2\"),\n",
        "                lb.Option(value=\"bbox_radio_answer_3\")\n",
        "              ]\n",
        "            )\n",
        "          ]\n",
        "        )\n",
        "    ],\n",
        "    classifications=[ \n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.CHECKLIST,\n",
        "            name=\"checklist_class\",\n",
        "            scope = lb.Classification.Scope.INDEX, ## Need to defined scope for frame classifications\n",
        "            options=[ \n",
        "                lb.Option(value=\"first_checklist_answer\"),\n",
        "                lb.Option(value=\"second_checklist_answer\")\n",
        "            ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.RADIO,\n",
        "            name=\"radio_class_global\",\n",
        "            options=[ \n",
        "                lb.Option(value=\"first_radio_answer\"),\n",
        "                lb.Option(value=\"second_radio_answer\")\n",
        "            ]\n",
        "        ),\n",
        "         lb.Classification(\n",
        "              class_type=lb.Classification.Type.RADIO,\n",
        "              name=\"radio_question_nested\",\n",
        "              options=[\n",
        "                  lb.Option(\"first_radio_question\",\n",
        "                        options=[\n",
        "                            lb.Classification(\n",
        "                                class_type=lb.Classification.Type.RADIO,\n",
        "                                name=\"sub_question_radio\",\n",
        "                                options=[lb.Option(\"sub_answer\")]\n",
        "                            )\n",
        "                        ]\n",
        "                  )\n",
        "              ] \n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.CHECKLIST,\n",
        "          name=\"nested_checklist_question\",\n",
        "          options=[\n",
        "              lb.Option(\"first_checklist_answer\",\n",
        "                options=[\n",
        "                  lb.Classification(\n",
        "                      class_type=lb.Classification.Type.CHECKLIST,\n",
        "                      name=\"sub_checklist_question\",\n",
        "                      options=[lb.Option(\"first_sub_checklist_answer\")]\n",
        "                  )\n",
        "              ]\n",
        "            )\n",
        "          ]\n",
        "        ),\n",
        "    ]  \n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Ontology Video Annotations\", ontology_builder.asdict(), media_type=lb.MediaType.Video)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 3: Create a labeling project \n",
        "Connect the ontology to the labeling project."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Project defaults to batch mode with benchmark quality settings if this argument is not provided\n",
        "# Queue mode will be deprecated once dataset mode is deprecated\n",
        "\n",
        "project = client.create_project(name=\"video_project_demo\",\n",
        "                                    queue_mode=lb.QueueMode.Batch,\n",
        "                                    media_type=lb.MediaType.Video)\n",
        "\n",
        "## connect ontology to your project\n",
        "project.setup_editor(ontology)\n",
        "\n",
        "######################### DATASET CONSENSUS OPTION ########################\n",
        "# Note that dataset base projects will be deprecated in the near future.\n",
        "\n",
        "# To use Datasets/Consensus instead of Batches/Benchmarks use the following query: \n",
        "# In this case, 10% of all data rows need to be annotated by three labelers.\n",
        "\n",
        "# dataset_project = client.create_project(name=\"dataset-test-project\",\n",
        "#                                 description=\"a description\",\n",
        "#                                 media_type=lb.MediaType.Text,\n",
        "#                                 auto_audit_percentage=0.1,\n",
        "#                                 auto_audit_number_of_labels=3,\n",
        "#                                 queue_mode=lb.QueueMode.Dataset)\n",
        "\n",
        "# dataset_project.datasets.connect(dataset)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 4: Send a batch of data rows to the project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create batches\n",
        "\n",
        "# Create a batch to send to your MAL project\n",
        "batch = project.create_batch(\n",
        "  \"first-batch-video-demo2\", # Each batch in a project must have a unique name\n",
        "  dataset.export_data_rows(), # A paginated collection of data row objects\n",
        "  5 # priority between 1(Highest) - 5(lowest)\n",
        ")\n",
        "\n",
        "print(\"Batch: \", batch)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch:  <Batch {\n",
            "    \"consensus_settings_json\": \"{\\\"numberOfLabels\\\":1,\\\"coveragePercentage\\\":0}\",\n",
            "    \"created_at\": \"2023-02-09 20:07:25+00:00\",\n",
            "    \"name\": \"first-batch-video-demo2\",\n",
            "    \"size\": 1,\n",
            "    \"uid\": \"5f05dc80-a8b5-11ed-80d6-db14826c319c\",\n",
            "    \"updated_at\": \"2023-02-09 20:07:25+00:00\"\n",
            "}>\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 5: Create the annotations payload \n",
        "Create the annotations payload using the snippets of code above.\n",
        "\n",
        "Labelbox supports two formats for the annotations payload: NDJSON and Python Annotation types. However, for video assets, only NDJSON format is supported."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### NDJSON annotations\n",
        "Here we create the complete `label_ndjson` payload of annotations. There is one annotation for each *reference to an annotation* that we created above."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## For nested frame base classifications we need to pass a featureSchemaId instead of the name. \n",
        "\n",
        "features = project.ontology().normalized\n",
        "\n",
        "for i in features['tools']:\n",
        "  print(i)\n",
        "  if i['name'] == 'bbox_class':\n",
        "    ## Classification feature schema id\n",
        "    class_feature_schema_id = i['classifications'][0]['featureSchemaId']\n",
        "    ## Answer feature schema id (select one of the answers)\n",
        "    class_options_feature_schema_id = i['classifications'][0]['options'][0]['featureSchemaId']\n",
        "\n",
        "    ## Update the original annotation with the schema ids\n",
        "    for frame in frame_bbox_with_checklist_subclass_ndjson['segments']:\n",
        "      for k in frame['keyframes']:\n",
        "        k['classifications'][0].update(\n",
        "            {'schemaId': class_feature_schema_id , \n",
        "              'answer': {'schemaId': class_options_feature_schema_id}\n",
        "              }\n",
        "            )\n",
        "        "
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'schemaNodeId': 'cldxj6zy80cvx07vdbg7q9qhs', 'featureSchemaId': 'cldxj6zy80cvw07vd9l34hymh', 'required': False, 'name': 'bbox_video', 'tool': 'rectangle', 'color': '#ff0000', 'archived': 0, 'classifications': []}\n",
            "{'schemaNodeId': 'cldxj6zy80cvz07vdf9285zd6', 'featureSchemaId': 'cldxj6zy80cvy07vdbad5dzyi', 'required': False, 'name': 'point_video', 'tool': 'point', 'color': '#7fff00', 'archived': 0, 'classifications': []}\n",
            "{'schemaNodeId': 'cldxj6zy80cw107vd7fdq6uyw', 'featureSchemaId': 'cldxj6zy80cw007vdb3hmau7o', 'required': False, 'name': 'line_video_frame', 'tool': 'line', 'color': '#00ffff', 'archived': 0, 'classifications': []}\n",
            "{'schemaNodeId': 'cldxj6zy90cwb07vd2cdgacin', 'featureSchemaId': 'cldxj6zy80cw207vd3brweppe', 'required': False, 'name': 'bbox_class', 'tool': 'rectangle', 'color': '#7f00ff', 'archived': 0, 'classifications': [{'schemaNodeId': 'cldxj6zy80cwa07vdc3qm8yb2', 'featureSchemaId': 'cldxj6zy80cw307vdgapmcu4e', 'archived': 0, 'required': False, 'instructions': 'bbox_radio', 'name': 'bbox_radio', 'type': 'radio', 'options': [{'schemaNodeId': 'cldxj6zy80cw507vd0r2aadwy', 'featureSchemaId': 'cldxj6zy80cw407vd1ynfckwg', 'label': 'bbox_radio_answer_1', 'value': 'bbox_radio_answer_1'}, {'schemaNodeId': 'cldxj6zy80cw707vda3bqeb9g', 'featureSchemaId': 'cldxj6zy80cw607vd4gel3yrq', 'label': 'bbox_radio_answer_2', 'value': 'bbox_radio_answer_2'}, {'schemaNodeId': 'cldxj6zy80cw907vdhm8c88gw', 'featureSchemaId': 'cldxj6zy80cw807vdhzst22m8', 'label': 'bbox_radio_answer_3', 'value': 'bbox_radio_answer_3'}]}]}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "label_ndjson = []\n",
        "\n",
        "for annotations in [point_annotation_ndjson,\n",
        "                    bbox_annotation_ndjson,\n",
        "                    polyline_frame_annotation_ndjson, \n",
        "                    frame_checklist_classification_ndjson, \n",
        "                    global_radio_classification_ndjson,\n",
        "                    nested_radio_classification,\n",
        "                    nested_checklist_annotation_ndjson,\n",
        "                    frame_bbox_with_checklist_subclass_ndjson\n",
        "                    ]:      \n",
        "  annotations.update({\n",
        "      'dataRow': {\n",
        "          'id':  next(dataset.export_data_rows()).uid\n",
        "      }\n",
        "  })\n",
        "  label_ndjson.append(annotations)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "label_ndjson"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'point_video',\n",
              "  'segments': [{'keyframes': [{'frame': 17,\n",
              "      'point': {'x': 660.134, 'y': 407.926}}]}],\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}},\n",
              " {'name': 'bbox_video',\n",
              "  'segments': [{'keyframes': [{'frame': 13,\n",
              "      'bbox': {'top': 146.0, 'left': 98.0, 'height': 382.0, 'width': 341.0}},\n",
              "     {'frame': 14,\n",
              "      'bbox': {'top': 146.0, 'left': 98.0, 'height': 382.0, 'width': 341.0}},\n",
              "     {'frame': 15,\n",
              "      'bbox': {'top': 146.0,\n",
              "       'left': 98.0,\n",
              "       'height': 382.0,\n",
              "       'width': 341.0}}]}],\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}},\n",
              " {'name': 'line_video_frame',\n",
              "  'segments': [{'keyframes': [{'frame': 5,\n",
              "      'line': [{'x': 680, 'y': 100},\n",
              "       {'x': 100, 'y': 190},\n",
              "       {'x': 190, 'y': 220}]},\n",
              "     {'frame': 12,\n",
              "      'line': [{'x': 680, 'y': 280},\n",
              "       {'x': 300, 'y': 380},\n",
              "       {'x': 400, 'y': 460}]},\n",
              "     {'frame': 20,\n",
              "      'line': [{'x': 680, 'y': 180},\n",
              "       {'x': 100, 'y': 200},\n",
              "       {'x': 200, 'y': 260}]}]},\n",
              "   {'keyframes': [{'frame': 24,\n",
              "      'line': [{'x': 300, 'y': 310}, {'x': 330, 'y': 430}]},\n",
              "     {'frame': 45, 'line': [{'x': 600, 'y': 810}, {'x': 900, 'y': 930}]}]}],\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}},\n",
              " {'name': 'checklist_class',\n",
              "  'answer': [{'name': 'first_checklist_answer',\n",
              "    'frames': [{'start': 29, 'end': 35}, {'start': 48, 'end': 65}]},\n",
              "   {'name': 'second_checklist_answer',\n",
              "    'frames': [{'start': 29, 'end': 35}, {'start': 48, 'end': 65}]}],\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}},\n",
              " {'name': 'radio_class_global',\n",
              "  'answer': {'name': 'first_radio_answer'},\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}},\n",
              " {'name': 'radio_question_nested',\n",
              "  'answer': {'name': 'first_radio_question'},\n",
              "  'classifications': [{'name': 'sub_question_radio',\n",
              "    'answer': {'name': 'sub_answer'}}],\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}},\n",
              " {'name': 'nested_checklist_question',\n",
              "  'answer': [{'name': 'first_checklist_answer',\n",
              "    'classifications': [{'name': 'sub_checklist_question',\n",
              "      'answer': {'name': 'first_sub_checklist_answer'}}]}],\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}},\n",
              " {'name': 'bbox_class',\n",
              "  'segments': [{'keyframes': [{'frame': 10,\n",
              "      'bbox': {'top': 146.0, 'left': 98.0, 'height': 382.0, 'width': 341.0},\n",
              "      'classifications': [{'schemaId': 'cldxj6zy80cw307vdgapmcu4e',\n",
              "        'answer': {'schemaId': 'cldxj6zy80cw407vd1ynfckwg'}}]},\n",
              "     {'frame': 11,\n",
              "      'bbox': {'top': 146.0, 'left': 98.0, 'height': 382.0, 'width': 341.0},\n",
              "      'classifications': [{'schemaId': 'cldxj6zy80cw307vdgapmcu4e',\n",
              "        'answer': {'schemaId': 'cldxj6zy80cw407vd1ynfckwg'}}]},\n",
              "     {'frame': 13,\n",
              "      'bbox': {'top': 146.0, 'left': 98.0, 'height': 382.0, 'width': 341.0},\n",
              "      'classifications': [{'schemaId': 'cldxj6zy80cw307vdgapmcu4e',\n",
              "        'answer': {'schemaId': 'cldxj6zy80cw407vd1ynfckwg'}}]}]}],\n",
              "  'dataRow': {'id': 'cldxj6yxi0a4o07yc8qkf0bvm'}}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 6: Upload annotations to a project as pre-labels or completed labels\n",
        "For the purpose of this tutorial only run one of the label imports at once, otherwise the previous import might get overwritten."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### Model-Assisted Labeling (MAL)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload MAL label for this data row in project\n",
        "upload_job_mal = lb.MALPredictionImport.create_from_objects(\n",
        "    client = client, \n",
        "    project_id = project.uid, \n",
        "    name=\"mal_import_job-\" + str(uuid.uuid4()), \n",
        "    predictions=label_ndjson)\n",
        "\n",
        "upload_job_mal.wait_until_done();\n",
        "print(\"Errors:\", upload_job_mal.errors)\n",
        "print(\"   \")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n",
            "   \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### Label Import"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_job_label_import = lb.LabelImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid, \n",
        "    name = \"label_import_job-\" + str(uuid.uuid4()),\n",
        "    labels=label_ndjson\n",
        ")\n",
        "\n",
        "upload_job_label_import.wait_until_done()\n",
        "print(\"Errors:\", upload_job_label_import.errors)\n",
        "print(\"   \")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n",
            "   \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Optional deletions for cleanup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Delete Project\n",
        "# project.delete()\n",
        "# dataset.delete()\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}