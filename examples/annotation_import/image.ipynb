{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/annotation_import/image.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/annotation_import/image.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Image Annotation Import\n",
        "This notebook will provide examples of each supported annotation type for image assets. \n",
        "\n",
        "### [Model-assisted labeling (MAL)](https://docs.labelbox.com/v4/docs/model-assisted-labeling)\n",
        "* This workflow allows you to import computer-generated predictions (or simply annotations created outside of Labelbox) as pre-labels on an asset. \n",
        "The imported annotations will be pre-populated in the labeling editor. However, in order to convert the pre-labels to real annotations, a human labeler will still need to open the Data Row in the Editor and submit it. This functionality is designed to speed up human labeling.\n",
        "\n",
        "\n",
        "### [Import ground truth](https://docs.labelbox.com/v4/docs/import-ground-truth)\n",
        "* This  workflow functionality allows you to bulk import your ground truth annotations from an external or third-party labeling system into Labelbox Annotate. Using the label import API to import external data is a useful way to consolidate and migrate all annotations into Labelbox as a single source of truth.\n",
        "\n",
        "\n",
        "### Python Annotation types vs NDJSON\n",
        "**Python Annotation Type (recommended)**\n",
        "- Provides a seamless transition between third-party platforms, machine learning pipelines, and Labelbox.\n",
        "\n",
        "- Allows you to build annotations locally with local file paths, numpy arrays, or URLs\n",
        "\n",
        "- Easily convert Python Annotation Type format to NDJSON format to quickly import annotations to Labelbox\n",
        "\n",
        "- It supports one-level nested classification (free text / radio / checklist) under the object or classification annotation.\n",
        "\n",
        "**NDJSON**\n",
        "- Skip formatting annotation payload in the Python Annotation Types format just to convert back to NDJSON\n",
        "\n",
        "- Ability to create the payload in the NDJSON import format directly\n",
        "\n",
        "- It supports any levels of nested classification (free text / radio / checklist) under the object or classification annotation."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Imports"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q 'labelbox[data]'"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import labelbox.data.annotation_types as lb_types\n",
        "import labelbox.data.serialization as lb_serializers\n",
        "import uuid\n",
        "import numpy as np\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Replace with your API KEY\n",
        "\n",
        "Guides on [Create an API key](https://docs.labelbox.com/docs/create-an-api-key)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "API_KEY = None\n",
        "client = lb.Client(API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Supported Annotations for Image\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Supported Annotation Types"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "########### Radio Classification ###########\n",
        "\n",
        "# Python annotation\n",
        "radio_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_question\", \n",
        "    value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"second_radio_answer\"))\n",
        ")\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "radio_annotation_ndjson = {\n",
        "  'name': 'radio_question',\n",
        "  'answer': {'name': 'second_radio_answer'}\n",
        "} "
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Nested Radio and Checklist Classification is only supported with NDJSON tools##########\n",
        "\n",
        "# NDJSON \n",
        "nested_radio_annotation_ndjson = {\n",
        "  \"name\": \"nested_radio_question\",\n",
        "  \"answer\": {\"name\": \"first_radio_answer\"},\n",
        "  \"classifications\" : [\n",
        "   {'name': 'sub_radio_question', 'answer': {'name': 'first_sub_radio_answer'}}\n",
        "   ]\n",
        "}\n",
        "\n",
        "\n",
        "nested_checklist_annotation_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\", \n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\", \n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\"}\n",
        "        }          \n",
        "      ]         \n",
        "  }]\n",
        "}\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "############ Checklist question ############\n",
        "\n",
        "# Python Annotations\n",
        "# Python Annotations\n",
        "checklist_annotation= lb_types.ClassificationAnnotation(\n",
        "  name=\"checklist_question\", # must match your ontology feature's name\n",
        "  value=lb_types.Checklist(\n",
        "      answer = [\n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"first_checklist_answer\"\n",
        "        ), \n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"second_checklist_answer\"\n",
        "        )\n",
        "      ]\n",
        "    )\n",
        " )\n",
        "\n",
        "# NDJSON\n",
        "checklist_annotation_ndjson = {\n",
        "  'name': 'checklist_question',\n",
        "  'answer': [\n",
        "    {'name': 'first_checklist_answer'},\n",
        "    {'name': 'second_checklist_answer'}\n",
        "  ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "############# Free text Classification #############\n",
        "\n",
        "# Python annotation\n",
        "text_annotation = lb_types.ClassificationAnnotation(\n",
        "  name=\"free_text\",  # must match your ontology feature's name\n",
        "  value=lb_types.Text(answer=\"sample text\")\n",
        ")\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "text_annotation_ndjson = {\n",
        "  'name': 'free_text',\n",
        "  'answer': 'sample text',\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "####### Bounding box #######\n",
        "\n",
        "\n",
        "# Python Annotation \n",
        "bbox_annotation = lb_types.ObjectAnnotation(\n",
        "  name = \"bounding_box\",  # must match your ontology feature's name\n",
        "  value = lb_types.Rectangle(\n",
        "        start=lb_types.Point(x=977, y=1690), # Top left\n",
        "        end=lb_types.Point(x=330, y=225), # Bottom right\n",
        "    ),\n",
        ")\n",
        "\n",
        "#NDJSON \n",
        "bbox_annotation_ndjson = {\n",
        "  'name': 'bounding_box',\n",
        "  'bbox': {\n",
        "          \"top\": 977,\n",
        "          \"left\": 1690,\n",
        "          \"height\": 330,\n",
        "          \"width\": 225\n",
        "      }\n",
        "}\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Bounding box with nested classification\n",
        "bbox_with_radio_subclass_annotation = lb_types.ObjectAnnotation(\n",
        "    name=\"bbox_with_radio_subclass\",\n",
        "    confidence=0.5, # must match your ontology feature's name\n",
        "    value=lb_types.Rectangle(\n",
        "        start=lb_types.Point(x=933, y=541), # Top left\n",
        "        end=lb_types.Point(x=191, y=330), # Bottom right\n",
        "    ),\n",
        "    classifications=[\n",
        "    \tlb_types.ClassificationAnnotation(\n",
        "        \tname=\"sub_radio_question\",\n",
        "      \t\tvalue=lb_types.Radio(answer=lb_types.ClassificationAnswer(name=\"first_sub_radio_answer\", confidence=0.5))\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "## NDJSON\n",
        "bbox_with_radio_subclass_ndjson = {\n",
        "    \"name\": \"bbox_with_radio_subclass\", \n",
        "    \"classifications\": [{\n",
        "        \"name\": \"sub_radio_question\",\n",
        "        \"answer\": \n",
        "            { \"name\":\"first_sub_radio_answer\" }\n",
        "         \n",
        "    }],\n",
        "    \"bbox\": {\n",
        "          \"top\": 933,\n",
        "          \"left\": 541,\n",
        "          \"height\": 191,\n",
        "          \"width\": 330\n",
        "        }\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Polygon ##########\n",
        "# Python AnotationTypes \n",
        "polygon_annotation = lb_types.ObjectAnnotation(\n",
        "  name = \"polygon\",  # must match your ontology feature's name \n",
        "  confidence = 0.5, \n",
        "  value=lb_types.Polygon( # Coordinates for the verticies of your polygon\n",
        "        points=[lb_types.Point(x=1489.581,y=183.934), lb_types.Point(x=2278.306,y=256.885), lb_types.Point(x=2428.197,y=200.437), lb_types.Point(x=2560.0,y=335.419),\n",
        "                lb_types.Point(x=2557.386,y=503.165), lb_types.Point(x=2320.596,y=503.103), lb_types.Point(x=2156.083, y=628.943), lb_types.Point(x=2161.111,y=785.519),\n",
        "                lb_types.Point(x=2002.115, y=894.647), lb_types.Point(x=1838.456,y=877.874), lb_types.Point(x=1436.53,y=874.636), lb_types.Point(x=1411.403,y=758.579),\n",
        "                lb_types.Point(x=1353.853,y=751.74), lb_types.Point(x=1345.264, y=453.461), lb_types.Point(x=1426.011,y=421.129)]\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "\n",
        "polygon_annotation_ndjson = {\n",
        "  'name': 'polygon',\n",
        "  'polygon': [\n",
        "    {'x': 1489.581, 'y': 183.934},\n",
        "    {'x': 2278.306, 'y': 256.885},\n",
        "    {'x': 2428.197, 'y': 200.437},\n",
        "    {'x': 2560.0, 'y': 335.419},\n",
        "    {'x': 2557.386, 'y': 503.165},\n",
        "    {'x': 2320.596, 'y': 503.103},\n",
        "    {'x': 2156.083, 'y': 628.943},\n",
        "    {'x': 2161.111, 'y': 785.519},\n",
        "    {'x': 2002.115, 'y': 894.647},\n",
        "    {'x': 1838.456, 'y': 877.874},\n",
        "    {'x': 1436.53, 'y': 874.636},\n",
        "    {'x': 1411.403, 'y': 758.579},\n",
        "    {'x': 1353.853, 'y': 751.74},\n",
        "    {'x': 1345.264, 'y': 453.461},\n",
        "    {'x': 1426.011, 'y': 421.129},\n",
        "    {'x': 1489.581, 'y': 183.934}\n",
        "  ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######### Mask #########\n",
        "\n",
        "\n",
        "# Python \n",
        "# Identifying what values in the numpy array correspond to the mask annotation\n",
        "color = (0, 0, 0)\n",
        "\n",
        "# convert a polygon to mask\n",
        "im_height, im_width = 100,100 #need to provide the height and width of image.\n",
        "mask_data = lb_types.MaskData(arr=\n",
        "                     polygon_annotation.value.draw(height=im_height,width=im_width,color=color))\n",
        "\n",
        "# convert a 2D array to 3D array\n",
        "arr_2d = np.zeros((100,100), dtype='uint8')\n",
        "mask_data = lb_types.MaskData.from_2D_arr(arr_2d)\n",
        "\n",
        "# a 3D array where 3rd axis is RGB values.\n",
        "mask_data = lb_types.MaskData(arr= np.zeros([400,450,3],dtype='uint8'))\n",
        "\n",
        "mask_annotation = lb_types.ObjectAnnotation(\n",
        "  name = \"mask\", # must match your ontology feature's name\n",
        "  value=lb_types.Mask(mask=mask_data, color=color),\n",
        ")\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "mask_annotation_ndjson = {\n",
        "  'name': 'mask',\n",
        "  'classifications': [],\n",
        "  'mask': {'instanceURI': 'https://storage.labelbox.com/cjhfn5y6s0pk507024nz1ocys%2F1d60856c-59b7-3060-2754-83f7e93e0d01-1?Expires=1666901963361&KeyName=labelbox-assets-key-3&Signature=t-2s2DB4YjFuWEFak0wxYqfBfZA',\n",
        "  'colorRGB': (0, 0, 0)}\n",
        "}\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Point Annotation ########\n",
        "\n",
        "# Python Annotation\n",
        "point_annotation = lb_types.ObjectAnnotation(\n",
        "  name = \"point\",  # must match your ontology feature's name\n",
        "  confidence=0.5,\n",
        "  value = lb_types.Point(x=1166.606, y=1441.768),\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "point_annotation_ndjson = {\n",
        "  'name': 'point',\n",
        "  'classifications': [],\n",
        "  'point': {'x': 1166.606, 'y': 1441.768}\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "###### Polygon ######\n",
        "\n",
        "\n",
        "# Python Annotation \n",
        "\n",
        "polyline_annotation = lb_types.ObjectAnnotation(\n",
        "  name = \"polyline\", # must match your ontology feature's name\n",
        "  value=lb_types.Line( # Coordinates for the keypoints in your polyline\n",
        "        points=[lb_types.Point(x=2534.353, y=249.471), lb_types.Point(x=2429.492, y=182.092), lb_types.Point(x=2294.322, y=221.962), lb_types.Point(x=2224.491, y=180.463), lb_types.Point(x=2136.123, y=204.716),\n",
        "                lb_types.Point(x=1712.247, y=173.949), lb_types.Point(x=1703.838, y=84.438), lb_types.Point(x=1579.772, y=82.61), lb_types.Point(x=1583.442, y=167.552),\n",
        "                lb_types.Point(x=1478.869, y=164.903), lb_types.Point(x=1418.941, y=318.149), lb_types.Point(x=1243.128, y=400.815), lb_types.Point(x=1022.067, y=319.007),\n",
        "                lb_types.Point(x=892.367, y=379.216), lb_types.Point(x=670.273, y=364.408), lb_types.Point(x=613.114, y=288.16), lb_types.Point(x=377.559, y=238.251),\n",
        "                lb_types.Point(x=368.087, y=185.064), lb_types.Point(x=246.557, y=167.286), lb_types.Point(x=236.648, y=285.61), lb_types.Point(x=90.929, y=326.412)]\n",
        "    ),\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "polyline_annotation_ndjson = {\n",
        "  'name': 'polyline',\n",
        "  'classifications': [],\n",
        "  'line': [\n",
        "    {'x': 2534.353, 'y': 249.471},\n",
        "    {'x': 2429.492, 'y': 182.092},\n",
        "    {'x': 2294.322, 'y': 221.962},\n",
        "    {'x': 2224.491, 'y': 180.463},\n",
        "    {'x': 2136.123, 'y': 204.716},\n",
        "    {'x': 1712.247, 'y': 173.949},\n",
        "    {'x': 1703.838, 'y': 84.438},\n",
        "    {'x': 1579.772, 'y': 82.61},\n",
        "    {'x': 1583.442, 'y': 167.552},\n",
        "    {'x': 1478.869, 'y': 164.903},\n",
        "    {'x': 1418.941, 'y': 318.149},\n",
        "    {'x': 1243.128, 'y': 400.815},\n",
        "    {'x': 1022.067, 'y': 319.007},\n",
        "    {'x': 892.367, 'y': 379.216},\n",
        "    {'x': 670.273, 'y': 364.408},\n",
        "    {'x': 613.114, 'y': 288.16},\n",
        "    {'x': 377.559, 'y': 238.251},\n",
        "    {'x': 368.087, 'y': 185.064},\n",
        "    {'x': 246.557, 'y': 167.286},\n",
        "    {'x': 236.648, 'y': 285.61},\n",
        "    {'x': 90.929, 'y': 326.412}\n",
        "  ]\n",
        "}\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Upload Annotations - putting it all together\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Import data rows into Catalog\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# send a sample image as batch to the project\n",
        "\n",
        "\n",
        "test_img_url = {\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/2560px-Kitano_Street_Kobe01s5s4110.jpeg\",\n",
        "    \"global_key\": str(uuid.uuid4())\n",
        "}\n",
        "  \n",
        "\n",
        "dataset = client.create_dataset(name=\"demo_dataset_img\")\n",
        "data_row = dataset.create_data_row(test_img_url)\n",
        "print(data_row)\n",
        "\n",
        "len(test_img_url)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<DataRow {\n",
            "    \"created_at\": \"2023-02-09 19:41:53+00:00\",\n",
            "    \"external_id\": null,\n",
            "    \"global_key\": \"64623226-cd97-4835-81c5-a6dbcd3aacba\",\n",
            "    \"media_attributes\": {},\n",
            "    \"metadata\": [],\n",
            "    \"metadata_fields\": [],\n",
            "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/2560px-Kitano_Street_Kobe01s5s4110.jpeg\",\n",
            "    \"uid\": \"cldxiaaqw08mb07y3dz6t63hy\",\n",
            "    \"updated_at\": \"2023-02-09 19:41:53+00:00\"\n",
            "}>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Create/select an Ontology\n",
        "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the `name`/`instructions` fields in your annotations to ensure the correct feature schemas are matched.\n",
        "\n",
        "For example, when we create the bounding box annotation above, we provided the `name` as `polyline`. Now, when we setup our ontology, we must ensure that the name of my bounding box tool is also `polyline`. The same alignment must hold true for the other tools and classifications we create in our ontology.\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "ontology_builder = lb.OntologyBuilder(\n",
        "  classifications=[ # List of Classification objects\n",
        "    lb.Classification( # Radio classification given the name \"text\" with two options: \"first_radio_answer\" and \"second_radio_answer\"\n",
        "      class_type=lb.Classification.Type.RADIO,\n",
        "      name=\"radio_question\", \n",
        "      options=[\n",
        "        lb.Option(value=\"first_radio_answer\"),\n",
        "        lb.Option(value=\"second_radio_answer\")\n",
        "      ]\n",
        "    ),\n",
        "    lb.Classification( # Checklist classification given the name \"text\" with two options: \"first_checklist_answer\" and \"second_checklist_answer\"\n",
        "      class_type=lb.Classification.Type.CHECKLIST,\n",
        "      name=\"checklist_question\", \n",
        "      options=[\n",
        "        lb.Option(value=\"first_checklist_answer\"),\n",
        "        lb.Option(value=\"second_checklist_answer\")\n",
        "      ]\n",
        "    ), \n",
        "    lb.Classification( # Text classification given the name \"text\"\n",
        "      class_type=lb.Classification.Type.TEXT,\n",
        "      name=\"free_text\"\n",
        "    ),\n",
        "    lb.Classification(\n",
        "        class_type=lb.Classification.Type.RADIO,\n",
        "        name=\"nested_radio_question\",\n",
        "        options=[\n",
        "            lb.Option(\"first_radio_answer\",\n",
        "                options=[\n",
        "                    lb.Classification(\n",
        "                        class_type=lb.Classification.Type.RADIO,\n",
        "                        name=\"sub_radio_question\",\n",
        "                        options=[lb.Option(\"first_sub_radio_answer\")]\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "          ] \n",
        "        ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.CHECKLIST,\n",
        "      name=\"nested_checklist_question\",\n",
        "      options=[\n",
        "          lb.Option(\"first_checklist_answer\",\n",
        "            options=[\n",
        "              lb.Classification(\n",
        "                  class_type=lb.Classification.Type.CHECKLIST,\n",
        "                  name=\"sub_checklist_question\", \n",
        "                  options=[lb.Option(\"first_sub_checklist_answer\")]\n",
        "              )\n",
        "          ]\n",
        "        )\n",
        "      ]\n",
        "    ),      \n",
        "  ],\n",
        "  tools=[ # List of Tool objects\n",
        "    lb.Tool( # Bounding Box tool given the name \"box\"\n",
        "      tool=lb.Tool.Type.BBOX,\n",
        "      name=\"bounding_box\"), \n",
        "    lb.Tool( # Bounding Box tool given the name \"box\"\n",
        "      tool=lb.Tool.Type.BBOX,\n",
        "      name=\"bbox_with_radio_subclass\",\n",
        "      classifications=[\n",
        "            lb.Classification(\n",
        "                class_type=lb.Classification.Type.RADIO,\n",
        "                name=\"sub_radio_question\",\n",
        "                options=[\n",
        "                  lb.Option(value=\"first_sub_radio_answer\")\n",
        "                ]\n",
        "              ),\n",
        "        ]\n",
        "      ), \n",
        "    lb.Tool( # Polygon tool given the name \"polygon\"\n",
        "      tool=lb.Tool.Type.POLYGON,\n",
        "      name=\"polygon\"),\n",
        "    lb.Tool( # Segmentation mask tool given the name \"mask\"\n",
        "      tool=lb.Tool.Type.SEGMENTATION,\n",
        "      name=\"mask\"),\n",
        " \t  lb.Tool( # Point tool given the name \"point\"\n",
        "      tool=lb.Tool.Type.POINT,\n",
        "      name=\"point\"), \n",
        "    lb.Tool( # Polyline tool given the name \"line\"\n",
        "      tool=lb.Tool.Type.LINE,\n",
        "      name=\"polyline\")]\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Image Prediction Import Demo\", ontology_builder.asdict(), media_type=lb.MediaType.Image)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Create a labeling project\n",
        "\n",
        "Connect the ontology to the labeling project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "\n",
        "# create a project and configure the ontology \n",
        "project = client.create_project(\n",
        "    name=\"annotations_import_project_demo\",\n",
        "    media_type=lb.MediaType.Image,\n",
        "    queue_mode=lb.QueueMode.Batch)\n",
        "\n",
        "project.setup_editor(ontology) # Connect your ontology and editor to your MAL project"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Send a batch of data rows to the project\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "batch = project.create_batch(\n",
        "    \"Initial batch2\", # name of the batch\n",
        "    dataset.export_data_rows(), # list of Data Rows\n",
        "  1 # priority between 1-5\n",
        ")\n",
        "print(\"Batch\", batch)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch <Batch {\n",
            "    \"consensus_settings_json\": \"{\\\"numberOfLabels\\\":1,\\\"coveragePercentage\\\":0}\",\n",
            "    \"created_at\": \"2023-02-09 19:41:59+00:00\",\n",
            "    \"name\": \"Initial batch2\",\n",
            "    \"size\": 1,\n",
            "    \"uid\": \"d1ab84f0-a8b1-11ed-8c77-5348ca1cf2e8\",\n",
            "    \"updated_at\": \"2023-02-09 19:41:59+00:00\"\n",
            "}>\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 5: Create the annotations payload\n",
        "\n",
        "Create the annotations payload using the snippets of code above\n",
        "\n",
        "Labelbox support two formats for the annotations payload: NDJSON and Python Annotation types. Both are described below. If you are using Python Annotation types, compose your annotations into Labels attached to the data rows."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Python Annotations\n",
        "\n",
        "Here we create the complete label ndjson payload of annotations only using python annotation format. There is one annotation for each reference to an annotation that we created."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# create a Label\n",
        "\n",
        "label = []\n",
        "for data_row in dataset.export_data_rows():\n",
        "  label.append(lb_types.Label(\n",
        "      data=lb_types.ImageData(\n",
        "          uid=data_row.uid),\n",
        "      annotations = [\n",
        "          checklist_annotation, \n",
        "          text_annotation,\n",
        "          bbox_annotation, \n",
        "          bbox_with_radio_subclass_annotation, \n",
        "          polygon_annotation, \n",
        "          mask_annotation, \n",
        "          point_annotation, \n",
        "          polyline_annotation\n",
        "      ]\n",
        "  )\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### NDJSON annotations\n",
        "Here we create the complete label ndjson payload of annotations only using NDJSON format. There is one annotation for each reference to an annotation that we created above."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "label_ndjson_method2 = []\n",
        "for annotation in [radio_annotation_ndjson, \n",
        "              checklist_annotation_ndjson, \n",
        "              text_annotation_ndjson,\n",
        "              bbox_annotation_ndjson, \n",
        "              bbox_with_radio_subclass_ndjson, \n",
        "              polygon_annotation_ndjson, \n",
        "              mask_annotation_ndjson, \n",
        "              point_annotation_ndjson, \n",
        "              polyline_annotation_ndjson,\n",
        "              nested_radio_annotation_ndjson,\n",
        "              nested_checklist_annotation_ndjson \n",
        "\n",
        "              ]:\n",
        "  annotation.update({\n",
        "      'uuid': str(uuid.uuid4()),\n",
        "      'dataRow': {'id': data_row.uid},\n",
        "  })\n",
        "  label_ndjson_method2.append(annotation)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 6: Upload annotations to a project as pre-labels or complete labels"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Model-Assisted Labeling\n",
        "For the purpose of this tutorial only run one of the label_ndjosn  annotation type tools at the time (NDJSON or Annotation types). Delete the previous labels before uploading labels that use the 2nd method (ndjson)\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload MAL label for this data row in project\n",
        "upload_job = lb.MALPredictionImport.create_from_objects(\n",
        "    client = client, \n",
        "    project_id = project.uid, \n",
        "    name=\"mal_job\"+str(uuid.uuid4()), \n",
        "    predictions=label_ndjson_method2)\n",
        "\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\" \")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n",
            " \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Label Import\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload label for this data row in project\n",
        "upload_job = lb.LabelImport.create_from_objects(\n",
        "    client = client, \n",
        "    project_id = project.uid, \n",
        "    name=\"label_import_job\"+str(uuid.uuid4()),  \n",
        "    labels=label_ndjson_method2)\n",
        "\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\" \")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: []\n",
            " \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# project.delete()\n",
        "# dataset.delete()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}