{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {},
    "cells": [
        {
            "cell_type": "markdown",
            "id": "db768cda",
            "metadata": {},
            "source": [
                "<td>",
                "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>",
                "</td>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb5611d0",
            "metadata": {},
            "source": [
                "<td>\n",
                "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/exports/export_data.ipynb\" target=\"_blank\"><img",
                "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>",
                "</td>\n",
                "\n",
                "<td>\n",
                "<a href=\"https://github.com/Labelbox/labelbox-python/tree/develop/examples/exports/export_data.ipynb\" target=\"_blank\"><img",
                "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
                "</td>"
            ]
        },
        {
            "metadata": {},
            "source": [
                "# Export data\n",
                "How to export data for projects, datasets, slices, data rows and models, with examples for each type of v2 export along with details on optional parameters and filters.\n",
                "\n",
                "***Beginning with SDK version 3.68, the `export_v2()` method has been enhanced to incorporate streamable functionality.***"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "%pip install -q \"labelbox[data]\"\n%pip install -q urllib3",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "import labelbox as lb\nimport urllib.request\nfrom PIL import Image\nimport time",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "# API Key and Client\n",
                "See the developer guide for [creating an API key](https://docs.labelbox.com/reference/create-api-key)."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "API_KEY = \"\"\nclient = lb.Client(api_key=API_KEY)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Export data rows from a project\n",
                "For complete details on the supported filters and parameters, including how they are used and what information is included, please see the [Export overview](https://docs.labelbox.com/reference/label-export#optional-parameters-and-filters) developer guide.\n",
                "\n",
                "### Parameters\n",
                "When you export data rows from a project, you may choose to include or exclude certain attributes, including:\n",
                "- `attachments`\n",
                "- `metadata_fields`\n",
                "- `data_row_details`\n",
                "- `project_details`\n",
                "- `label_details`\n",
                "- `performance_details`\n",
                "- `interpolated_frames`\n",
                "    - Only applicable for video data rows.\n",
                "\n",
                "### Filters\n",
                "When you export data rows from a project, you can specify the included data rows with the following filters:\n",
                "- `last_activity_at`\n",
                "- `label_created_at`\n",
                "- `data_row_ids`\n",
                "- `global_keys`\n",
                "- `batch_ids`\n",
                "- `workflow_status`\n",
                "\n",
                "#### Filter details\n",
                "You can set the range for `last_activity_at` and `label_created_at` in the following formats: \n",
                "- `YYYY-MM-DD`\n",
                "- `YYYY-MM-DD hh:mm:ss`\n",
                "- `YYYY-MM-DDThh:mm:ss\u00b1hhmm` (ISO 8601)\n",
                "\n",
                "The ISO 8061 format allows you to specify the timezone, while the other two formats assume timezone from the user's workspace settings.\n",
                "\n",
                "The `last_activity_at` filter captures the creation and modification of labels, metadata, workflow status, comments, and reviews.\n",
                "\n",
                "If you wish to specify data rows to export, uncomment the `data_row_ids` or `global_keys` filter and provide a list of applicable IDs. The data rows must be part of a batch attached to the project in question. You can provide up to 2,000 data row IDs.\n",
                "\n",
                "The `batch_ids` filter allows you to specify data rows for export based on their associated batch ID. This is particularly useful when `data_row_ids` is not sufficient due to 2,000 data row IDs limit. \n",
                "\n",
                "\n",
                "The `workflow_status` filter allows you to specify data rows in a given work flow step. This filter only accepts one value. For example, `filters = {\"workflow_status\": \"InReview\"}`. The filer accepts the following:\n",
                "- `ToLabel`\n",
                "- `InReview`\n",
                "- `InRework`\n",
                "- `Done`\n"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Insert the project ID of the project from which you wish to export data rows.\nPROJECT_ID = \"\"\nproject = client.get_project(PROJECT_ID)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Export V2 Method\n"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n}\n\n# Note: Filters follow AND logic, so typically using one filter is sufficient.\nfilters = {\n    \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"global_keys\": [\"<global_key>\", \"<global_key>\"],\n    # \"data_row_ids\": [\"<data_row_id>\", \"<data_row_id>\"],\n    # \"batch_ids\": [\"<batch_id>\", \"<batch_id>\"],\n    # \"workflow_status\": \"<workflow_status>\"\n}\n\nexport_task = project.export_v2(params=export_params, filters=filters)\nexport_task.wait_till_done()\n\nif export_task.errors:\n    print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Stream Task Export Method\n",
                "The return type of this method is an ExportTask, instead of a Task. This is just a wrapper around Task, and most of its features are also present in ExportTask.\n",
                "This allows streaming of task results and errors."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n}\n\n# Note: Filters follow AND logic, so typically using one filter is sufficient.\nfilters = {\n    \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"global_keys\": [\"<global_key>\", \"<global_key>\"],\n    # \"data_row_ids\": [\"<data_row_id>\", \"<data_row_id>\"],\n    # \"batch_ids\": [\"<batch_id>\", \"<batch_id>\"],\n    # \"workflow_status\": \"<workflow_status>\"\n}\n\nclient.enable_experimental = True\n\nexport_task = project.export(params=export_params, filters=filters)\nexport_task.wait_till_done()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# Provide results with JSON converter\n# Returns streamed JSON output strings from export task results/errors, one by one\n\n\n# Callback used for JSON Converter\ndef json_stream_handler(output: lb.JsonConverterOutput):\n    print(output.json_str)\n\n\nif export_task.has_errors():\n    export_task.get_stream(converter=lb.JsonConverter(),\n                           stream_type=lb.StreamType.ERRORS).start(\n                               stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    export_json = export_task.get_stream(\n        converter=lb.JsonConverter(), stream_type=lb.StreamType.RESULT).start(\n            stream_handler=json_stream_handler)\n\nprint(\n    \"file size: \",\n    export_task.get_total_file_size(stream_type=lb.StreamType.RESULT),\n)\nprint(\n    \"line count: \",\n    export_task.get_total_lines(stream_type=lb.StreamType.RESULT),\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# Uncomment to get stream results as a written file\n\n# Provide results with file converter\n\n# if export_task.has_errors():\n#     export_task.get_stream(\n#         converter=lb.FileConverter(file_path=\"./errors.txt\"),\n#         stream_type=lb.StreamType.ERRORS\n#     ).start()\n\n# if export_task.has_result():\n#     export_task.get_stream(\n#         converter=lb.FileConverter(file_path=\"./result.txt\"),\n#         stream_type=lb.StreamType.RESULT\n#     ).start()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Export data rows from a dataset\n",
                "For complete details on the supported filters and parameters, including how they are used and what information is included, please see the [Export overview](https://docs.labelbox.com/reference/label-export#optional-parameters-and-filters) developer guide.\n",
                "\n",
                "### Parameters\n",
                "When you export data rows from a dataset, you may choose to include or exclude certain attributes, including:\n",
                "- `attachments`\n",
                "- `metadata_fields`\n",
                "- `data_row_details`\n",
                "- `project_details`\n",
                "- `label_details`\n",
                "- `performance_details`\n",
                "- `interpolated_frames`\n",
                "    - Only applicable for video data rows.\n",
                "- `project_ids`\n",
                "    - Accepts a list of project IDs. If provided, the labels created _in these projects_ on the exported data rows will be included. \n",
                "- `model_run_ids`\n",
                "    - Accepts a list of model run IDs. If provided, the labels and predicitions created _in these model runs_ will be included. \n",
                "\n",
                "### Filters\n",
                "When you export data rows from a dataset, you can specify the included data rows with the following filters:\n",
                "- `last_activity_at`\n",
                "- `label_created_at`\n",
                "- `data_row_ids`\n",
                "- `global_keys`\n",
                "\n",
                "See the _Export data rows from a project_ section above for additional details on each filter. "
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Insert the dataset ID of the dataset from which you wish to export data rows.\nDATASET_ID = \"\"\ndataset = client.get_dataset(DATASET_ID)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Export V2 Method"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n    # \"project_ids\": [\"<project_id>\", \"<project_id>\"],\n    # \"model_run_ids\": [\"<model_run_id>\", \"<model_run_id>\"]\n}\n\n# Note: Filters follow AND logic, so typically using one filter is sufficient.\nfilters = {\n    \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"global_keys\": [\"<global_key>\", \"<global_key>\"],\n    # \"data_row_ids\": [\"<data_row_id>\", \"<data_row_id>\"],\n}\n\nexport_task = dataset.export_v2(params=export_params, filters=filters)\nexport_task.wait_till_done()\n\nif export_task.errors:\n    print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Stream Task Export Method\n",
                "The return type of this method is an ExportTask, instead of a Task. This is just a wrapper around Task, and most of its features are also present in ExportTask.\n",
                "This allows streaming of task results and errors."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n    # \"project_ids\": [\"<project_id>\", \"<project_id>\"],\n    # \"model_run_ids\": [\"<model_run_id>\", \"<model_run_id>\"]\n}\n\n# Note: Filters follow AND logic, so typically using one filter is sufficient.\nfilters = {\n    \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"global_keys\": [\"<global_key>\", \"<global_key>\"],\n    # \"data_row_ids\": [\"<data_row_id>\", \"<data_row_id>\"],\n}\n\nclient.enable_experimental = True\n\nexport_task = dataset.export(params=export_params, filters=filters)\nexport_task.wait_till_done()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# Provide results with JSON converter\n# Returns streamed JSON output strings from export task results/errors, one by one\n\n\n# Callback used for JSON Converter\ndef json_stream_handler(output: lb.JsonConverterOutput):\n    print(output.json_str)\n\n\nif export_task.has_errors():\n    export_task.get_stream(converter=lb.JsonConverter(),\n                           stream_type=lb.StreamType.ERRORS).start(\n                               stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    export_json = export_task.get_stream(\n        converter=lb.JsonConverter(), stream_type=lb.StreamType.RESULT).start(\n            stream_handler=json_stream_handler)\n\nprint(\n    \"file size: \",\n    export_task.get_total_file_size(stream_type=lb.StreamType.RESULT),\n)\nprint(\n    \"line count: \",\n    export_task.get_total_lines(stream_type=lb.StreamType.RESULT),\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Export data rows from Catalog\n",
                "`get_catalog()` method allows you to fetch all your data from catalog\n",
                "\n",
                "### Parameters\n",
                "When exporting from catalog, you can apply the same parameters as exporting from a project.\n",
                "\n",
                "### Filters\n",
                "When exporting from catalog, you can apply the same filters as exporting from a dataset.\n"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "catalog = client.get_catalog()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "export_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n    # \"project_ids\": [\"<project_id_1>\",\"<project_id_2>\"],\n    # \"model_run_ids\": [\"<model_run_id>\", \"<model_run_id>\"]\n}\n\nfilters = {\n    \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"global_keys\": [\"<global_key>\", \"<global_key>\"],\n    # \"data_row_ids\": [\"<data_row_id>\", \"<data_row_id>\"]\n}\nexport_task = catalog.export_v2(params=export_params, filters=filters)\nexport_task.wait_till_done()\n\nif export_task.errors:\n    print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Stream Task Export Method\n",
                "The return type of this method is an ExportTask, instead of a Task. This is just a wrapper around Task, and most of its features are also present in ExportTask.\n",
                "This allows streaming of task results and errors."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "export_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n    # \"project_ids\": [\"<project_id_1>\",\"<project_id_2>\"],\n    # \"model_run_ids\": [\"<model_run_id>\", \"<model_run_id>\"]\n}\n\nfilters = {\n    \"last_activity_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"label_created_at\": [\"2000-01-01 00:00:00\", \"2050-01-01 00:00:00\"],\n    # \"global_keys\": [\"<global_key>\", \"<global_key>\"],\n    # \"data_row_ids\": [\"<data_row_id>\", \"<data_row_id>\"]\n}\n\nclient.enable_experimental = True\nexport_task = catalog.export(params=export_params)\nexport_task.wait_till_done()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "def json_stream_handler(output: lb.JsonConverterOutput):\n    print(output.json_str)\n\n\nif export_task.has_errors():\n    export_task.get_stream(converter=lb.JsonConverter(),\n                           stream_type=lb.StreamType.ERRORS).start(\n                               stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    export_json = export_task.get_stream(\n        converter=lb.JsonConverter(), stream_type=lb.StreamType.RESULT).start(\n            stream_handler=json_stream_handler)\n\nprint(\n    \"file size: \",\n    export_task.get_total_file_size(stream_type=lb.StreamType.RESULT),\n)\nprint(\n    \"line count: \",\n    export_task.get_total_lines(stream_type=lb.StreamType.RESULT),\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Export data rows from a slice\n",
                "For complete details on the supported filters and parameters, including how they are used and what information is included, please see the [Export overview](https://docs.labelbox.com/reference/label-export#optional-parameters-and-filters) developer guide.\n",
                "\n",
                "### Parameters\n",
                "When exporting from a slice, you can apply the same parameters as exporting from a dataset.\n",
                "\n",
                "### Filters\n",
                "No filters are applicable to exports from a slice. All the data rows of the slice must be exported."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Insert the Catalog slice ID of the slice from which you wish to export data rows.\nCATALOG_SLICE_ID = \"\"\ncatalog_slice = client.get_catalog_slice(CATALOG_SLICE_ID)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Export V2 Method"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n    # \"project_ids\": [\"<project_id>\", \"<project_id>\"],\n    # \"model_run_ids\": [\"<model_run_id>\", \"<model_run_id>\"]\n}\n\nexport_task = catalog_slice.export_v2(params=export_params)\nexport_task.wait_till_done()\n\nif export_task.errors:\n    print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Stream Task Export Method\n",
                "The return type of this method is an ExportTask, instead of a Task. This is just a wrapper around Task, and most of its features are also present in ExportTask.\n",
                "This allows streaming of task results and errors."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n    # \"project_ids\": [\"<project_id>\", \"<project_id>\"],\n    # \"model_run_ids\": [\"<model_run_id>\", \"<model_run_id>\"]\n}\n\nclient.enable_experimental = True\n\nexport_task = catalog_slice.export(params=export_params)\nexport_task.wait_till_done()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# Provide results with JSON converter\n# Returns streamed JSON output strings from export task results/errors, one by one\n\n\n# Callback used for JSON Converter\ndef json_stream_handler(output: lb.JsonConverterOutput):\n    print(output.json_str)\n\n\nif export_task.has_errors():\n    export_task.get_stream(converter=lb.JsonConverter(),\n                           stream_type=lb.StreamType.ERRORS).start(\n                               stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    export_json = export_task.get_stream(\n        converter=lb.JsonConverter(), stream_type=lb.StreamType.RESULT).start(\n            stream_handler=json_stream_handler)\n\nprint(\n    \"file size: \",\n    export_task.get_total_file_size(stream_type=lb.StreamType.RESULT),\n)\nprint(\n    \"line count: \",\n    export_task.get_total_lines(stream_type=lb.StreamType.RESULT),\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Export data rows from a model run\n",
                "For complete details on the supported filters and parameters, including how they are used and what information is included, please see the [Export overview](https://docs.labelbox.com/reference/label-export#optional-parameters-and-filters) developer guide.\n",
                "\n",
                "### Parameters\n",
                "- `attachments`\n",
                "- `metadata_fields`\n",
                "- `data_row_details`\n",
                "- `interpolated_frames`\n",
                "    - Only applicable for video data rows.\n",
                "- `predictions`\n",
                "    - If true, all predictions made in the model run will be included for each data row in the export.\n",
                "\n",
                "### Filters\n",
                "No filters are applicable to exports from a model run. All the data rows of the model run must be exported.\n"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Insert the model run ID of the model run from which you wish to export data rows.\nMODEL_RUN_ID = \"\"\nmodel_run = client.get_model_run(MODEL_RUN_ID)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Export V2 Method"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"interpolated_frames\": True,\n    \"predictions\": True,\n    \"embeddings\": True,\n}\n\nexport_task = model_run.export_v2(params=export_params)\nexport_task.wait_till_done()\n\nif export_task.errors:\n    print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Stream Task Export Method\n",
                "The return type of this method is an ExportTask, instead of a Task. This is just a wrapper around Task, and most of its features are also present in ExportTask.\n",
                "This allows streaming of task results and errors."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"interpolated_frames\": True,\n    \"predictions\": True,\n    \"embeddings\": True,\n}\n\nclient.enable_experimental = True\n\nexport_task = model_run.export(params=export_params)\nexport_task.wait_till_done()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# Provide results with JSON converter\n# Returns streamed JSON output strings from export task results/errors, one by one\n\n\n# Callback used for JSON Converter\ndef json_stream_handler(output: lb.JsonConverterOutput):\n    print(output.json_str)\n\n\nif export_task.has_errors():\n    export_task.get_stream(converter=lb.JsonConverter(),\n                           stream_type=lb.StreamType.ERRORS).start(\n                               stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    export_json = export_task.get_stream(\n        converter=lb.JsonConverter(), stream_type=lb.StreamType.RESULT).start(\n            stream_handler=json_stream_handler)\n\nprint(\n    \"file size: \",\n    export_task.get_total_file_size(stream_type=lb.StreamType.RESULT),\n)\nprint(\n    \"line count: \",\n    export_task.get_total_lines(stream_type=lb.StreamType.RESULT),\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "## Export Data Row\n",
                "For complete details on the supported filters and parameters, including how they are used and what information is included, please see the [Export overview](https://docs.labelbox.com/reference/label-export#optional-parameters-and-filters) developer guide.\n",
                "\n",
                "### Parameters\n",
                "When exporting data rows, you can apply the same parameters as exporting from a project.\n",
                "\n",
                "### Filters\n",
                "No filters are applicable to export data rows. All the data rows specified in the export task are included."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Insert the global key of the data row you wish to export\nDATA_ROW_GLOBAL_KEY = \"\"",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Export V2 Method"
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n}\n\n# Provide a list of data row global keys\nexport_task = lb.DataRow.export_v2(client=client,\n                                   global_keys=[DATA_ROW_GLOBAL_KEY],\n                                   params=export_params)\nexport_task.wait_till_done()\n\nif export_task.errors:\n    print(export_task.errors)\n\nexport_json = export_task.result\nprint(\"results: \", export_json)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": [
                "#### Stream Task Export Method\n",
                "The return type of this method is an ExportTask, instead of a Task. This is just a wrapper around Task, and most of its features are also present in ExportTask.\n",
                "This allows streaming of task results and errors."
            ],
            "cell_type": "markdown"
        },
        {
            "metadata": {},
            "source": "# Set the export params to include/exclude certain fields.\nexport_params = {\n    \"attachments\": True,\n    \"metadata_fields\": True,\n    \"data_row_details\": True,\n    \"project_details\": True,\n    \"label_details\": True,\n    \"performance_details\": True,\n    \"interpolated_frames\": True,\n    \"embeddings\": True,\n}\n\nclient.enable_experimental = True\n\n# Provide a list of data row global keys\nexport_task = lb.DataRow.export(client=client,\n                                global_keys=[DATA_ROW_GLOBAL_KEY],\n                                params=export_params)\nexport_task.wait_till_done()",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        },
        {
            "metadata": {},
            "source": "# Provide results with JSON converter\n# Returns streamed JSON output strings from export task results/errors, one by one\n\n\n# Callback used for JSON Converter\ndef json_stream_handler(output: lb.JsonConverterOutput):\n    print(output.json_str)\n\n\nif export_task.has_errors():\n    export_task.get_stream(converter=lb.JsonConverter(),\n                           stream_type=lb.StreamType.ERRORS).start(\n                               stream_handler=lambda error: print(error))\n\nif export_task.has_result():\n    export_json = export_task.get_stream(\n        converter=lb.JsonConverter(), stream_type=lb.StreamType.RESULT).start(\n            stream_handler=json_stream_handler)\n\nprint(\n    \"file size: \",\n    export_task.get_total_file_size(stream_type=lb.StreamType.RESULT),\n)\nprint(\n    \"line count: \",\n    export_task.get_total_lines(stream_type=lb.StreamType.RESULT),\n)",
            "cell_type": "code",
            "outputs": [],
            "execution_count": null
        }
    ]
}