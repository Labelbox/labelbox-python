{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/llm_import/conversational.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/llm_import/conversational.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# LLM pairwise comparison with Conversational text using MAL and Ground truth\n",
        "This demo is meant to showcase how to upload conversational row data that contains model outputs for pairwise comparisons analysis.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q \"labelbox[data]\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Setup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import uuid"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Replace with your API Key"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "API_KEY = \"\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Step 1: Create annotations"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a gobal radio and text annotation\n",
        "radio_annotation_ndjson = {\n",
        "    \"name\": \"Choose the best response\",\n",
        "    \"answer\": {\n",
        "      \"name\": \"Response B\"\n",
        "    }\n",
        "}\n",
        "\n",
        "text_annotation_ndjson = {\n",
        "    \"name\": \"Provide a reason for your choice\",\n",
        "    \"answer\": \"This is the more concise answer\",\n",
        "\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Step 2: Setup a project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Import data rows with \"modelOutputs\" into Catalog\n",
        "In addition to your message based data, you will need to add a list of model outputs to your JSON file:\n",
        "\n",
        "```\n",
        "\"modelOutputs\" : [\n",
        "  {\n",
        "      \"title\": \"Name of the response option\",\n",
        "      \"content\": \"Content of the response\",\n",
        "      \"modelConfigName\": \"Name of model configuration\"\n",
        "  }\n",
        "]\n",
        "```\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Example of row_data with model outputs"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "pairwise_shopping_2 =  \"\"\"\n",
        " {\n",
        "  \"type\": \"application/vnd.labelbox.conversational\",\n",
        "  \"version\": 1,\n",
        "  \"messages\": [\n",
        "    {\n",
        "      \"messageId\": \"message-0\",\n",
        "      \"timestampUsec\": 1530718491,\n",
        "      \"content\": \"Hi! How can I help?\",\n",
        "      \"user\": {\n",
        "        \"userId\": \"Bot 002\",\n",
        "        \"name\": \"Bot\"\n",
        "      },\n",
        "      \"align\": \"left\",\n",
        "      \"canLabel\": false\n",
        "    },\n",
        "    {\n",
        "      \"messageId\": \"message-1\",\n",
        "      \"timestampUsec\": 1530718503,\n",
        "      \"content\": \"I just bought a vacuum cleaner from you guys like a week ago and it's already broken!!\",\n",
        "      \"user\": {\n",
        "        \"userId\": \"User 00686\",\n",
        "        \"name\": \"User\"\n",
        "      },\n",
        "      \"align\": \"right\",\n",
        "      \"canLabel\": true\n",
        "    }\n",
        "\n",
        "  ],\n",
        "  \"modelOutputs\": [\n",
        "    {\n",
        "      \"title\": \"Response A\",\n",
        "      \"content\": \"I'm really sorry to hear that your vacuum cleaner is not working as expected. We certainly understand how frustrating this can be, especially with a recent purchase. I assure you, we're here to help!\\n\\n To proceed with resolving this issue, could you please provide some details about the problem you're experiencing with the vacuum cleaner? Additionally, if you could share your order number or receipt details, that would be very helpful. We will definitely look into the available options for you, which may include a replacement or a refund, depending on the specific circumstances and our return policy.\\n\\n Your satisfaction is our priority, and we'll do our best to resolve this matter promptly and to your satisfaction.\",\n",
        "      \"modelConfigName\": \"GPT-3.5 with temperature 0\"\n",
        "    },\n",
        "    {\n",
        "      \"title\": \"Response B\",\n",
        "      \"content\": \"I'm sorry about the issue with your vacuum cleaner. Please send us the order number or receipt details so we can quickly assist you with a replacement. Your satisfaction is important to us!\",\n",
        "      \"modelConfigName\": \"Fine Tuned GPT-3.5 with demo data\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "\n",
        "### Create dataset and data rows using a cloud hosted JSON file with \"modelOutputs\""
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Generate dummy global keys\n",
        "global_key_1 = str(uuid.uuid4())\n",
        "global_key_2 = str(uuid.uuid4())\n",
        "global_key_3 = str(uuid.uuid4())\n",
        "\n",
        "# Create a dataset\n",
        "dataset = client.create_dataset(\n",
        "    name=\"pairwise_demo_\"+str(uuid.uuid4()),\n",
        "    iam_integration=None\n",
        ")\n",
        "# Upload data rows\n",
        "task = dataset.create_data_rows([\n",
        "    {\n",
        "      \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/conversational-sample-data/pairwise_shopping_1.json\",\n",
        "      \"global_key\": global_key_1\n",
        "    },\n",
        "    {\n",
        "        \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/conversational-sample-data/pairwise_shopping_2.json\",\n",
        "        \"global_key\": global_key_2\n",
        "    },\n",
        "    {\n",
        "        \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/conversational-sample-data/pairwise_shopping_3.json\",\n",
        "        \"global_key\": global_key_3\n",
        "    }\n",
        "  ])\n",
        "task.wait_till_done()\n",
        "print(\"Errors:\",task.errors)\n",
        "print(\"Failed data rows:\", task.failed_data_rows)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Create/select an ontology"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create an ontology with relevant classifications\n",
        "\n",
        "ontology_builder = lb.OntologyBuilder(\n",
        "  classifications=[\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.RADIO,\n",
        "      scope=lb.Classification.Scope.GLOBAL,\n",
        "      name=\"Choose the best response\",\n",
        "      options=[lb.Option(value=\"Response A\"), lb.Option(value=\"Response B\"), lb.Option(value=\"Tie\")]\n",
        "    ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.TEXT,\n",
        "      name=\"Provide a reason for your choice\"\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Pairwise comparison ontology\", ontology_builder.asdict(), media_type=lb.MediaType.Conversational)\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Create a labeling project and send a batch of data rows to the project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "project = client.create_project(name=\"Pairwise Conversational Text Demo\",\n",
        "                                    media_type=lb.MediaType.Conversational)\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "project.create_batch(\n",
        "  \"batch_conversational\",\n",
        "  global_keys=[global_key_1, global_key_2, global_key_3],\n",
        "  priority=5\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Step 3: Upload annotations to a project as pre-labels or complete labels"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "Setup the payload with the annotations that were created in Step 1."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "labels = []\n",
        "for key in [global_key_1, global_key_2, global_key_3]:\n",
        "  for ann in [radio_annotation_ndjson, text_annotation_ndjson]:\n",
        "    ann_copy = ann.copy()\n",
        "    ann_copy.update({\n",
        "        \"dataRow\": {\n",
        "            \"globalKey\": key\n",
        "        }\n",
        "    })\n",
        "    labels.append(ann_copy)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Model Assisted Labeling (MAL)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_job = lb.MALPredictionImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid,\n",
        "    name=f\"mal_job-{str(uuid.uuid4())}\",\n",
        "    predictions=labels)\n",
        "\n",
        "upload_job.wait_until_done()\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Label Import"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_job = lb.LabelImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid,\n",
        "    name=\"label_import_job\"+str(uuid.uuid4()),\n",
        "    labels=labels)\n",
        "\n",
        "upload_job.wait_until_done();\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}