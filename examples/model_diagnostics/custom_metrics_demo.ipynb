{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mounted-asian",
   "metadata": {
    "id": "EyNkbpW7ouEf"
   },
   "source": [
    "  \n",
    "<td>\n",
    "    <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-lemon",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Model Diagnostics - Custom Metrics Demo\n",
    "\n",
    "* Measuring model quality is critical to efficiently building models. It is important that the metrics used to measure model quality closely align with the business objectives for the model. Otherwise, slight changes in model quality, as they related to these core objectives, are lost to noise. Custom metrics enables users to measure model quality in terms of their exact business goals. By incorporating custom metrics into workflows, users can:\n",
    "    * Iterate faster\n",
    "    * Measure and report on model quality\n",
    "    * Understand marginal value of additional labels and modeling efforts\n",
    "\n",
    "    \n",
    "* Checkout this [notebook](custom_metrics_basics.ipynb) for more details on the metrics types and built in functions for calculating metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-magic",
   "metadata": {
    "id": "subsequent-magic"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-minister",
   "metadata": {
    "id": "voluntary-minister"
   },
   "outputs": [],
   "source": [
    "!pip install -q \"labelbox[data]\" \\\n",
    "             scikit-image \\\n",
    "             tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-worship",
   "metadata": {
    "id": "wooden-worship"
   },
   "outputs": [],
   "source": [
    "# Run these if running in a colab notebook\n",
    "COLAB = \"google.colab\" in str(get_ipython())\n",
    "\n",
    "if COLAB:\n",
    "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    !cd labelbox-python\n",
    "    !mv labelbox-python/examples/model_assisted_labeling/*.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-leone",
   "metadata": {
    "id": "latter-leone"
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-richards",
   "metadata": {
    "id": "committed-richards"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../model_assisted_labeling')\n",
    "\n",
    "import uuid\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import requests\n",
    "from tqdm import notebook\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool\n",
    "from labelbox.data.metrics.group import get_label_pairs\n",
    "from labelbox import Client, LabelingFrontend, MALPredictionImport\n",
    "from labelbox.data.metrics import (\n",
    "    feature_miou_metric, \n",
    "    confusion_matrix_metric, \n",
    "    feature_confusion_matrix_metric\n",
    ")\n",
    "from labelbox.data.serialization import NDJsonConverter\n",
    "from labelbox.data.annotation_types import (\n",
    "    ScalarMetric, \n",
    "    LabelList, \n",
    "    Label, \n",
    "    ImageData, \n",
    "    MaskData,\n",
    "    Mask, \n",
    "    Polygon,\n",
    "    Point, \n",
    "    Rectangle, \n",
    "    ObjectAnnotation,\n",
    "    ClassificationAnnotation,\n",
    "    ClassificationAnswer,\n",
    "    Radio\n",
    ")\n",
    "\n",
    "try:\n",
    "    from image_model import predict, load_model\n",
    "except ModuleNotFoundError: \n",
    "    # !git clone https://github.com/Labelbox/labelbox-python.git\n",
    "    # !cd labelbox-python && git checkout mea-dev\n",
    "    # !mv labelbox-python/examples/model_assisted_labeling/*.py .\n",
    "    raise Exception(\"You will need to run from the labelbox-python git repo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-ambassador",
   "metadata": {},
   "source": [
    "Configure client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-chase",
   "metadata": {
    "id": "economic-chase"
   },
   "outputs": [],
   "source": [
    "API_KEY = None\n",
    "PROJECT_NAME = \"Diagnostics Demo Custom Metrics\"\n",
    "MODEL_NAME = \"MSCOCO Mapillary Custom Metrics\"\n",
    "MODEL_VERSION = \"0.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-myanmar",
   "metadata": {
    "id": "affecting-myanmar"
   },
   "outputs": [],
   "source": [
    "client = Client(api_key=API_KEY)\n",
    "load_model() # initialize Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-program",
   "metadata": {
    "id": "modern-program"
   },
   "outputs": [],
   "source": [
    "# Configure for whatever combination of tools and class names that you would like.\n",
    "class_mappings = {\n",
    "    1: {\"name\": 'person', \"kind\": Tool.Type.POLYGON},\n",
    "    2: {\"name\": 'bicycle', \"kind\": Tool.Type.SEGMENTATION, 'color' : 64},\n",
    "    3: {\"name\": 'car', \"kind\": Tool.Type.BBOX},\n",
    "    4: {\"name\": 'motorcycle', \"kind\": Tool.Type.BBOX},\n",
    "    6: {\"name\": 'bus', \"kind\": Tool.Type.POLYGON},\n",
    "    7: {\"name\": 'train', \"kind\": Tool.Type.POLYGON},\n",
    "    8: {\"name\": 'truck', \"kind\": Tool.Type.POLYGON},\n",
    "    10: {\"name\": 'traffic light', \"kind\": Tool.Type.POINT},\n",
    "    11: {\"name\": 'fire hydrant', \"kind\": Tool.Type.BBOX},\n",
    "    13: {\"name\": 'stop sign', \"kind\": Tool.Type.SEGMENTATION, 'color' : 255},\n",
    "    14: {\"name\": 'parking meter', \"kind\": Tool.Type.POINT},\n",
    "    28: {\"name\": 'umbrella', \"kind\": Tool.Type.SEGMENTATION, 'color' : 128},    \n",
    "    31: {\"name\": 'handbag', \"kind\": Tool.Type.POINT},        \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-burden",
   "metadata": {
    "id": "dated-burden"
   },
   "source": [
    "## Create Predictions\n",
    "* Loop over data_rows, make predictions, and create ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- setup dataset ---\n",
    "# load mapillary sample\n",
    "sample_csv_url = \"https://raw.githubusercontent.com/Labelbox/labelbox-python/develop/examples/assets/mapillary_sample.csv\"\n",
    "with requests.get(sample_csv_url, stream=True) as r:\n",
    "    image_data = [row.split(',') for row in (line.decode('utf-8') for line in r.iter_lines())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-savings",
   "metadata": {
    "id": "asian-savings"
   },
   "outputs": [],
   "source": [
    "predictions = LabelList()\n",
    "for (image_url, external_id) in notebook.tqdm(image_data):\n",
    "    image = ImageData(url = image_url, external_id = external_id)\n",
    "    height, width = image.value.shape[:2]\n",
    "    prediction = predict(np.array([image.im_bytes]), min_score=0.5, height=height, width = width)\n",
    "    boxes, classes, seg_masks = prediction[\"boxes\"], prediction[\"class_indices\"], prediction[\"seg_masks\"]\n",
    "    annotations = []\n",
    "    for box, class_idx, seg in zip(boxes, classes, seg_masks):\n",
    "        if class_idx in class_mappings:\n",
    "            class_info = class_mappings.get(class_idx)\n",
    "            if class_info['kind'] == Tool.Type.POLYGON:\n",
    "                contours = measure.find_contours(seg, 0.5)\n",
    "                pts = contours[0].astype(np.int32)\n",
    "                value = Polygon(points = [Point(x = x, y = y) for x,y in np.roll(pts, 1, axis=-1)])\n",
    "            elif class_info['kind'] == Tool.Type.BBOX:\n",
    "                value = Rectangle(start = Point(x = box[1], y = box[0]), end = Point(x=box[3], y=box[2]))\n",
    "            elif class_info['kind'] == Tool.Type.POINT:\n",
    "                value = Point(x=(box[1] + box[3]) / 2., y = (box[0] + box[2]) / 2.)\n",
    "            elif class_info['kind'] == Tool.Type.SEGMENTATION:\n",
    "                value = Mask(mask = MaskData.from_2D_arr(seg * class_info['color']), color = (class_info['color'],)* 3)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported kind found. {class_info['kind']}\")\n",
    "            annotations.append(ObjectAnnotation(name = class_info['name'], value = value))\n",
    "    predictions.append(Label(data = image, annotations = annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-suicide",
   "metadata": {},
   "source": [
    "## Setup a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "for target in class_mappings.values():\n",
    "     tools.append(Tool(tool=target['kind'], name=target[\"name\"]))\n",
    "ontology_builder = OntologyBuilder(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Setting up: {PROJECT_NAME}\")\n",
    "\n",
    "project = client.create_project(name=PROJECT_NAME)\n",
    "editor = next(client.get_labeling_frontends(where=LabelingFrontend.name == \"Editor\"))\n",
    "project.setup(editor, ontology_builder.asdict())\n",
    "\n",
    "dataset = client.create_dataset(name=\"Mapillary Diagnostics Demo\")\n",
    "print(f\"Dataset Created: {dataset.uid}\")\n",
    "project.datasets.connect(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-shelf",
   "metadata": {},
   "source": [
    "## Prepare for upload\n",
    "* Our local annotations need the following:\n",
    "    1. signed url for segmentation masks\n",
    "    2. data rows in labelbox\n",
    "    3. feature schema ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "signer = lambda _bytes: client.upload_data(content=_bytes, sign=True)\n",
    "predictions.add_url_to_masks(signer) \\\n",
    "         .add_url_to_data(signer) \\\n",
    "         .assign_feature_schema_ids(OntologyBuilder.from_project(project)) \\\n",
    "         .add_to_dataset(dataset, client.upload_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-seafood",
   "metadata": {
    "id": "perfect-seafood"
   },
   "source": [
    "## **Optional** - Create labels with [Model Assisted Labeling](https://docs.labelbox.com/en/core-concepts/model-assisted-labeling)\n",
    "\n",
    "* Pre-label image so that we can quickly create ground truth\n",
    "* Create ground truth data for Model Diagnostics\n",
    "* Click on link below to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-painting",
   "metadata": {
    "id": "subject-painting"
   },
   "outputs": [],
   "source": [
    "RUN_MAL = True\n",
    "if RUN_MAL:\n",
    "    project.enable_model_assisted_labeling()\n",
    "    # Convert from annotation types to import format\n",
    "    ndjson_predictions = NDJsonConverter.serialize(predictions)\n",
    "    upload_task = MALPredictionImport.create_from_objects(client, project.uid, f'mal-import-{uuid.uuid4()}',ndjson_predictions )\n",
    "    upload_task.wait_until_done()\n",
    "    print(upload_task.state , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MV4U1W4H_eMq",
   "metadata": {
    "id": "MV4U1W4H_eMq"
   },
   "outputs": [],
   "source": [
    "print(f\"https://app.labelbox.com/go-label/{project.uid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-mandate",
   "metadata": {
    "id": "stopped-mandate"
   },
   "source": [
    "## Export Labels\n",
    "\n",
    "We do not support `Skipped` labels and have a limit of **2000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-seminar",
   "metadata": {
    "id": "excited-seminar"
   },
   "outputs": [],
   "source": [
    "MAX_LABELS = 2000\n",
    "labels = [l for idx, l in enumerate(project.label_generator()) if idx < MAX_LABELS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-catering",
   "metadata": {
    "id": "smoking-catering"
   },
   "source": [
    "## Setup Model & Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-minnesota",
   "metadata": {
    "id": "mental-minnesota"
   },
   "outputs": [],
   "source": [
    "lb_model = client.create_model(name = MODEL_NAME, ontology_id = project.ontology().uid)\n",
    "lb_model_run = lb_model.create_model_run(MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cu8h6h0g-Fe2",
   "metadata": {
    "id": "cu8h6h0g-Fe2"
   },
   "source": [
    "Select label ids to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-coordinate",
   "metadata": {
    "id": "static-coordinate"
   },
   "outputs": [],
   "source": [
    "lb_model_run.upsert_labels([label.uid for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g_u1ak2n7qn5",
   "metadata": {
    "id": "g_u1ak2n7qn5"
   },
   "source": [
    "### Compute Metrics\n",
    "* First get pairs of labels and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-netherlands",
   "metadata": {},
   "source": [
    "* Create helper functions for our metric\n",
    "* All functions will accept ground truth and prediction annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import cascaded_union\n",
    "\n",
    "def nearby_cars_iou(ground_truths, predictions, area_threshold = 17000):\n",
    "    \"\"\"\n",
    "    Metric to track the iou score for cars that are nearby (determined by pixel size).\n",
    "    \n",
    "    This might be useful to investigate why the model poorly when vehicles are nearby.\n",
    "    We might care a lot about optimizing this metric because our self driving car needs to \n",
    "     be aware of its immediate surroundings for safety reasons.\n",
    "    \"\"\"\n",
    "    ground_truths = [gt for gt in ground_truths if gt.name == 'car']\n",
    "    predictions   = [pred for pred in predictions if pred.name == 'car']\n",
    "    ground_truths = cascaded_union([gt.value.shapely for gt in ground_truths if gt.value.shapely.area > area_threshold])\n",
    "    predictions   = cascaded_union([pred.value.shapely for pred in predictions if pred.value.shapely.area > area_threshold])\n",
    "    union = ground_truths.union(predictions).area\n",
    "    # If there is no prediction or label then the score is undefined\n",
    "    if union == 0:\n",
    "        return []\n",
    "    return [ScalarMetric(\n",
    "            value = ground_truths.intersection(predictions).area / union,\n",
    "            metric_name = \"iou\",\n",
    "            feature_name = \"car\",\n",
    "            subclass_name = \"nearby\" # Doesn't necessarily need to be a subclass in the ontology\n",
    "        )] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-rugby",
   "metadata": {},
   "source": [
    "* Compute and sssign each metric to prediction label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-fairy",
   "metadata": {
    "id": "committed-fairy"
   },
   "outputs": [],
   "source": [
    "# Metric functions expect to be provided labels and predictions that correspond to the same data image/video frame\n",
    "# This get_label_pairs function uses the datarow id to achieve this.\n",
    "pairs = get_label_pairs(labels, predictions, filter_mismatch = True)\n",
    "for (ground_truth, prediction) in pairs.values():\n",
    "    metrics = []\n",
    "    metrics.extend(feature_miou_metric(ground_truth.annotations, prediction.annotations))\n",
    "    metrics.extend(feature_confusion_matrix_metric(ground_truth.annotations, prediction.annotations))    \n",
    "    metrics.extend(nearby_cars_iou(ground_truth.annotations, prediction.annotations))\n",
    "    prediction.annotations.extend(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-illinois",
   "metadata": {},
   "source": [
    "### Upload to Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-addition",
   "metadata": {
    "id": "anonymous-addition"
   },
   "outputs": [],
   "source": [
    "upload_task = lb_model_run.add_predictions(f'diagnostics-import-{uuid.uuid4()}', NDJsonConverter.serialize(predictions))\n",
    "upload_task.wait_until_done()\n",
    "print(upload_task.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uTjGOyIW-3op",
   "metadata": {
    "id": "uTjGOyIW-3op"
   },
   "source": [
    "### Open Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zrll9K6Q9tGK",
   "metadata": {
    "id": "zrll9K6Q9tGK"
   },
   "outputs": [],
   "source": [
    "for idx, model_run_data_row in enumerate(lb_model_run.model_run_data_rows()):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(model_run_data_row.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-silly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model Diagnostics Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
