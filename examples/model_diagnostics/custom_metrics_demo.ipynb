{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "\n",
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/develop/examples/prediction_upload/image_predictions.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/blob/develop/examples/prediction_upload/image_predictions.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "# Model Diagnostics - Custom Metrics Demo\n",
        "\n",
        "* Measuring model quality is critical to efficiently building models. It is important that the metrics used to measure model quality closely align with the business objectives for the model. Otherwise, slight changes in model quality, as they related to these core objectives, are lost to noise. Custom metrics enables users to measure model quality in terms of their exact business goals. By incorporating custom metrics into workflows, users can:\n",
        "    * Iterate faster\n",
        "    * Measure and report on model quality\n",
        "    * Understand marginal value of additional labels and modeling efforts\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Environment setup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q 'labelbox[data]'"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
        "from labelbox import Client, MALPredictionImport, LabelImport\n",
        "from labelbox.data.serialization import NDJsonConverter\n",
        "from labelbox.schema.media_type import MediaType\n",
        "from labelbox.schema.quality_mode import QualityMode\n",
        "from labelbox.data.metrics.group import get_label_pairs\n",
        "from labelbox.data.metrics import feature_miou_metric, feature_confusion_matrix_metric\n",
        "from labelbox.data.annotation_types import (\n",
        "    Label, ImageData, ObjectAnnotation, MaskData,\n",
        "    Rectangle, Point, Line, Mask, Polygon,\n",
        "    Radio, Checklist, Text,\n",
        "    ClassificationAnnotation, ClassificationAnswer, RelationshipAnnotation, Relationship\n",
        ")\n",
        "import uuid\n",
        "import numpy as np\n",
        "from labelbox.schema.queue_mode import QueueMode"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Replace with your API Key\n",
        "Guides on [Create an API key](https://docs.labelbox.com/docs/create-an-api-key)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "API_KEY = \"\"\n",
        "\n",
        "client = Client(API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Supported Predictions"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "########### Radio Classification ###########\n",
        "\n",
        "# Python annotation\n",
        "radio_prediction = ClassificationAnnotation(\n",
        "    name=\"radio_question\",\n",
        "    value=Radio(answer = ClassificationAnswer(name = \"first_radio_answer\", confidence=0.5))\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "radio_prediction_ndjson = {\n",
        "  'name': 'radio_question',\n",
        "  'answer': {'name': 'first_radio_answer', 'confidence': 0.5}\n",
        "}\n",
        "\n",
        "########## Nested Classifications are only supported with NDJSON tools ##########\n",
        "\n",
        "nested_radio_prediction_ndjson = {\n",
        "  \"name\": \"nested_radio_question\",\n",
        "  \"confidence\": 0.5 ,\n",
        "  \"answer\": { \"name\": \"first_radio_answer\", \"confidence\": 0.5 },\n",
        "      \"classifications\" : [\n",
        "      {\n",
        "        \"name\": \"sub_radio_question\",\n",
        "        \"answer\": {\"name\": \"first_sub_radio_answer\", \"confidence\": 0.5 }\n",
        "      }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "nested_checklist_prediction_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"confidence\": 0.5 ,\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\",\n",
        "      \"confidence\": 0.5,\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\",\n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\", \"confidence\": 0.5 }\n",
        "        }\n",
        "      ]\n",
        "  }]\n",
        "}\n",
        "\n",
        "############ Checklist ############\n",
        "\n",
        "# Python Annotations\n",
        "checklist_prediction = ClassificationAnnotation(\n",
        "  name=\"checklist_question\", # must match your ontology feature's name\n",
        "  value=Checklist(\n",
        "      answer = [\n",
        "        ClassificationAnswer(\n",
        "            name = \"first_checklist_answer\",\n",
        "            confidence=0.5\n",
        "        ),\n",
        "        ClassificationAnswer(\n",
        "            name = \"second_checklist_answer\",\n",
        "            confidence=0.5\n",
        "        )\n",
        "      ]\n",
        "    )\n",
        " )\n",
        "\n",
        "# NDJSON\n",
        "checklist_prediction_ndjson = {\n",
        "  'name': 'checklist_question',\n",
        "  'answer': [\n",
        "    {'name': 'first_checklist_answer' , 'confidence': 0.5},\n",
        "    {'name': 'second_checklist_answer', 'confidence': 0.5}\n",
        "  ]\n",
        "}\n",
        "\n",
        "####### Bounding box #######\n",
        "\n",
        "\n",
        "# Python Annotation\n",
        "bbox_prediction = ObjectAnnotation(\n",
        "  name = \"bounding_box\",  # must match your ontology feature's name\n",
        "  confidence=0.5,\n",
        "  value=Rectangle(\n",
        "        start=Point(x=977, y=1690), # Top left\n",
        "        end=Point(x=330, y=225), # Bottom right\n",
        "    ),\n",
        "\n",
        ")\n",
        "\n",
        "#NDJSON\n",
        "bbox_prediction_ndjson = {\n",
        "  'name': 'bounding_box',\n",
        "  'confidence': 0.5,\n",
        "  'bbox': {\n",
        "          \"top\": 500,\n",
        "          \"left\": 1190,\n",
        "          \"height\": 230,\n",
        "          \"width\": 225\n",
        "      }\n",
        "}\n",
        "\n",
        "####### Bounding box with nested classification #######\n",
        "bbox_with_radio_subclass_prediction = ObjectAnnotation(\n",
        "    name=\"bbox_with_radio_subclass\",\n",
        "    confidence=0.5, # must match your ontology feature's name\n",
        "    value=Rectangle(\n",
        "        start=Point(x=433, y=341), # Top left\n",
        "        end=Point(x=291, y=230), # Bottom right\n",
        "    ),\n",
        "    classifications=[\n",
        "    \tClassificationAnnotation(\n",
        "        \tname=\"sub_radio_question\",\n",
        "      \t\tvalue=Radio(answer=ClassificationAnswer(name=\"first_sub_radio_answer\", confidence=0.5))\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "## NDJSON\n",
        "bbox_with_radio_subclass_prediction_ndjson = {\n",
        "    \"name\": \"bbox_with_radio_subclass\",\n",
        "    \"confidence\": 0.5,\n",
        "    \"classifications\": [{\n",
        "        \"name\": \"sub_radio_question\",\n",
        "        \"confidence\": 0.5,\n",
        "        \"answer\":\n",
        "            { \"name\":\"first_sub_radio_answer\", \"confidence\": 0.5}\n",
        "\n",
        "    }],\n",
        "    \"bbox\": {\n",
        "          \"top\": 533,\n",
        "          \"left\": 641,\n",
        "          \"height\": 291,\n",
        "          \"width\": 330\n",
        "        }\n",
        "}\n",
        "\n",
        "\n",
        "####### Bounding box with nested free text #######\n",
        "\n",
        "## NDJSON\n",
        "bbox_with_free_text_subclass_prediction_ndjson = {\n",
        "    \"name\": \"bbox_with_free_text_subclass\",\n",
        "    \"confidence\": 0.5,\n",
        "    \"classifications\": [{\n",
        "        \"name\": \"text\",\n",
        "        \"confidence\": 0.5,\n",
        "        'answer': 'sample text',\n",
        "\n",
        "    }],\n",
        "    \"bbox\": {\n",
        "          \"top\": 933,\n",
        "          \"left\": 541,\n",
        "          \"height\": 191,\n",
        "          \"width\": 330\n",
        "        }\n",
        "}\n",
        "\n",
        "########## Polygon ##########\n",
        "# Python Anotation\n",
        "polygon_prediction = ObjectAnnotation(\n",
        "  name = \"polygon\",  # must match your ontology feature's name\n",
        "  confidence = 0.5,\n",
        "  value=Polygon( # Coordinates for the verticies of your polygon\n",
        "        points=[Point(x=1489.581,y=183.934),Point(x=2278.306,y=256.885),Point(x=2428.197,y=200.437),Point(x=2560.0,y=335.419),\n",
        "                Point(x=2557.386,y=503.165),Point(x=2320.596,y=503.103),Point(x=2156.083, y=628.943),Point(x=2161.111,y=785.519),\n",
        "                Point(x=2002.115, y=894.647),Point(x=1838.456,y=877.874),Point(x=1436.53,y=874.636),Point(x=1411.403,y=758.579),\n",
        "                Point(x=1353.853,y=751.74),Point(x=1345.264, y=453.461),Point(x=1426.011,y=421.129)]\n",
        "    ),\n",
        ")\n",
        "\n",
        "polygon_prediction_target = ObjectAnnotation(\n",
        "  name = \"polygon\",  # must match your ontology feature's name\n",
        "  confidence = 0.5,\n",
        "  value=Polygon( # Coordinates for the verticies of your polygon\n",
        "        points=[Point(x=1089.581,y=203.934),Point(x=1878.306,y=276.885),Point(x=2028.197,y=220.437),Point(x=2160.0,y=355.419),\n",
        "                Point(x=2157.386,y=523.165),Point(x=2020.596,y=523.103),Point(x=1756.083, y=648.943),Point(x=1761.111,y=805.519),\n",
        "                Point(x=1602.115, y=914.647),Point(x=1438.456,y=897.874),Point(x=1036.53,y=894.636),Point(x=1011.403,y=778.579),\n",
        "                Point(x=953.853,y=771.74),Point(x=945.264, y=473.461),Point(x=926.011,y=441.129)]\n",
        "    ),\n",
        ")\n",
        "\n",
        "polygon_relationship = RelationshipAnnotation(\n",
        "    name=\"relationship\",\n",
        "    value=Relationship(\n",
        "        source=polygon_prediction,\n",
        "        target=polygon_prediction_target,\n",
        "        type=Relationship.Type.UNIDIRECTIONAL,\n",
        "    ))\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "\n",
        "polygon_prediction_ndjson = {\n",
        "  'name': 'polygon',\n",
        "  'confidence': 0.5,\n",
        "  'polygon': [\n",
        "    {'x': 1489.581, 'y': 183.934},\n",
        "    {'x': 2278.306, 'y': 256.885},\n",
        "    {'x': 2428.197, 'y': 200.437},\n",
        "    {'x': 2560.0, 'y': 335.419},\n",
        "    {'x': 2557.386, 'y': 503.165},\n",
        "    {'x': 2320.596, 'y': 503.103},\n",
        "    {'x': 2156.083, 'y': 628.943},\n",
        "    {'x': 2161.111, 'y': 785.519},\n",
        "    {'x': 2002.115, 'y': 894.647},\n",
        "    {'x': 1838.456, 'y': 877.874},\n",
        "    {'x': 1436.53, 'y': 874.636},\n",
        "    {'x': 1411.403, 'y': 758.579},\n",
        "    {'x': 1353.853, 'y': 751.74},\n",
        "    {'x': 1345.264, 'y': 453.461},\n",
        "    {'x': 1426.011, 'y': 421.129},\n",
        "    {'x': 1489.581, 'y': 183.934}\n",
        "  ]\n",
        "}\n",
        "\n",
        "####### Free text #######\n",
        "# Confidence is not supported for text prediction\n",
        "# Python annotation\n",
        "text_annotation = ClassificationAnnotation(\n",
        "  name=\"free_text\",  # must match your ontology feature's name\n",
        "  value=Text(answer=\"sample text\")\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "text_annotation_ndjson = {\n",
        "  'name': 'free_text',\n",
        "  'answer': 'sample text',\n",
        "}\n",
        "\n",
        "######### Segmentation mask #########\n",
        "\n",
        "# Python\n",
        "# Identifying what values in the numpy array correspond to the mask annotation\n",
        "color = (0, 0, 0)\n",
        "\n",
        "# convert a polygon to mask\n",
        "im_height, im_width = 100,100 #need to provide the height and width of image.\n",
        "mask_data = MaskData(arr=\n",
        "                     polygon_prediction.value.draw(height=im_height,width=im_width,color=color))\n",
        "\n",
        "# convert a 2D array to 3D array\n",
        "arr_2d = np.zeros((100,100), dtype='uint8')\n",
        "mask_data = MaskData.from_2D_arr(arr_2d)\n",
        "\n",
        "# a 3D array where 3rd axis is RGB values.\n",
        "mask_data = MaskData(arr= np.zeros([400,450,3],dtype='uint8'))\n",
        "\n",
        "mask_prediction = ObjectAnnotation(\n",
        "  name = \"mask\", # must match your ontology feature's name\n",
        "  confidence=0.5,\n",
        "  value=Mask(mask=mask_data, color=color),\n",
        ")\n",
        "\n",
        "mask_prediction_ndjson = {\n",
        "  \"name\": \"mask\",\n",
        "  \"confidence\": 0.5,\n",
        "  \"classifications\": [],\n",
        "  \"mask\": {\"instanceURI\": \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/raster_seg.png\",\n",
        "  \"colorRGB\": (255, 255, 255)}\n",
        "}\n",
        "\n",
        "######## Point ########\n",
        "\n",
        "# Python Annotation\n",
        "point_prediction = ObjectAnnotation(\n",
        "  name = \"point\",  # must match your ontology feature's name\n",
        "  confidence=0.5,\n",
        "  value = Point(x=1166.606, y=1441.768),\n",
        ")\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "point_prediction_ndjson = {\n",
        "  'name': 'point',\n",
        "  'confidence': 0.5,\n",
        "  'classifications': [],\n",
        "  'point': {'x': 1166.606, 'y': 1441.768}\n",
        "}\n",
        "\n",
        "###### Polyline ######\n",
        "\n",
        "\n",
        "# Python Annotation\n",
        "\n",
        "polyline_prediction = ObjectAnnotation(\n",
        "  name = \"polyline\", # must match your ontology feature's name\n",
        "  confidence=0.5, ## Not supported for python annotation tools\n",
        "  value=Line( # Coordinates for the keypoints in your polyline\n",
        "        points=[Point(x=2534.353, y=249.471),Point(x=2429.492, y=182.092),Point(x=2294.322, y=221.962),Point(x=2224.491, y=180.463),Point(x=2136.123, y=204.716),\n",
        "                Point(x=1712.247, y=173.949),Point(x=1703.838, y=84.438),Point(x=1579.772, y=82.61),Point(x=1583.442, y=167.552),\n",
        "                Point(x=1478.869, y=164.903),Point(x=1418.941, y=318.149),Point(x=1243.128, y=400.815),Point(x=1022.067, y=319.007),\n",
        "                Point(x=892.367, y=379.216),Point(x=670.273, y=364.408),Point(x=613.114, y=288.16),Point(x=377.559, y=238.251),\n",
        "                Point(x=368.087, y=185.064),Point(x=246.557, y=167.286),Point(x=236.648, y=285.61),Point(x=90.929, y=326.412)]\n",
        "    ),\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "polyline_prediction_ndjson = {\n",
        "  'name': 'polyline',\n",
        "  'confidence':0.5,\n",
        "  'classifications': [],\n",
        "  'line': [\n",
        "    {'x': 2534.353, 'y': 249.471},\n",
        "    {'x': 2429.492, 'y': 182.092},\n",
        "    {'x': 2294.322, 'y': 221.962},\n",
        "    {'x': 2224.491, 'y': 180.463},\n",
        "    {'x': 2136.123, 'y': 204.716},\n",
        "    {'x': 1712.247, 'y': 173.949},\n",
        "    {'x': 1703.838, 'y': 84.438},\n",
        "    {'x': 1579.772, 'y': 82.61},\n",
        "    {'x': 1583.442, 'y': 167.552},\n",
        "    {'x': 1478.869, 'y': 164.903},\n",
        "    {'x': 1418.941, 'y': 318.149},\n",
        "    {'x': 1243.128, 'y': 400.815},\n",
        "    {'x': 1022.067, 'y': 319.007},\n",
        "    {'x': 892.367, 'y': 379.216},\n",
        "    {'x': 670.273, 'y': 364.408},\n",
        "    {'x': 613.114, 'y': 288.16},\n",
        "    {'x': 377.559, 'y': 238.251},\n",
        "    {'x': 368.087, 'y': 185.064},\n",
        "    {'x': 246.557, 'y': 167.286},\n",
        "    {'x': 236.648, 'y': 285.61},\n",
        "    {'x': 90.929, 'y': 326.412}\n",
        "  ]\n",
        "}\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Import data rows into Catalog"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "NUM_DATA_ROWS = 1\n",
        "\n",
        "# send a sample image as batch to the project\n",
        "test_img_urls = [{\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/2560px-Kitano_Street_Kobe01s5s4110.jpeg\",\n",
        "    \"global_key\": str(uuid.uuid4())\n",
        "} for i in range(0, NUM_DATA_ROWS)]\n",
        "dataset = client.create_dataset(name=\"image_prediction_demo\", iam_integration=None)\n",
        "data_rows = dataset.create_data_rows(test_img_urls)\n",
        "print(data_rows)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Create/select an Ontology for your model predictions\n",
        "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the name/instructions fields in your annotations to ensure the correct feature schemas are matched.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "ontology_builder = OntologyBuilder(\n",
        "  classifications=[ # List of Classification objects\n",
        "    Classification( # Radio classification given the name \"text\" with two options: \"first_radio_answer\" and \"second_radio_answer\"\n",
        "      class_type=Classification.Type.RADIO,\n",
        "      name=\"radio_question\",\n",
        "      options=[\n",
        "        Option(value=\"first_radio_answer\"),\n",
        "        Option(value=\"second_radio_answer\")\n",
        "      ]\n",
        "    ),\n",
        "    Classification( # Checklist classification given the name \"text\" with two options: \"first_checklist_answer\" and \"second_checklist_answer\"\n",
        "      class_type=Classification.Type.CHECKLIST,\n",
        "      name=\"checklist_question\",\n",
        "      options=[\n",
        "        Option(value=\"first_checklist_answer\"),\n",
        "        Option(value=\"second_checklist_answer\")\n",
        "      ]\n",
        "    ),\n",
        "    Classification( # Text classification given the name \"text\"\n",
        "      class_type=Classification.Type.TEXT,\n",
        "      name=\"free_text\"\n",
        "    ),\n",
        "    Classification(\n",
        "        class_type=Classification.Type.RADIO,\n",
        "        name=\"nested_radio_question\",\n",
        "        options=[\n",
        "            Option(\"first_radio_answer\",\n",
        "                options=[\n",
        "                    Classification(\n",
        "                        class_type=Classification.Type.RADIO,\n",
        "                        name=\"sub_radio_question\",\n",
        "                        options=[Option(\"first_sub_radio_answer\")]\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "          ]\n",
        "        ),\n",
        "    Classification(\n",
        "      class_type=Classification.Type.CHECKLIST,\n",
        "      name=\"nested_checklist_question\",\n",
        "      options=[\n",
        "          Option(\"first_checklist_answer\",\n",
        "            options=[\n",
        "              Classification(\n",
        "                  class_type=Classification.Type.CHECKLIST,\n",
        "                  name=\"sub_checklist_question\",\n",
        "                  options=[Option(\"first_sub_checklist_answer\")]\n",
        "              )\n",
        "          ]\n",
        "        )\n",
        "      ]\n",
        "    ),\n",
        "  ],\n",
        "  tools=[ # List of Tool objects\n",
        "    Tool( # Bounding Box tool given the name \"box\"\n",
        "      tool=Tool.Type.BBOX,\n",
        "      name=\"bounding_box\"),\n",
        "    Tool( # Bounding Box tool given the name \"box\"\n",
        "      tool=Tool.Type.BBOX,\n",
        "      name=\"bbox_with_radio_subclass\",\n",
        "      classifications=[\n",
        "            Classification(\n",
        "                class_type=Classification.Type.RADIO,\n",
        "                name=\"sub_radio_question\",\n",
        "                options=[\n",
        "                  Option(value=\"first_sub_radio_answer\")\n",
        "                ]\n",
        "              ),\n",
        "        ]\n",
        "      ),\n",
        "    Tool( # Bounding Box tool given the name \"box\"\n",
        "      tool=Tool.Type.BBOX,\n",
        "      name=\"bbox_with_free_text_subclassification\",\n",
        "      classifications=[\n",
        "            Classification(\n",
        "                class_type=Classification.Type.TEXT,\n",
        "                name=\"sub_text_classification\",\n",
        "              ),\n",
        "        ]\n",
        "      ),\n",
        "    Tool( # Polygon tool given the name \"polygon\"\n",
        "      tool=Tool.Type.POLYGON,\n",
        "      name=\"polygon\"),\n",
        "    Tool( # Segmentation mask tool given the name \"mask\"\n",
        "      tool=Tool.Type.RASTER_SEGMENTATION,\n",
        "      name=\"mask\"),\n",
        " \t  Tool( # Point tool given the name \"point\"\n",
        "      tool=Tool.Type.POINT,\n",
        "      name=\"point\"),\n",
        "    Tool( # Polyline tool given the name \"line\"\n",
        "      tool=Tool.Type.LINE,\n",
        "      name=\"polyline\")]\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Image Prediction Import Demo\", ontology_builder.asdict(), media_type=MediaType.Image)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Create a Model and Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# create Model\n",
        "model = client.create_model(name=\"with_aggregated_custom_metrics\" + str(uuid.uuid4()),\n",
        "                            ontology_id=ontology.uid)\n",
        "# create Model Run\n",
        "model_run = model.create_model_run(\"iteration 1\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Send data rows to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "model_run.upsert_data_rows(global_keys=[data_row.global_key for data_row in dataset.export_data_rows()])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 5. Create the predictions payload\n",
        "\n",
        "Create the prediction payload using the snippets of code in ***Supported Predictions*** section.\n",
        "\n",
        "The resulting label_ndjson should have exactly the same content for predictions that are supported by both (with exception of the uuid strings that are generated)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Label for predictions\n",
        "label_predictions = [Label(\n",
        "    data=ImageData(uid=data_row.uid),\n",
        "    annotations = [\n",
        "      radio_prediction,\n",
        "      checklist_prediction,\n",
        "      bbox_prediction,\n",
        "      bbox_with_radio_subclass_prediction,\n",
        "      polygon_prediction,\n",
        "      # mask_prediction,\n",
        "      point_prediction,\n",
        "      text_annotation,\n",
        "    ]\n",
        ") for data_row in dataset.export_data_rows()]\n",
        "\n",
        "# Convert the prediction label from a Labelbox class object to the underlying NDJSON format required for upload - uploads can be directly built in this syntax as well\n",
        "ndjson_prediction = list(NDJsonConverter.serialize(label_predictions))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "If using NDJSON"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Custom metrics"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Special case for custom feature metrics\n",
        "\n",
        "# NDJSON\n",
        "radio_prediction_ndjson = {\n",
        "  'name': 'radio_question',\n",
        "  'answer': {'name': 'first_radio_answer', 'confidence': 0.5,         'customMetrics': [\n",
        "            { 'name': 'iou', 'value': 0.1 },\n",
        "            { 'name': 'f1', 'value': 0.33 },\n",
        "            { 'name': 'precision', 'value': 0.55 },\n",
        "            { 'name': 'recall', 'value': 0.33 },\n",
        "            { 'name': 'tagsCount', 'value': 43 },\n",
        "            { 'name': 'metric_with_a_very_long_name', 'value': 0.334332 }\n",
        "          ]}\n",
        "}\n",
        "\n",
        "########## Nested Classifications are only supported with NDJSON tools ##########\n",
        "\n",
        "nested_radio_prediction_ndjson = {\n",
        "  \"name\": \"nested_radio_question\",\n",
        "  \"confidence\": 0.5 ,\n",
        "  \"answer\": { \"name\": \"first_radio_answer\", \"confidence\": 0.5,         'customMetrics': [\n",
        "            { 'name': 'iou', 'value': 0.5 },\n",
        "            { 'name': 'f1', 'value': 0.33 },\n",
        "            { 'name': 'precision', 'value': 0.55 },\n",
        "            { 'name': 'recall', 'value': 0.33 },\n",
        "            { 'name': 'tagsCount', 'value': 43 },\n",
        "            { 'name': 'metric_with_a_very_long_name', 'value': 0.334332 }\n",
        "          ] },\n",
        "      \"classifications\" : [\n",
        "      {\n",
        "        \"name\": \"sub_radio_question\",\n",
        "        \"answer\": {\"name\": \"first_sub_radio_answer\", \"confidence\": 0.5,         'customMetrics': [\n",
        "            { 'name': 'iou', 'value': 0.5 },\n",
        "            { 'name': 'f1', 'value': 0.33 },\n",
        "            { 'name': 'precision', 'value': 0.55 },\n",
        "            { 'name': 'recall', 'value': 0.33 },\n",
        "            { 'name': 'tagsCount', 'value': 43 },\n",
        "            { 'name': 'metric_with_a_very_long_name', 'value': 0.334332 }\n",
        "          ] }\n",
        "      }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "nested_checklist_prediction_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"confidence\": 0.5 ,\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\",\n",
        "      \"confidence\": 0.5,\n",
        "              'customMetrics': [\n",
        "            { 'name': 'iou', 'value': 0.5 },\n",
        "            { 'name': 'f1', 'value': 0.33 },\n",
        "            { 'name': 'precision', 'value': 0.55 },\n",
        "            { 'name': 'recall', 'value': 0.33 },\n",
        "            { 'name': 'tagsCount', 'value': 43 },\n",
        "            { 'name': 'metric_with_a_very_long_name', 'value': 0.334332 }\n",
        "          ],\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\",\n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\", \"confidence\": 0.5,         'customMetrics': [\n",
        "            { 'name': 'iou', 'value': 0.5 },\n",
        "            { 'name': 'f1', 'value': 0.33 },\n",
        "            { 'name': 'precision', 'value': 0.55 },\n",
        "            { 'name': 'recall', 'value': 0.33 },\n",
        "            { 'name': 'tagsCount', 'value': 43 },\n",
        "            { 'name': 'metric_with_a_very_long_name', 'value': 0.334332 }\n",
        "          ] }\n",
        "        }\n",
        "      ]\n",
        "  }]\n",
        "}\n",
        "\n",
        "############ Checklist ############\n",
        "checklist_prediction_ndjson = {\n",
        "  'name': 'checklist_question',\n",
        "  'answer': [\n",
        "    {'name': 'first_checklist_answer' , 'confidence': 0.5,         'customMetrics': [\n",
        "            { 'name': 'iou', 'value': 0.5 },\n",
        "            { 'name': 'f1', 'value': 0.33 },\n",
        "            { 'name': 'precision', 'value': 0.55 },\n",
        "            { 'name': 'recall', 'value': 0.33 },\n",
        "            { 'name': 'tagsCount', 'value': 43 },\n",
        "            { 'name': 'metric_with_a_very_long_name', 'value': 0.334332 }\n",
        "          ]},\n",
        "    {'name': 'second_checklist_answer', 'confidence': 0.5,         'customMetrics': [\n",
        "            { 'name': 'iou', 'value': 0.5 },\n",
        "            { 'name': 'f1', 'value': 0.33 },\n",
        "            { 'name': 'precision', 'value': 0.55 },\n",
        "            { 'name': 'recall', 'value': 0.33 },\n",
        "            { 'name': 'tagsCount', 'value': 43 },\n",
        "            { 'name': 'metric_with_a_very_long_name', 'value': 0.334332 }\n",
        "          ]}\n",
        "  ]\n",
        "}\n",
        "all_annotations = [\n",
        "      radio_prediction_ndjson,\n",
        "      nested_radio_prediction_ndjson,\n",
        "      checklist_prediction_ndjson,\n",
        "      nested_checklist_prediction_ndjson,\n",
        "      ]\n",
        "\n",
        "three_k_annotations = all_annotations\n",
        "\n",
        "ndjson_prediction_method2 = []\n",
        "dr_ids = [data_row.uid for data_row in dataset.export_data_rows()]\n",
        "for data_row_id in dr_ids:\n",
        "  for annot in three_k_annotations:\n",
        "    ndjson_prediction_method2.append({\n",
        "        **annot,\n",
        "        'uuid': str(uuid.uuid4()),\n",
        "        'dataRow': {'id': data_row_id },\n",
        "    })"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## OCR special case"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Special case for OCR\n",
        "\n",
        "bbox_with_free_text_subclass_prediction_ndjson1 = {\n",
        "    \"name\": \"bbox_with_free_text_subclassification\",\n",
        "    \"confidence\": 0.5,\n",
        "    \"classifications\": [{\n",
        "        \"name\": \"sub_text_classification\",\n",
        "        \"confidence\": 0.5,\n",
        "        'answer': 'aaaaaaaa - matching nicely',\n",
        "\n",
        "    }],\n",
        "    \"bbox\": {\n",
        "          \"top\": 933,\n",
        "          \"left\": 541,\n",
        "          \"height\": 191,\n",
        "          \"width\": 330\n",
        "        }\n",
        "}\n",
        "bbox_with_free_text_subclass_prediction_ndjson2 = {\n",
        "    \"name\": \"bbox_with_free_text_subclassification\",\n",
        "    \"confidence\": 0.5,\n",
        "    \"classifications\": [{\n",
        "        \"name\": \"sub_text_classification\",\n",
        "        \"confidence\": 0.5,\n",
        "        'answer': 'zzzzzzz',\n",
        "\n",
        "    }],\n",
        "    \"bbox\": {\n",
        "          \"top\": 913,\n",
        "          \"left\": 521,\n",
        "          \"height\": 50,\n",
        "          \"width\": 50\n",
        "        }\n",
        "}\n",
        "all_annotations = [\n",
        "      bbox_with_free_text_subclass_prediction_ndjson1,\n",
        "      bbox_with_free_text_subclass_prediction_ndjson2,\n",
        "      ]\n",
        "\n",
        "three_k_annotations = []\n",
        "three_k_annotations.extend(all_annotations)\n",
        "\n",
        "ndjson_prediction_method2 = []\n",
        "dr_ids = [data_row.uid for data_row in dataset.export_data_rows()]\n",
        "for data_row_id in dr_ids:\n",
        "  for annot in three_k_annotations:\n",
        "    ndjson_prediction_method2.append({\n",
        "        **annot,\n",
        "        'uuid': str(uuid.uuid4()),\n",
        "        'dataRow': {'id': data_row_id },\n",
        "    })"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "\n",
        "all_annotations = [\n",
        "      radio_prediction_ndjson,\n",
        "      checklist_prediction_ndjson,\n",
        "      bbox_prediction_ndjson,\n",
        "      bbox_with_radio_subclass_prediction_ndjson,\n",
        "      polygon_prediction_ndjson,\n",
        "      # mask_prediction_ndjson,\n",
        "      point_prediction_ndjson,\n",
        "      polyline_prediction_ndjson,\n",
        "      text_annotation_ndjson,\n",
        "      nested_radio_prediction_ndjson,\n",
        "      nested_checklist_prediction_ndjson\n",
        "      ]\n",
        "\n",
        "# three_k_annotations = bbox_predictions\n",
        "# three_k_annotations.extend(all_annotations)\n",
        "three_k_annotations = all_annotations\n",
        "\n",
        "ndjson_prediction_method2 = []\n",
        "dr_ids = [data_row.uid for data_row in dataset.export_data_rows()]\n",
        "for data_row_id in dr_ids:\n",
        "  for annot in three_k_annotations:\n",
        "    ndjson_prediction_method2.append({\n",
        "        **annot,\n",
        "        'uuid': str(uuid.uuid4()),\n",
        "        'dataRow': {'id': data_row_id }\n",
        "    })"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 6. Upload the predictions payload to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload the prediction label to the Model Run\n",
        "upload_job_prediction = model_run.add_predictions(\n",
        "    name=\"prediction_upload_job\"+str(uuid.uuid4()),\n",
        "    predictions=ndjson_prediction_method2)\n",
        "\n",
        "# Errors will appear for prediction uploads that failed.\n",
        "print(\"Errors:\",  upload_job_prediction.errors)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 7: Send annotations to a model run\n",
        "To visualize both annotations and predictions in the model run we will create a project with ground truth annotations.\n",
        "To send annotations to a Model Run, we must first import them into a project, create a label payload and then send them to the Model Run."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "##### 7.1. Create a labelbox project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Labelbox project\n",
        "project = client.create_project(name=\"image_prediction_many_kinds\",\n",
        "                                    quality_mode=QualityMode.Benchmark,\n",
        "                                    media_type=MediaType.Image)\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.2. Create a batch to send to the project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "project.create_batch(\n",
        "  \"batch_predictions_demo1\", # Each batch in a project must have a unique name\n",
        "  [data_row.uid for data_row in dataset.export_data_rows()], # A list of data rows or data row ids\n",
        "  5 # priority between 1(Highest) - 5(lowest)\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.3 Create the annotations payload"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "########### Annotations ###########\n",
        "radio_annotation_ndjson = {\n",
        "  \"name\": \"radio_question\",\n",
        "  \"answer\": {\"name\": \"first_radio_answer\"}\n",
        "}\n",
        "\n",
        "nested_radio_annotation_ndjson = {\n",
        "  \"name\": \"nested_radio_question\",\n",
        "  \"answer\": {\"name\": \"first_radio_answer\"},\n",
        "  \"classifications\" : [\n",
        "   {\"name\": \"sub_radio_question\", \"answer\": {\"name\": \"first_sub_radio_answer\"}}\n",
        "   ]\n",
        "}\n",
        "\n",
        "checklist_annotation_ndjson = {\n",
        "  \"name\": \"checklist_question\",\n",
        "  \"answer\": [\n",
        "    {\"name\": \"first_checklist_answer\"},\n",
        "    {\"name\": \"second_checklist_answer\"}\n",
        "  ]\n",
        "}\n",
        "\n",
        "bbox_annotation_ndjson = {\n",
        "  \"name\": \"bounding_box\",\n",
        "  \"bbox\": {\n",
        "          \"top\": 877,\n",
        "          \"left\": 1490,\n",
        "          \"height\": 130,\n",
        "          \"width\": 125\n",
        "      }\n",
        "}\n",
        "\n",
        "bbox_with_radio_subclass_ndjson = {\n",
        "    \"name\": \"bbox_with_radio_subclass\",\n",
        "    \"classifications\": [{\n",
        "        \"name\": \"sub_radio_question\",\n",
        "        \"answer\":\n",
        "            { \"name\":\"first_sub_radio_answer\" }\n",
        "\n",
        "    }],\n",
        "    \"bbox\": {\n",
        "          \"top\": 533,\n",
        "          \"left\": 841,\n",
        "          \"height\": 191,\n",
        "          \"width\": 230\n",
        "        }\n",
        "}\n",
        "\n",
        "polygon_annotation_ndjson = {\n",
        "  \"name\": \"polygon\",\n",
        "  \"polygon\": [\n",
        "    {\"x\": 1489.581, \"y\": 183.934},\n",
        "    {\"x\": 2278.306, \"y\": 256.885},\n",
        "    {\"x\": 2428.197, \"y\": 200.437},\n",
        "    {\"x\": 2560.0, \"y\": 335.419},\n",
        "    {\"x\": 2557.386, \"y\": 503.165},\n",
        "    {\"x\": 2320.596, \"y\": 503.103},\n",
        "    {\"x\": 2156.083, \"y\": 628.943},\n",
        "    {\"x\": 2161.111, \"y\": 785.519},\n",
        "    {\"x\": 2002.115, \"y\": 894.647},\n",
        "    {\"x\": 1838.456, \"y\": 877.874},\n",
        "    {\"x\": 1436.53, \"y\": 874.636},\n",
        "    {\"x\": 1411.403, \"y\": 758.579},\n",
        "    {\"x\": 1353.853, \"y\": 751.74},\n",
        "    {\"x\": 1345.264, \"y\": 453.461},\n",
        "    {\"x\": 1426.011, \"y\": 421.129},\n",
        "    {\"x\": 1489.581, \"y\": 183.934}\n",
        "  ]\n",
        "}\n",
        "\n",
        "mask_annotation_ndjson = {\n",
        "  \"name\": \"mask\",\n",
        "  \"classifications\": [],\n",
        "  \"mask\": {\"instanceURI\": \"https://storage.googleapis.com/labelbox-datasets/image_sample_data/raster_seg.png\",\n",
        "  \"colorRGB\": (0, 0, 0)}\n",
        "}\n",
        "\n",
        "\n",
        "point_annotation_ndjson = {\n",
        "  \"name\": \"point\",\n",
        "  \"classifications\": [],\n",
        "  \"point\": {\"x\": 1166.606, \"y\": 1441.768}\n",
        "}\n",
        "\n",
        "point_annotation_ndjson = {\n",
        "  \"name\": \"point\",\n",
        "  \"classifications\": [],\n",
        "  \"point\": {\"x\": 1166.606, \"y\": 1441.768}\n",
        "}\n",
        "\n",
        "polyline_annotation_ndjson = {\n",
        "  \"name\": \"polyline\",\n",
        "  \"classifications\": [],\n",
        "  \"line\": [\n",
        "    {\"x\": 2534.353, \"y\": 249.471},\n",
        "    {\"x\": 2429.492, \"y\": 182.092},\n",
        "    {\"x\": 2294.322, \"y\": 221.962},\n",
        "    {\"x\": 2224.491, \"y\": 180.463},\n",
        "    {\"x\": 2136.123, \"y\": 204.716},\n",
        "    {\"x\": 1712.247, \"y\": 173.949},\n",
        "    {\"x\": 1703.838, \"y\": 84.438},\n",
        "    {\"x\": 1579.772, \"y\": 82.61},\n",
        "    {\"x\": 1583.442, \"y\": 167.552},\n",
        "    {\"x\": 1478.869, \"y\": 164.903},\n",
        "    {\"x\": 1418.941, \"y\": 318.149},\n",
        "    {\"x\": 1243.128, \"y\": 400.815},\n",
        "    {\"x\": 1022.067, \"y\": 319.007},\n",
        "    {\"x\": 892.367, \"y\": 379.216},\n",
        "    {\"x\": 670.273, \"y\": 364.408},\n",
        "    {\"x\": 613.114, \"y\": 288.16},\n",
        "    {\"x\": 377.559, \"y\": 238.251},\n",
        "    {\"x\": 368.087, \"y\": 185.064},\n",
        "    {\"x\": 246.557, \"y\": 167.286},\n",
        "    {\"x\": 236.648, \"y\": 285.61},\n",
        "    {\"x\": 90.929, \"y\": 326.412}\n",
        "  ]\n",
        "}\n",
        "\n",
        "nested_checklist_annotation_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\",\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\",\n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\"}\n",
        "        }\n",
        "      ]\n",
        "  }]\n",
        "}\n",
        "\n",
        "text_annotation_ndjson = {\n",
        "  \"name\": \"free_text\",\n",
        "  \"answer\": \"sample text\",\n",
        "}\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.4. Create the label object"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Label object by identifying the applicable data row in Labelbox and providing a list of annotations\n",
        "annotations = [\n",
        "      radio_annotation_ndjson,\n",
        "      checklist_annotation_ndjson,\n",
        "      bbox_annotation_ndjson,\n",
        "      bbox_with_radio_subclass_ndjson,\n",
        "      polygon_annotation_ndjson,\n",
        "      mask_annotation_ndjson,\n",
        "      point_annotation_ndjson,\n",
        "      polyline_annotation_ndjson,\n",
        "      nested_radio_annotation_ndjson,\n",
        "      nested_checklist_annotation_ndjson,\n",
        "      text_annotation_ndjson\n",
        "  ]\n",
        "# gts = bbox_annotations\n",
        "gts = (annotations)\n",
        "ndjson_annotation = []\n",
        "for data_row in dataset.export_data_rows():\n",
        "  for annot in gts:\n",
        "      ndjson_annotation.append({\n",
        "        **annot,\n",
        "        'uuid': str(uuid.uuid4()),\n",
        "        'dataRow': {'id': data_row.uid}\n",
        "      })\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.5. Upload annotations to the project using Label Import"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_job_annotation = LabelImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid,\n",
        "    name=\"annotation_import_\" + str(uuid.uuid4()),\n",
        "    labels=ndjson_annotation)\n",
        "\n",
        "upload_job_annotation.wait_until_done()\n",
        "# Errors will appear for annotation uploads that failed.\n",
        "print(\"Errors:\", upload_job_annotation.errors)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.6 Send the annotations to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# get the labels id from the project\n",
        "task = project.export_v2()\n",
        "task.wait_till_done()\n",
        "label_ids = [l[\"id\"] for dr in task.result for l in dr[\"projects\"][project.uid][\"labels\"]]\n",
        "model_run.upsert_labels(label_ids)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Optional deletions for cleanup\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# project.delete()\n",
        "# dataset.delete()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}