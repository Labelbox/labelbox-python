{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/model_diagnostics/custom_metrics_demo.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/model_diagnostics/custom_metrics_demo.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "  \n",
        "<td>\n",
        "    <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "----\n",
        "\n",
        "# Model Diagnostics - Custom Metrics Demo\n",
        "\n",
        "* Measuring model quality is critical to efficiently building models. It is important that the metrics used to measure model quality closely align with the business objectives for the model. Otherwise, slight changes in model quality, as they related to these core objectives, are lost to noise. Custom metrics enables users to measure model quality in terms of their exact business goals. By incorporating custom metrics into workflows, users can:\n",
        "    * Iterate faster\n",
        "    * Measure and report on model quality\n",
        "    * Understand marginal value of additional labels and modeling efforts\n",
        "\n",
        "    \n",
        "* Checkout this [notebook](custom_metrics_basics.ipynb) for more details on the metrics types and built in functions for calculating metrics.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Install dependencies"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q \"labelbox[data]\" \\\n",
        "             scikit-image \\\n",
        "             tensorflow"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Run these if running in a colab notebook\n",
        "COLAB = \"google.colab\" in str(get_ipython())\n",
        "\n",
        "if COLAB:\n",
        "    !git clone https://github.com/Labelbox/labelbox-python.git\n",
        "    !cd labelbox-python\n",
        "    !mv labelbox-python/examples/model_assisted_labeling/*.py ."
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Import libraries"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('../model_assisted_labeling')\n",
        "\n",
        "import uuid\n",
        "import numpy as np\n",
        "from skimage import measure\n",
        "import requests\n",
        "from tqdm import notebook\n",
        "import requests\n",
        "import csv\n",
        "import os\n",
        "\n",
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "from labelbox.data.metrics.group import get_label_pairs\n",
        "from labelbox.data.metrics import (feature_miou_metric, confusion_matrix_metric,\n",
        "                                   feature_confusion_matrix_metric)\n",
        "\n",
        "try:\n",
        "    from image_model import predict, load_model\n",
        "except ModuleNotFoundError:\n",
        "    # !git clone https://github.com/Labelbox/labelbox-python.git\n",
        "    # !cd labelbox-python && git checkout mea-dev\n",
        "    # !mv labelbox-python/examples/model_assisted_labeling/*.py .\n",
        "    raise Exception(\"You will need to run from the labelbox-python git repo\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Configure client"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "PROJECT_NAME = \"Diagnostics Demo Custom Metrics\"\n",
        "MODEL_NAME = \"MSCOCO Mapillary Custom Metrics\"\n",
        "MODEL_VERSION = \"0.0.0\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "API Key\n",
        "\n",
        "Provide a valid api key below in order to properly connect to the Labelbox Client."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Add your api key\n",
        "API_KEY = None\n",
        "client = lb.Client(api_key=API_KEY)\n",
        "load_model()  # initialize Tensorflow Model"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Configure for whatever combination of tools and class names that you would like.\n",
        "class_mappings = {\n",
        "    1: {\n",
        "        \"name\": 'person',\n",
        "        \"kind\": lb.Tool.Type.POLYGON\n",
        "    },\n",
        "    2: {\n",
        "        \"name\": 'bicycle',\n",
        "        \"kind\": lb.Tool.Type.SEGMENTATION,\n",
        "        'color': 64\n",
        "    },\n",
        "    3: {\n",
        "        \"name\": 'car',\n",
        "        \"kind\": lb.Tool.Type.BBOX\n",
        "    },\n",
        "    4: {\n",
        "        \"name\": 'motorcycle',\n",
        "        \"kind\": lb.Tool.Type.BBOX\n",
        "    },\n",
        "    6: {\n",
        "        \"name\": 'bus',\n",
        "        \"kind\": lb.Tool.Type.POLYGON\n",
        "    },\n",
        "    7: {\n",
        "        \"name\": 'train',\n",
        "        \"kind\": lb.Tool.Type.POLYGON\n",
        "    },\n",
        "    8: {\n",
        "        \"name\": 'truck',\n",
        "        \"kind\": lb.Tool.Type.POLYGON\n",
        "    },\n",
        "    10: {\n",
        "        \"name\": 'traffic light',\n",
        "        \"kind\": lb.Tool.Type.POINT\n",
        "    },\n",
        "    11: {\n",
        "        \"name\": 'fire hydrant',\n",
        "        \"kind\": lb.Tool.Type.BBOX\n",
        "    },\n",
        "    13: {\n",
        "        \"name\": 'stop sign',\n",
        "        \"kind\": lb.Tool.Type.SEGMENTATION,\n",
        "        'color': 255\n",
        "    },\n",
        "    14: {\n",
        "        \"name\": 'parking meter',\n",
        "        \"kind\": lb.Tool.Type.POINT\n",
        "    },\n",
        "    28: {\n",
        "        \"name\": 'umbrella',\n",
        "        \"kind\": lb.Tool.Type.SEGMENTATION,\n",
        "        'color': 128\n",
        "    },\n",
        "    31: {\n",
        "        \"name\": 'handbag',\n",
        "        \"kind\": lb.Tool.Type.POINT\n",
        "    },\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Create Predictions\n",
        "* Loop over data_rows, make predictions, and create ndjson"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# --- setup dataset ---\n",
        "# load mapillary sample\n",
        "sample_csv_url = \"https://raw.githubusercontent.com/Labelbox/labelbox-python/master/examples/assets/mapillary_sample.csv\"\n",
        "with requests.get(sample_csv_url, stream=True) as r:\n",
        "    image_data = [\n",
        "        row.split(',')\n",
        "        for row in (line.decode('utf-8') for line in r.iter_lines())\n",
        "    ]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "predictions = list()\n",
        "for (image_url, external_id) in notebook.tqdm(image_data):\n",
        "    image = lb_types.ImageData(url=image_url, external_id=external_id)\n",
        "    height, width = image.value.shape[:2]\n",
        "    prediction = predict(np.array([image.im_bytes]),\n",
        "                         min_score=0.5,\n",
        "                         height=height,\n",
        "                         width=width)\n",
        "    boxes, classes, seg_masks = prediction[\"boxes\"], prediction[\n",
        "        \"class_indices\"], prediction[\"seg_masks\"]\n",
        "    annotations = []\n",
        "    for box, class_idx, seg in zip(boxes, classes, seg_masks):\n",
        "        if class_idx in class_mappings:\n",
        "            class_info = class_mappings.get(class_idx)\n",
        "            if class_info['kind'] == lb.Tool.Type.POLYGON:\n",
        "                contours = measure.find_contours(seg, 0.5)\n",
        "                pts = contours[0].astype(np.int32)\n",
        "                value = lb_types.Polygon(points=[\n",
        "                    lb_types.Point(x=x, y=y) for x, y in np.roll(pts, 1, axis=-1)\n",
        "                ])\n",
        "            elif class_info['kind'] == lb.Tool.Type.BBOX:\n",
        "                value = lb_types.Rectangle(start=lb_types.Point(x=box[1], y=box[0]),\n",
        "                                  end=lb_types.Point(x=box[3], y=box[2]))\n",
        "            elif class_info['kind'] == lb.Tool.Type.POINT:\n",
        "                value = lb_types.Point(x=(box[1] + box[3]) / 2.,\n",
        "                              y=(box[0] + box[2]) / 2.)\n",
        "            elif class_info['kind'] == lb.Tool.Type.SEGMENTATION:\n",
        "                value = lb_types.Mask(mask=lb_types.MaskData.from_2D_arr(seg *\n",
        "                                                       class_info['color']),\n",
        "                             color=(class_info['color'],) * 3)\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\"Unsupported kind found. {class_info['kind']}\")\n",
        "            annotations.append(\n",
        "                lb_types.ObjectAnnotation(name=class_info['name'], value=value))\n",
        "    predictions.append(lb_types.Label(data=image, annotations=annotations))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup a project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "tools = []\n",
        "for target in class_mappings.values():\n",
        "    tools.append(lb.Tool(tool=target['kind'], name=target[\"name\"]))\n",
        "ontology_builder = lb.OntologyBuilder(tools=tools)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "print(f\"Setting up: {PROJECT_NAME}\")\n",
        "\n",
        "project = client.create_project(name=PROJECT_NAME, media_type=lb.MediaType.Image)\n",
        "editor = next(\n",
        "    client.get_labeling_frontends(where=lb.LabelingFrontend.name == \"Editor\"))\n",
        "project.setup(editor, ontology_builder.asdict())\n",
        "\n",
        "dataset = client.create_dataset(name=\"Mapillary Diagnostics Demo\")\n",
        "print(f\"Dataset Created: {dataset.uid}\")\n",
        "project.create_batches_from_dataset(\"batch\", dataset.uid)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Prepare for upload\n",
        "* Our local annotations need the following:\n",
        "    1. signed url for segmentation masks\n",
        "    2. data rows in labelbox\n",
        "    3. feature schema ids"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "signer = lambda _bytes: client.upload_data(content=_bytes, sign=True)\n",
        "predictions.add_url_to_masks(signer) \\\n",
        "         .add_url_to_data(signer) \\\n",
        "         .add_to_dataset(dataset, client.upload_data)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## **Optional** - Create labels with [Model Assisted Labeling](https://docs.labelbox.com/en/core-concepts/model-assisted-labeling)\n",
        "\n",
        "* Pre-label image so that we can quickly create ground truth\n",
        "* Create ground truth data for Model Diagnostics\n",
        "* Click on link below to label"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "RUN_MAL = True\n",
        "if RUN_MAL:\n",
        "    project.enable_model_assisted_labeling()\n",
        "    upload_task = lb.MALPredictionImport.create_from_objects(\n",
        "        client, project.uid, f'mal-import-{uuid.uuid4()}', predictions)\n",
        "    upload_task.wait_until_done()\n",
        "    print(upload_task.state, '\\n')"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "print(f\"https://app.labelbox.com/go-label/{project.uid}\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Export Labels\n",
        "\n",
        "We do not support `Skipped` labels and have a limit of **2000**"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "MAX_LABELS = 2000\n",
        "labels = [\n",
        "    l for idx, l in enumerate(project.label_generator()) if idx < MAX_LABELS\n",
        "]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Model & Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "lb_model = client.create_model(name=MODEL_NAME,\n",
        "                               ontology_id=project.ontology().uid)\n",
        "lb_model_run = lb_model.create_model_run(MODEL_VERSION)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Select label ids to upload"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "lb_model_run.upsert_labels([label.uid for label in labels])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Compute Metrics\n",
        "* First get pairs of labels and predictions"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "* Create helper functions for our metric\n",
        "* All functions will accept ground truth and prediction annotations"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from shapely.ops import cascaded_union\n",
        "\n",
        "\n",
        "def nearby_cars_iou(ground_truths, predictions, area_threshold=17000):\n",
        "    \"\"\"\n",
        "    Metric to track the iou score for cars that are nearby (determined by pixel size).\n",
        "    \n",
        "    This might be useful to investigate why the model poorly when vehicles are nearby.\n",
        "    We might care a lot about optimizing this metric because our self driving car needs to \n",
        "     be aware of its immediate surroundings for safety reasons.\n",
        "    \"\"\"\n",
        "    ground_truths = [gt for gt in ground_truths if gt.name == 'car']\n",
        "    predictions = [pred for pred in predictions if pred.name == 'car']\n",
        "    ground_truths = cascaded_union([\n",
        "        gt.value.shapely\n",
        "        for gt in ground_truths\n",
        "        if gt.value.shapely.area > area_threshold\n",
        "    ])\n",
        "    predictions = cascaded_union([\n",
        "        pred.value.shapely\n",
        "        for pred in predictions\n",
        "        if pred.value.shapely.area > area_threshold\n",
        "    ])\n",
        "    union = ground_truths.union(predictions).area\n",
        "    # If there is no prediction or label then the score is undefined\n",
        "    if union == 0:\n",
        "        return []\n",
        "    return [\n",
        "        ScalarMetric(\n",
        "            value=ground_truths.intersection(predictions).area / union,\n",
        "            metric_name=\"iou\",\n",
        "            feature_name=\"car\",\n",
        "            subclass_name=\n",
        "            \"nearby\"  # Doesn't necessarily need to be a subclass in the ontology\n",
        "        )\n",
        "    ]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "* Compute and sssign each metric to prediction label"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Metric functions expect to be provided labels and predictions that correspond to the same data image/video frame\n",
        "# This get_label_pairs function uses the datarow id to achieve this.\n",
        "pairs = get_label_pairs(labels, predictions, filter_mismatch=True)\n",
        "for (ground_truth, prediction) in pairs.values():\n",
        "    metrics = []\n",
        "    metrics.extend(\n",
        "        feature_miou_metric(ground_truth.annotations, prediction.annotations))\n",
        "    metrics.extend(\n",
        "        feature_confusion_matrix_metric(ground_truth.annotations,\n",
        "                                        prediction.annotations))\n",
        "    metrics.extend(\n",
        "        nearby_cars_iou(ground_truth.annotations, prediction.annotations))\n",
        "    prediction.annotations.extend(metrics)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Upload to Labelbox"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_task = lb_model_run.add_predictions(\n",
        "    f'diagnostics-import-{uuid.uuid4()}', predictions)\n",
        "upload_task.wait_until_done()\n",
        "print(upload_task.state)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Open Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "for idx, model_run_data_row in enumerate(lb_model_run.model_run_data_rows()):\n",
        "    if idx == 5:\n",
        "        break\n",
        "    print(model_run_data_row.url)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}